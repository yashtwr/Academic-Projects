{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'.\\train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv(r'.\\train_labels.csv')\n",
    "x = df\n",
    "\n",
    "# Split the data in train_validate_test: 80:20 Train:Test\n",
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(x, y, test_size=0.2, random_state=50)\n",
    "# Split the data in train_validate_test: 90:10 Train:Validate\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_train_val, Y_train_val, test_size=0.1, random_state=50)\n",
    "\n",
    "N = y_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def mean_squared_error(predictions, labels):\n",
    "    N = labels.size\n",
    "    mse = ((predictions - labels)**2).sum() / (2*N)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "    predicions_correct = predictions.max(axis=1) == labels.max(axis=1)\n",
    "    accuracy = predicions_correct.mean()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLD weights are:\n",
      "Weights from input to hidden layer: [[ 0.66579325  0.35763949 -0.77270015 ...  0.05427426  0.00214572\n",
      "  -0.08730011]\n",
      " [ 0.21651309  0.60151869 -0.48253284 ...  0.06756844  0.7422685\n",
      "  -0.53990244]\n",
      " [-0.98886414 -0.87168615  0.13303508 ...  0.69899819 -0.13562399\n",
      "   0.30660209]\n",
      " ...\n",
      " [-0.65525474 -0.2581449   0.39199269 ... -0.1499362   0.2711711\n",
      "  -0.26161749]\n",
      " [-0.23948924 -0.24653798  0.21128405 ... -0.887403    0.32889022\n",
      "  -0.29837126]\n",
      " [ 0.38106452  0.29109196 -0.25335657 ...  0.09785153 -0.0341746\n",
      "   0.05756914]]\n",
      "Weights from hidden to outpu layer: [[ 0.49253976  0.16480257 -0.05729035 -0.2316216 ]\n",
      " [ 0.86029544  0.47654979  0.13243439 -0.32192288]\n",
      " [ 0.67355332 -0.39951134  1.12836133  0.36388273]\n",
      " [ 0.14082781  0.47503754 -0.40307529 -0.94068578]\n",
      " [-0.85054635  0.2064683  -0.83586409  0.16165919]\n",
      " [-0.07703012  0.4715005   0.20470836 -0.11303358]\n",
      " [-0.05926661  0.15629633 -1.14947972  0.09500192]\n",
      " [-0.10018552  0.11537668  0.5364384   0.06483497]\n",
      " [-0.7788787  -0.0473278   0.73003255  0.17569693]\n",
      " [ 0.06552012 -0.37606494  0.53227707  0.93956882]]\n",
      "Updated weights are:\n",
      "Weights from input to hidden layer: [[ 0.66579325  0.35763949 -0.77270015 ...  0.05427426  0.00214572\n",
      "  -0.08730011]\n",
      " [ 0.21651309  0.60151869 -0.48253284 ...  0.06756844  0.7422685\n",
      "  -0.53990244]\n",
      " [-0.98886414 -0.87168615  0.13303508 ...  0.69899819 -0.13562399\n",
      "   0.30660209]\n",
      " ...\n",
      " [-0.65525474 -0.2581449   0.39199269 ... -0.1499362   0.2711711\n",
      "  -0.26161749]\n",
      " [-0.23948924 -0.24653798  0.21128405 ... -0.887403    0.32889022\n",
      "  -0.29837126]\n",
      " [ 0.38106452  0.29109196 -0.25335657 ...  0.09785153 -0.0341746\n",
      "   0.05756914]]\n",
      "Weights from hidden to outpu layer: [[ 0.47507579  0.08966805 -0.1128411  -0.24990657]\n",
      " [ 0.64148281  0.45147217 -0.07351324 -0.30963516]\n",
      " [ 0.54221427 -0.66187297  0.91492919  0.38668569]\n",
      " [-0.09379074  0.12308311 -0.5981099  -1.07204229]\n",
      " [-0.96919577 -0.25656178 -0.92507819  0.02165357]\n",
      " [-0.03511804  0.29493082  0.08578446 -0.15705921]\n",
      " [-0.17733133 -0.04209724 -1.25585032 -0.22467562]\n",
      " [-0.26410906 -0.03059512  0.28219322 -0.26616787]\n",
      " [-0.98947168 -0.08339238  0.60960871 -0.08420386]\n",
      " [ 0.05340023 -0.69565789  0.34620695  0.74827321]]\n",
      "bias of output layer:        1.000000000000000000e+00  0.000000000000000000e+00  \\\n",
      "14901                  0.000100                 -0.000069   \n",
      "12766                  0.000096                 -0.000071   \n",
      "6757                  -0.000010                  0.000078   \n",
      "14126                 -0.000082                 -0.000079   \n",
      "11326                  0.000061                 -0.000069   \n",
      "...                         ...                       ...   \n",
      "3050                  -0.000051                  0.000066   \n",
      "15612                  0.000084                 -0.000075   \n",
      "3418                  -0.000025                  0.000097   \n",
      "16818                  0.000082                 -0.000082   \n",
      "15290                 -0.000070                  0.000071   \n",
      "\n",
      "       0.000000000000000000e+00.1  0.000000000000000000e+00.2  \n",
      "14901                   -0.000091                   -0.000081  \n",
      "12766                   -0.000089                   -0.000093  \n",
      "6757                    -0.000019                   -0.000031  \n",
      "14126                   -0.000065                    0.000104  \n",
      "11326                   -0.000057                   -0.000098  \n",
      "...                           ...                         ...  \n",
      "3050                    -0.000064                   -0.000031  \n",
      "15612                   -0.000097                   -0.000091  \n",
      "3418                    -0.000077                   -0.000080  \n",
      "16818                   -0.000060                   -0.000055  \n",
      "15290                   -0.000057                   -0.000027  \n",
      "\n",
      "[17821 rows x 4 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000000000000000e+00      0.029909\n",
       "0.00000...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000000000000000e+00      0.029562\n",
       "0.00000...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000000000000000e+00      0.029227\n",
       "0.00000...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000000000000000e+00      0.028903\n",
       "0.00000...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000000000000000e+00      0.028589\n",
       "0.00000...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.000000000000000000e+00      0.019753\n",
       "0.00000...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1.000000000000000000e+00      0.019731\n",
       "0.00000...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1.000000000000000000e+00      0.019710\n",
       "0.00000...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.000000000000000000e+00      0.019689\n",
       "0.00000...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.000000000000000000e+00      0.019668\n",
       "0.00000...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   mean_squared_error  accuracy\n",
       "0   1.000000000000000000e+00      0.029909\n",
       "0.00000...       0.0\n",
       "1   1.000000000000000000e+00      0.029562\n",
       "0.00000...       0.0\n",
       "2   1.000000000000000000e+00      0.029227\n",
       "0.00000...       0.0\n",
       "3   1.000000000000000000e+00      0.028903\n",
       "0.00000...       0.0\n",
       "4   1.000000000000000000e+00      0.028589\n",
       "0.00000...       0.0\n",
       "..                                                ...       ...\n",
       "95  1.000000000000000000e+00      0.019753\n",
       "0.00000...       0.0\n",
       "96  1.000000000000000000e+00      0.019731\n",
       "0.00000...       0.0\n",
       "97  1.000000000000000000e+00      0.019710\n",
       "0.00000...       0.0\n",
       "98  1.000000000000000000e+00      0.019689\n",
       "0.00000...       0.0\n",
       "99  1.000000000000000000e+00      0.019668\n",
       "0.00000...       0.0\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameters\n",
    "learning_rate = 0.5\n",
    "epochs = 100\n",
    "\n",
    "n_input = 784\n",
    "n_hidden = 10\n",
    "n_output = 4\n",
    "bias = [np.zeros(n_hidden), np.zeros(n_output)]\n",
    "np.random.seed(10)\n",
    "weights_1 = np.random.normal(scale=0.5, size=(n_input, n_hidden))   # (4, 2)\n",
    "weights_2 = np.random.normal(scale=0.5, size=(n_hidden, n_output))  # (2, 3)\n",
    "print(\"OLD weights are:\")\n",
    "print(\"Weights from input to hidden layer:\", weights_1)\n",
    "print(\"Weights from hidden to outpu layer:\", weights_2)\n",
    "# training the neural net\n",
    "monitoring = {\"mean_squared_error\": [], \"accuracy\": []}\n",
    "for epoch in range(epochs):    \n",
    "    \n",
    "    # feedforward\n",
    "    hidden_layer_inputs = np.dot(x_train, weights_1) + bias[-2]\n",
    "    hidden_layer_outputs = sigmoid(hidden_layer_inputs)\n",
    "\n",
    "    output_layer_inputs = np.dot(hidden_layer_outputs, weights_2) + bias[-1]\n",
    "    output_layer_outputs = sigmoid(output_layer_inputs)\n",
    "    \n",
    "    \n",
    "    # monitor training process\n",
    "    mse = mean_squared_error(output_layer_outputs, y_train)\n",
    "    acc = accuracy(output_layer_outputs, y_train)\n",
    "    \n",
    "    monitoring[\"mean_squared_error\"].append(mse)\n",
    "    monitoring[\"accuracy\"].append(acc)\n",
    "    \n",
    "    \n",
    "    # backpropagation\n",
    "    output_layer_error = output_layer_outputs - y_train\n",
    "    output_layer_delta = output_layer_error * output_layer_outputs * (1 - output_layer_outputs)\n",
    "\n",
    "    hidden_layer_error = np.dot(output_layer_delta, weights_2.T)\n",
    "    hidden_layer_delta = hidden_layer_error * hidden_layer_outputs * (1 - hidden_layer_outputs)\n",
    "\n",
    "    \n",
    "    # weight updates\n",
    "    weights_2_update = np.dot(hidden_layer_outputs.T, output_layer_delta) / N\n",
    "    weights_1_update = np.dot(x_train.T, hidden_layer_delta) / N\n",
    "\n",
    "    weights_2 = weights_2 - learning_rate * weights_2_update\n",
    "    weights_1 = weights_1 - learning_rate * weights_1_update\n",
    "    #bias updates\n",
    "    bias[-1] = bias[-1] - learning_rate*output_layer_delta/N\n",
    "    bias[-2] = bias[-2] - learning_rate*hidden_layer_delta/N\n",
    "print(\"Updated weights are:\")\n",
    "print(\"Weights from input to hidden layer:\", weights_1)\n",
    "print(\"Weights from hidden to outpu layer:\", weights_2)\n",
    "print(\"bias of output layer:\",bias[-1])\n",
    "monitoring_df = pd.DataFrame(monitoring)\n",
    "monitoring_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09745036, 0.39505523, 0.12022221, 0.21938366],\n",
       "       [0.30844341, 0.26194403, 0.29105294, 0.39302231],\n",
       "       [0.42827952, 0.57010408, 0.37181087, 0.25429089],\n",
       "       ...,\n",
       "       [0.19083613, 0.20461829, 0.42748631, 0.36911882],\n",
       "       [0.15233156, 0.41596639, 0.29308195, 0.22814185],\n",
       "       [0.27188167, 0.45277893, 0.38592456, 0.26675199]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feedforward\n",
    "hidden_layer_inputs = np.dot(x_test, weights_1)\n",
    "hidden_layer_outputs = sigmoid(hidden_layer_inputs)\n",
    "\n",
    "output_layer_inputs = np.dot(hidden_layer_outputs, weights_2)\n",
    "output_layer_outputs = sigmoid(output_layer_inputs)\n",
    "outs = output_layer_outputs\n",
    "outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode the data\n",
    "for i in range(len(outs)):\n",
    "    max_Val = np.max(outs[i])\n",
    "    \n",
    "    for j in range(len(outs[i])):\n",
    "        if outs[i][j] == max_Val:\n",
    "            outs[i][j] = 1\n",
    "        else:\n",
    "            outs[i][j] = 0\n",
    "        \n",
    "outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual output       1.000000000000000000e+00  0.000000000000000000e+00  \\\n",
      "13904                       0.0                       0.0   \n",
      "24324                       0.0                       0.0   \n",
      "12055                       0.0                       0.0   \n",
      "3849                        0.0                       1.0   \n",
      "5327                        0.0                       0.0   \n",
      "...                         ...                       ...   \n",
      "11369                       0.0                       0.0   \n",
      "22094                       0.0                       1.0   \n",
      "8875                        0.0                       0.0   \n",
      "2751                        0.0                       0.0   \n",
      "16858                       0.0                       1.0   \n",
      "\n",
      "       0.000000000000000000e+00.1  0.000000000000000000e+00.2  \n",
      "13904                         1.0                         0.0  \n",
      "24324                         0.0                         1.0  \n",
      "12055                         0.0                         1.0  \n",
      "3849                          0.0                         0.0  \n",
      "5327                          0.0                         1.0  \n",
      "...                           ...                         ...  \n",
      "11369                         1.0                         0.0  \n",
      "22094                         0.0                         0.0  \n",
      "8875                          1.0                         0.0  \n",
      "2751                          0.0                         1.0  \n",
      "16858                         0.0                         0.0  \n",
      "\n",
      "[1981 rows x 4 columns] predicted out [[0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual output{} predicted out {}\".format(y_test, outs))\n",
    "acc = accuracy(outs, y_test)\n",
    "print(\"Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
