{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Invalid requirement: 'torch!'\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aayushibeniwal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/aayushibeniwal/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b1b0d8027e5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"aclImdb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"pos\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "basepath = './data/aclImdb'\n",
    "dir_list = os.listdir(basepath)\n",
    "dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an empty train dataframe\n",
    "df_train = pd.DataFrame(columns=['Review','Polarity'])\n",
    "\n",
    "#creating an empty test dataframe\n",
    "df_test = pd.DataFrame(columns=['Review','Polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the reviews from files from in the directory and saving them in the train and test dataframes along with polarity.\n",
    "df_index = 0\n",
    "for superfolder in dir_list:\n",
    "    if superfolder== 'test' or superfolder== 'train':\n",
    "        subsuperfolder = os.listdir(basepath+'/'+superfolder)\n",
    "        for subsuperfolder in subsuperfolder:\n",
    "            if subsuperfolder == 'neg' or subsuperfolder =='pos':\n",
    "                file_list = os.listdir(basepath+'/'+superfolder+'/'+subsuperfolder)\n",
    "                for subfile in file_list:\n",
    "                    fdata = open(basepath+'/'+superfolder+'/'+subsuperfolder+'/'+subfile, encoding=\"utf8\")\n",
    "                    if superfolder == 'train':\n",
    "                        if subsuperfolder == 'neg':\n",
    "                            df_train = df_train.append({'Review': fdata.read(), 'Polarity': 0}, ignore_index=True)\n",
    "                        else:\n",
    "                            df_train = df_train.append({'Review': fdata.read(), 'Polarity': 1}, ignore_index=True)\n",
    "                    else:\n",
    "                        if subsuperfolder == 'neg':\n",
    "                            df_test = df_test.append({'Review': fdata.read(), 'Polarity': 0}, ignore_index=True)\n",
    "                        else:\n",
    "                            df_test = df_test.append({'Review': fdata.read(), 'Polarity': 1}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Working with one of the best Shakespeare sourc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well...tremors I, the original started off in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ouch! This one was a bit painful to sit throug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've seen some crappy movies in my life, but t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Carriers\" follows the exploits of two guys an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Polarity\n",
       "0  Working with one of the best Shakespeare sourc...        0\n",
       "1  Well...tremors I, the original started off in ...        0\n",
       "2  Ouch! This one was a bit painful to sit throug...        0\n",
       "3  I've seen some crappy movies in my life, but t...        0\n",
       "4  \"Carriers\" follows the exploits of two guys an...        0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alan Rickman &amp; Emma Thompson give good perform...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have seen this movie and I did not care for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In Los Angeles, the alcoholic and lazy Hank Ch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film is bundled along with \"Gli fumavano ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I only comment on really very good films and o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Polarity\n",
       "0  Alan Rickman & Emma Thompson give good perform...        0\n",
       "1  I have seen this movie and I did not care for ...        0\n",
       "2  In Los Angeles, the alcoholic and lazy Hank Ch...        0\n",
       "3  This film is bundled along with \"Gli fumavano ...        0\n",
       "4  I only comment on really very good films and o...        0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment of 0 is 50 % of total\n",
      "Sentiment of 1 is 50 % of total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'samples')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Checking if no of reviews are same for pos and neg\n",
    "\n",
    "print('Sentiment of 0 is {} % of total'.format(round(df_train['Polarity'].value_counts()[0]/len(df_train['Polarity'])*100)))\n",
    "print('Sentiment of 1 is {} % of total'.format(round(df_train['Polarity'].value_counts()[1]/len(df_train['Polarity'])*100)))\n",
    "x=df_train.Polarity.value_counts()\n",
    "sns.barplot(x.index,x)\n",
    "plt.gca().set_ylabel('samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Working with one of the best Shakespeare sourc...\n",
       "1        Well...tremors I, the original started off in ...\n",
       "2        Ouch! This one was a bit painful to sit throug...\n",
       "3        I've seen some crappy movies in my life, but t...\n",
       "4        \"Carriers\" follows the exploits of two guys an...\n",
       "                               ...                        \n",
       "24995    About a year ago I finally gave up on American...\n",
       "24996    When I saw the elaborate DVD box for this and ...\n",
       "24997    Last November, I had a chance to see this film...\n",
       "24998    Great movie -I loved it. Great editing and use...\n",
       "24999    Enchanted April is a tone poem, an impressioni...\n",
       "Name: Review, Length: 25000, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing unwanted words to convert a document to a sequence of words which are more useful to determine sentiment\n",
    "#Removing special characters and numbers from the reviews\n",
    "\n",
    "import re\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\*)|(\\d+)\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "NON_LETTERS = re.compile(\"[^a-zA-Z]\")\n",
    "NO_SPACE = \"\"\n",
    "SPACE = \" \"\n",
    "\n",
    "def review_to_words(review, string = True, remove_stopwords=True):\n",
    "    \n",
    "    review = [REPLACE_NO_SPACE.sub(NO_SPACE, line.lower()) for line in review]\n",
    "    review = [REPLACE_WITH_SPACE.sub(SPACE, line) for line in review]\n",
    "    review = [NON_LETTERS.sub(SPACE, line) for line in review]  \n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of reviews\n",
    "clean_train_reviews = review_to_words(df_train.Review)\n",
    "clean_test_reviews = review_to_words(df_test.Review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'working with one of the best shakespeare sources this film manages to be creditable to its source whilst still appealing to a wider audience branagh steals the film from under fishburnes nose and theres a talented cast on good form'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns='Review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(columns='Review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.insert(0,'Review', clean_train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.insert(0,'Review', clean_test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Review Polarity\n",
      "0      working with one of the best shakespeare sourc...        0\n",
      "1      welltremors i the original started off in  and...        0\n",
      "2      ouch this one was a bit painful to sit through...        0\n",
      "3      ive seen some crappy movies in my life but thi...        0\n",
      "4      carriers follows the exploits of two guys and ...        0\n",
      "...                                                  ...      ...\n",
      "24995  about a year ago i finally gave up on american...        1\n",
      "24996  when i saw the elaborate dvd box for this and ...        1\n",
      "24997  last november i had a chance to see this film ...        1\n",
      "24998  great movie  i loved it great editing and use ...        1\n",
      "24999  enchanted april is a tone poem an impressionis...        1\n",
      "\n",
      "[25000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopwords Removal\n",
    "Now, let's get rid of the stopwords i.e words which occur very frequently and have possible value like a, an, the, are etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>working one best shakespeare sources film mana...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>welltremors original started found movie quite...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ouch one bit painful sit cute amusing premise ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ive seen crappy movies life one must among wor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>carriers follows exploits two guys two gals st...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Polarity\n",
       "0  working one best shakespeare sources film mana...        0\n",
       "1  welltremors original started found movie quite...        0\n",
       "2  ouch one bit painful sit cute amusing premise ...        0\n",
       "3  ive seen crappy movies life one must among wor...        0\n",
       "4  carriers follows exploits two guys two gals st...        0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword = set(stopwords.words(\"english\"))\n",
    "\n",
    "for i in range(0,25000) : \n",
    "    review = df_train.iloc[i,0] # review column : 0\n",
    "    review = review.lower().split()\n",
    "    words = [r for r in review if not r in stopword]\n",
    "    clean_review = ' '.join(words)\n",
    "    df_train.iloc[i,0] = clean_review\n",
    "\n",
    "for i in range(0,25000) : \n",
    "    review = df_test.iloc[i,0] # review column : 0\n",
    "    review = review.lower().split()\n",
    "    words = [r for r in review if not r in stopword]\n",
    "    clean_review = ' '.join(words)\n",
    "    df_test.iloc[i,0] = clean_review\n",
    "    \n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Shuffling the data so that the neg and pos polarities are not in order and get mixed </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>laurel hardy comedy short boys arrive sweep ch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thhe entertaining youll laugh lot cringe proba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>labored comedy irs agent tony randall investig...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>havent always fan show grew wasnt season start...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>movie two stories one political murder call gi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Polarity\n",
       "0  laurel hardy comedy short boys arrive sweep ch...        1\n",
       "1  thhe entertaining youll laugh lot cringe proba...        0\n",
       "2  labored comedy irs agent tony randall investig...        0\n",
       "3  havent always fan show grew wasnt season start...        1\n",
       "4  movie two stories one political murder call gi...        0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>worst movie ever clever funny thought provokin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>film succeed film festival karlovy vary czech ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>first thing note music nothing amazing ruggero...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>brother plays moose film although scenes left ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rather mild horror movie couple sex scenes cou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Polarity\n",
       "0  worst movie ever clever funny thought provokin...        0\n",
       "1  film succeed film festival karlovy vary czech ...        1\n",
       "2  first thing note music nothing amazing ruggero...        0\n",
       "3  brother plays moose film although scenes left ...        0\n",
       "4  rather mild horror movie couple sex scenes cou...        0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(df_train['Review'])\n",
    "X_train = cv.transform(df_train['Review'])\n",
    "X_test = cv.transform(df_test['Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.87524\n",
      "Accuracy for C=0.05: 0.8796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.25: 0.87396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.5: 0.8706\n",
      "Accuracy for C=1: 0.86692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_train = df_train['Polarity']\n",
    "y_train = y_train.astype('int')\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, target, test_size = 0.20, random_state=42)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" % (c, accuracy_score(df_test['Polarity'].astype('int'), lr.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tk = Tokenizer()\n",
    "tk.fit_on_texts(list(df_train['Review'])+list(df_test['Review']))\n",
    "text_seq_tr=tk.texts_to_sequences(df_train['Review'])\n",
    "text_seq_te=tk.texts_to_sequences(df_test['Review'])\n",
    "word_ind=tk.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total word count is :',len(word_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "pad_train=pad_sequences(text_seq_tr, maxlen=400) \n",
    "pad_test=pad_sequences(text_seq_te, maxlen=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(pad_train, train['sentiment'], random_state=77, test_size=0.07, stratify=train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of\n",
    "# strings.\n",
    "\n",
    "train_data_features = vectorizer.fit_transform(df_train['Review'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
