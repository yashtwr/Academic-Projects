{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Yash\n",
      "[nltk_data]     Tiwari\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Yash\n",
      "[nltk_data]     Tiwari\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imdb.vocab', 'imdbEr.txt', 'README', 'test', 'train']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basepath = './data/aclImdb'\n",
    "dir_list = os.listdir(basepath)\n",
    "dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an empty train dataframe\n",
    "df_train = pd.DataFrame(columns=['Review','Polarity'])\n",
    "\n",
    "#creating an empty test dataframe\n",
    "df_test = pd.DataFrame(columns=['Review','Polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the reviews from files from in the directory and saving them in the train and test dataframes along with polarity.\n",
    "df_index = 0\n",
    "for superfolder in dir_list:\n",
    "    if superfolder== 'test' or superfolder== 'train':\n",
    "        subsuperfolder = os.listdir(basepath+'/'+superfolder)\n",
    "        for subsuperfolder in subsuperfolder:\n",
    "            if subsuperfolder == 'neg' or subsuperfolder =='pos':\n",
    "                file_list = os.listdir(basepath+'/'+superfolder+'/'+subsuperfolder)\n",
    "                for subfile in file_list:\n",
    "                    fdata = open(basepath+'/'+superfolder+'/'+subsuperfolder+'/'+subfile, encoding=\"utf8\")\n",
    "                    if superfolder == 'train':\n",
    "                        if subsuperfolder == 'neg':\n",
    "                            df_train = df_train.append({'Review': fdata.read(), 'Polarity': 0}, ignore_index=True)\n",
    "                        else:\n",
    "                            df_train = df_train.append({'Review': fdata.read(), 'Polarity': 1}, ignore_index=True)\n",
    "                    else:\n",
    "                        if subsuperfolder == 'neg':\n",
    "                            df_test = df_test.append({'Review': fdata.read(), 'Polarity': 0}, ignore_index=True)\n",
    "                        else:\n",
    "                            df_test = df_test.append({'Review': fdata.read(), 'Polarity': 1}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Story of a man who has unnatural feelings for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Airport '77 starts as a brand new luxury 747 p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This film lacked something I couldn't put my f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sorry everyone,,, I know this is supposed to b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When I was little my parents took me along to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Polarity\n",
       "0  Story of a man who has unnatural feelings for ...        0\n",
       "1  Airport '77 starts as a brand new luxury 747 p...        0\n",
       "2  This film lacked something I couldn't put my f...        0\n",
       "3  Sorry everyone,,, I know this is supposed to b...        0\n",
       "4  When I was little my parents took me along to ...        0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Polarity\n",
       "0  Once again Mr. Costner has dragged out a movie...        0\n",
       "1  This is an example of why the majority of acti...        0\n",
       "2  First of all I hate those moronic rappers, who...        0\n",
       "3  Not even the Beatles could write songs everyon...        0\n",
       "4  Brass pictures (movies is not a fitting word f...        0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment of 0 is 50 % of total\n",
      "Sentiment of 1 is 50 % of total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yash Tiwari\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'samples')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Checking if no of reviews are same for pos and neg\n",
    "\n",
    "print('Sentiment of 0 is {} % of total'.format(round(df_train['Polarity'].value_counts()[0]/len(df_train['Polarity'])*100)))\n",
    "print('Sentiment of 1 is {} % of total'.format(round(df_train['Polarity'].value_counts()[1]/len(df_train['Polarity'])*100)))\n",
    "x=df_train.Polarity.value_counts()\n",
    "sns.barplot(x.index,x)\n",
    "plt.gca().set_ylabel('samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Story of a man who has unnatural feelings for ...\n",
       "1        Airport '77 starts as a brand new luxury 747 p...\n",
       "2        This film lacked something I couldn't put my f...\n",
       "3        Sorry everyone,,, I know this is supposed to b...\n",
       "4        When I was little my parents took me along to ...\n",
       "                               ...                        \n",
       "24995    Seeing as the vote average was pretty low, and...\n",
       "24996    The plot had some wretched, unbelievable twist...\n",
       "24997    I am amazed at how this movie(and most others ...\n",
       "24998    A Christmas Together actually came before my t...\n",
       "24999    Working-class romantic drama from director Mar...\n",
       "Name: Review, Length: 25000, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing unwanted words to convert a document to a sequence of words which are more useful to determine sentiment\n",
    "#Removing special characters and numbers from the reviews\n",
    "\n",
    "import re\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\*)|(\\d+)\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "NON_LETTERS = re.compile(\"[^a-zA-Z]\")\n",
    "NO_SPACE = \"\"\n",
    "SPACE = \" \"\n",
    "\n",
    "def review_to_words(review, string = True, remove_stopwords=True):\n",
    "    \n",
    "    review = [REPLACE_NO_SPACE.sub(NO_SPACE, line.lower()) for line in review]\n",
    "    review = [REPLACE_WITH_SPACE.sub(SPACE, line) for line in review]\n",
    "    review = [NON_LETTERS.sub(SPACE, line) for line in review]  \n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of reviews\n",
    "clean_train_reviews = review_to_words(df_train.Review)\n",
    "clean_test_reviews = review_to_words(df_test.Review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'story of a man who has unnatural feelings for a pig starts out with a opening scene that is a terrific example of absurd comedy a formal orchestra audience is turned into an insane violent mob by the crazy chantings of its singers unfortunately it stays absurd the whole time with no general narrative eventually making it just too off putting even those from the era should be turned off the cryptic dialogue would make shakespeare seem easy to a third grader on a technical level its better than you might think with some good cinematography by future great vilmos zsigmond future stars sally kirkland and frederic forrest can be seen briefly'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns='Review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(columns='Review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.insert(0,'Review', clean_train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.insert(0,'Review', clean_test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Review Polarity\n",
      "0      story of a man who has unnatural feelings for ...        0\n",
      "1      airport  starts as a brand new luxury  plane i...        0\n",
      "2      this film lacked something i couldnt put my fi...        0\n",
      "3      sorry everyone i know this is supposed to be a...        0\n",
      "4      when i was little my parents took me along to ...        0\n",
      "...                                                  ...      ...\n",
      "24995  seeing as the vote average was pretty low and ...        1\n",
      "24996  the plot had some wretched unbelievable twists...        1\n",
      "24997  i am amazed at how this movieand most others h...        1\n",
      "24998  a christmas together actually came before my t...        1\n",
      "24999  working class romantic drama from director mar...        1\n",
      "\n",
      "[25000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopwords Removal\n",
    "Now, let's get rid of the stopwords i.e words which occur very frequently and have possible value like a, an, the, are etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>story man unnatural feelings pig starts openin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>airport starts brand new luxury plane loaded v...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>film lacked something couldnt put finger first...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sorry everyone know supposed art film wow hand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>little parents took along theater see interior...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Polarity\n",
       "0  story man unnatural feelings pig starts openin...        0\n",
       "1  airport starts brand new luxury plane loaded v...        0\n",
       "2  film lacked something couldnt put finger first...        0\n",
       "3  sorry everyone know supposed art film wow hand...        0\n",
       "4  little parents took along theater see interior...        0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword = set(stopwords.words(\"english\"))\n",
    "\n",
    "for i in range(0,25000) : \n",
    "    review = df_train.iloc[i,0] # review column : 0\n",
    "    review = review.lower().split()\n",
    "    words = [r for r in review if not r in stopword]\n",
    "    clean_review = ' '.join(words)\n",
    "    df_train.iloc[i,0] = clean_review\n",
    "\n",
    "for i in range(0,25000) : \n",
    "    review = df_test.iloc[i,0] # review column : 0\n",
    "    review = review.lower().split()\n",
    "    words = [r for r in review if not r in stopword]\n",
    "    clean_review = ' '.join(words)\n",
    "    df_test.iloc[i,0] = clean_review\n",
    "    \n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Shuffling the data so that the neg and pos polarities are not in order and get mixed </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>god run lola run adaptation persuasion horribl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deliverance fascinating haunting sometimes eve...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tremendous black white nighttime cinematograph...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blank check one kids movies could great suspen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>viewing several episodes series come conclusio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Polarity\n",
       "0  god run lola run adaptation persuasion horribl...        0\n",
       "1  deliverance fascinating haunting sometimes eve...        1\n",
       "2  tremendous black white nighttime cinematograph...        1\n",
       "3  blank check one kids movies could great suspen...        0\n",
       "4  viewing several episodes series come conclusio...        1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aakrosh second film govind nihalani directortill movie made audience documentaries indiathis movie proved point documentary fulfil requirements commercial film without diluting essence one successful movies year released movie contested big banners bollywood likecoolie betaabhero smithapatel movie acted like conscience hero whenever drifted away lost composure remind like usual heroine usual stuff running around trees shrubsat one timeshe even gave love heros ruthlessness touched roof top another character movie played om puri contemporary naseeruddin shahhe played inspector turned alcoholic characterthe role conveyed message end result honest cop rubbed wrong side system also gave viewers chance forecast heros ending debut filmsadashiv amrapurkar captivated audience cameo role ultimately best supporting actor filmfarethe cop movie complete straight forward personality able adjust system extent anger left half handedly continued govind nihalanis film drohkaal even two decades movie remembered director entire crew one played part par excellence'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ok risky move rent flick thought nothing losew...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie excellent acting cinematography directio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eric idle robbie coltraine janet suzman almost...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>working title dont spank baby wayne crawford w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>enjoy gay themed movies characters arent stere...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Polarity\n",
       "0  ok risky move rent flick thought nothing losew...        0\n",
       "1  movie excellent acting cinematography directio...        1\n",
       "2  eric idle robbie coltraine janet suzman almost...        0\n",
       "3  working title dont spank baby wayne crawford w...        1\n",
       "4  enjoy gay themed movies characters arent stere...        0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(df_train['Review'])\n",
    "X_train = cv.transform(df_train['Review'])\n",
    "X_test = cv.transform(df_test['Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.87524\n",
      "Accuracy for C=0.05: 0.8796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yash Tiwari\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.25: 0.87396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yash Tiwari\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.5: 0.8706\n",
      "Accuracy for C=1: 0.86688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yash Tiwari\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_train = df_train['Polarity']\n",
    "y_train = y_train.astype('int')\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, target, test_size = 0.20, random_state=42)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" % (c, accuracy_score(df_test['Polarity'].astype('int'), lr.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.convert_to_tensor(df_train['Review'])\n",
    "X_test = tf.convert_to_tensor(df_test['Review'])\n",
    "y_train = tf.convert_to_tensor(df_train['Polarity'].astype(int))\n",
    "y_test = tf.convert_to_tensor(df_test['Polarity'].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-0f81abbe71af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtext_seq_tr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtext_seq_te\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_preprocessing\\text.py\u001b[0m in \u001b[0;36mfit_on_texts\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    220\u001b[0m                 \u001b[0mseq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m                 seq = text_to_word_sequence(text,\n\u001b[0m\u001b[0;32m    223\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_preprocessing\\text.py\u001b[0m in \u001b[0;36mtext_to_word_sequence\u001b[1;34m(text, filters, lower, split)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \"\"\"\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnp_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m         np_config.enable_numpy_behavior()\"\"\".format(type(self).__name__, name))\n\u001b[1;32m--> 401\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tk = Tokenizer()\n",
    "tk.fit_on_texts(list(X_train)+list(X_test))\n",
    "text_seq_tr=tk.texts_to_sequences(X_train)\n",
    "text_seq_te=tk.texts_to_sequences(X_test)\n",
    "word_ind=tk.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`sequences` must be a list of iterables. Found non-iterable: tf.Tensor(b'god run lola run adaptation persuasion horrible bad enough screenwriter use term loosely cut pasted dialogue one character onto another often completely context rush story along anne elliott running location location pursuit wentworth near end piece abomination austen must spinning grave respectable young woman would acted atrocious fashion actress played mary horrors needless say rest austen remakes bad turning new generation watchers want see impeccable version otherwise wonderful novel get roger michell directed version starring amanda root whose expressions alone speak volumes ciaran hinds superb', shape=(), dtype=string)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_preprocessing\\sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[1;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mlengths\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mflag\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1044\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1045\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Scalar tensor has no `len()`\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1046\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Scalar tensor has no `len()`",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-1d03a19c9285>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# applying pad sequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#max_review = 100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_train_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[1;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[0;32m    150\u001b[0m           \u001b[1;32mor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcase\u001b[0m \u001b[0mof\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m   \"\"\"\n\u001b[1;32m--> 152\u001b[1;33m   return sequence.pad_sequences(\n\u001b[0m\u001b[0;32m    153\u001b[0m       \u001b[0msequences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m       padding=padding, truncating=truncating, value=value)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_preprocessing\\sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[1;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[0mflag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             raise ValueError('`sequences` must be a list of iterables. '\n\u001b[0m\u001b[0;32m     74\u001b[0m                              'Found non-iterable: ' + str(x))\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: `sequences` must be a list of iterables. Found non-iterable: tf.Tensor(b'god run lola run adaptation persuasion horrible bad enough screenwriter use term loosely cut pasted dialogue one character onto another often completely context rush story along anne elliott running location location pursuit wentworth near end piece abomination austen must spinning grave respectable young woman would acted atrocious fashion actress played mary horrors needless say rest austen remakes bad turning new generation watchers want see impeccable version otherwise wonderful novel get roger michell directed version starring amanda root whose expressions alone speak volumes ciaran hinds superb', shape=(), dtype=string)"
     ]
    }
   ],
   "source": [
    "# applying pad sequence\n",
    "#max_review = 100\n",
    "#X_train_1 = sequence.pad_sequences(X_train, maxlen = 500)\n",
    "#X_test = sequence.pad_sequences(X_test, maxlen = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1000, 32)          160000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# data modelling using LSTM\n",
    "embedding_vector_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(5000, embedding_vector_length, input_length=1000))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1000) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1000), dtype=tf.float32, name='embedding_1_input'), name='embedding_1_input', description=\"created by layer 'embedding_1_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1000) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1000), dtype=tf.float32, name='embedding_1_input'), name='embedding_1_input', description=\"created by layer 'embedding_1_input'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": " Cast string to float is not supported\n\t [[node sequential_2/Cast (defined at C:\\Users\\Yash Tiwari\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:633) ]] [Op:__inference_train_function_3818]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_2/Cast:\n ExpandDims (defined at C:\\Users\\Yash Tiwari\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py:1414)\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-750d934bebf7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#train the model with epoch 5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1156\u001b[0m                 _r=1):\n\u001b[0;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1158\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1159\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    948\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnimplementedError\u001b[0m:  Cast string to float is not supported\n\t [[node sequential_2/Cast (defined at C:\\Users\\Yash Tiwari\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:633) ]] [Op:__inference_train_function_3818]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_2/Cast:\n ExpandDims (defined at C:\\Users\\Yash Tiwari\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py:1414)\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "#train the model with epoch 5\n",
    "model.fit(X_train,y_train , epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-a1e8abdf06c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Review'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Review'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtext_seq_tr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Review'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtext_seq_te\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Review'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mword_ind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Tokenizer' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total word count is :',len(word_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "pad_train=pad_sequences(text_seq_tr, maxlen=400) \n",
    "pad_test=pad_sequences(text_seq_te, maxlen=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(pad_train, train['sentiment'], random_state=77, test_size=0.07, stratify=train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of\n",
    "# strings.\n",
    "\n",
    "train_data_features = vectorizer.fit_transform(df_train['Review'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
