{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Yash\n",
      "[nltk_data]     Tiwari\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Yash\n",
      "[nltk_data]     Tiwari\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imdb.vocab', 'imdbEr.txt', 'README', 'test', 'train']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basepath = './data/aclImdb'\n",
    "dir_list = os.listdir(basepath)\n",
    "dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an empty train dataframe\n",
    "df_train = pd.DataFrame(columns=['Review','Polarity'])\n",
    "#creating an empty test dataframe\n",
    "df_test = pd.DataFrame(columns=['Review','Polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the reviews from files in the local directory and saving them in the train and test dataframes along with polarity.\n",
    "df_index = 0\n",
    "for superfolder in dir_list:\n",
    "    if superfolder== 'test' or superfolder== 'train':\n",
    "        subsuperfolder = os.listdir(basepath+'/'+superfolder)\n",
    "        for subsuperfolder in subsuperfolder:\n",
    "            if subsuperfolder == 'neg' or subsuperfolder =='pos':\n",
    "                file_list = os.listdir(basepath+'/'+superfolder+'/'+subsuperfolder)\n",
    "                for subfile in file_list:\n",
    "                    fdata = open(basepath+'/'+superfolder+'/'+subsuperfolder+'/'+subfile, encoding=\"utf8\")\n",
    "                    if superfolder == 'train':\n",
    "                        if subsuperfolder == 'neg':\n",
    "                            df_train = df_train.append({'Review': fdata.read(), 'Polarity': 0}, ignore_index=True)\n",
    "                        else:\n",
    "                            df_train = df_train.append({'Review': fdata.read(), 'Polarity': 1}, ignore_index=True)\n",
    "                    else:\n",
    "                        if subsuperfolder == 'neg':\n",
    "                            df_test = df_test.append({'Review': fdata.read(), 'Polarity': 0}, ignore_index=True)\n",
    "                        else:\n",
    "                            df_test = df_test.append({'Review': fdata.read(), 'Polarity': 1}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Story of a man who has unnatural feelings for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Airport '77 starts as a brand new luxury 747 p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This film lacked something I couldn't put my f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sorry everyone,,, I know this is supposed to b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When I was little my parents took me along to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Polarity\n",
       "0  Story of a man who has unnatural feelings for ...        0\n",
       "1  Airport '77 starts as a brand new luxury 747 p...        0\n",
       "2  This film lacked something I couldn't put my f...        0\n",
       "3  Sorry everyone,,, I know this is supposed to b...        0\n",
       "4  When I was little my parents took me along to ...        0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Polarity\n",
       "0  Once again Mr. Costner has dragged out a movie...        0\n",
       "1  This is an example of why the majority of acti...        0\n",
       "2  First of all I hate those moronic rappers, who...        0\n",
       "3  Not even the Beatles could write songs everyon...        0\n",
       "4  Brass pictures (movies is not a fitting word f...        0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment of 0 is 50 % of total\n",
      "Sentiment of 1 is 50 % of total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yash Tiwari\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'samples')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Checking if no of reviews are same for pos and neg by plotting them\n",
    "print('Sentiment of 0 is {} % of total'.format(round(df_train['Polarity'].value_counts()[0]/len(df_train['Polarity'])*100)))\n",
    "print('Sentiment of 1 is {} % of total'.format(round(df_train['Polarity'].value_counts()[1]/len(df_train['Polarity'])*100)))\n",
    "x=df_train.Polarity.value_counts()\n",
    "sns.barplot(x.index,x)\n",
    "plt.gca().set_ylabel('samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopwords Removal\n",
    "Now, let's get rid of the stopwords i.e words which occur very frequently and have possible value like a, an, the, are etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of stop words that we can remove from our reviews:\n",
      "{'not', 'i', \"you'd\", \"aren't\", 'yours', 'him', 'if', 'during', 'shan', 'his', 'this', \"isn't\", 't', 'off', 'did', 'wouldn', 'such', \"mightn't\", 'haven', 'themselves', 'on', 'a', 'have', 'having', 'under', 'between', 'when', \"didn't\", 'what', 'we', 'into', 'ourselves', 'has', 'do', 'were', 'its', 'was', 'you', 'does', \"you're\", 'there', 'hasn', 'from', 'while', 'don', 'just', 'doesn', 'for', 'same', 'is', 'they', 'further', 'about', 'so', 'hadn', 'himself', 'd', 'by', 'now', \"you've\", 'she', 'because', 'very', 'yourself', 's', 'their', \"wasn't\", 'both', 'isn', \"needn't\", 'can', 'shouldn', 'me', 'wasn', \"haven't\", 'up', \"that'll\", 'of', 'above', 'most', 'these', 'before', 'once', 'our', 'needn', 'should', \"should've\", 'myself', 'that', \"hasn't\", \"mustn't\", 'ma', 'down', 'how', 'been', 'few', 'whom', 'hers', 'couldn', 'won', 'll', 'as', 'all', 'at', 'he', \"wouldn't\", 'to', 'it', 'o', 'any', 'my', 'yourselves', 'or', 'your', 'some', 'be', 'but', 'only', 'here', 'against', 'than', 'didn', 'where', \"couldn't\", 'mightn', 'being', 'm', 'mustn', 'over', 'an', 'after', 'other', 'then', 'more', 'out', 'why', \"doesn't\", 'own', 'each', 'until', \"hadn't\", 'those', 'will', 'no', 'with', 'ain', 'itself', \"shan't\", \"weren't\", \"don't\", 'ours', \"you'll\", 'the', 'again', 'herself', 'in', 'had', \"it's\", 'too', 're', 'her', 'aren', \"shouldn't\", \"she's\", 'below', 'weren', 'through', 'doing', 'are', \"won't\", 'theirs', 've', 'and', 'them', 'which', 'am', 'y', 'who', 'nor'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopWords = set(stopwords.words('english'))\n",
    "print(\"List of stop words that we can remove from our reviews:\")\n",
    "print(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>story man unnatural feelings pig. starts openi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>airport '77 starts brand new luxury 747 plane ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>film lacked something put finger first: charis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sorry everyone,,, know supposed \"art\" film,, w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>little parents took along theater see interior...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Polarity\n",
       "0  story man unnatural feelings pig. starts openi...        0\n",
       "1  airport '77 starts brand new luxury 747 plane ...        0\n",
       "2  film lacked something put finger first: charis...        0\n",
       "3  sorry everyone,,, know supposed \"art\" film,, w...        0\n",
       "4  little parents took along theater see interior...        0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing unwanted words to convert a document to a sequence of words which are more useful to determine sentiment\n",
    "stopword = set(stopwords.words(\"english\"))\n",
    "\n",
    "for i in range(0,25000) : \n",
    "    review = df_train.iloc[i,0] # review column : 0\n",
    "    review = review.lower().split()\n",
    "    words = [r for r in review if not r in stopword]\n",
    "    clean_review = ' '.join(words)\n",
    "    df_train.iloc[i,0] = clean_review\n",
    "\n",
    "for i in range(0,25000) : \n",
    "    review = df_test.iloc[i,0] # review column : 0\n",
    "    review = review.lower().split()\n",
    "    words = [r for r in review if not r in stopword]\n",
    "    clean_review = ' '.join(words)\n",
    "    df_test.iloc[i,0] = clean_review\n",
    "    \n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing special characters and numbers from the reviews\n",
    "\n",
    "def review_to_words(review, string = True, remove_stopwords=True):\n",
    "    REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\*)|(\\d+)\")\n",
    "    REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "    NON_LETTERS = re.compile(\"[^a-zA-Z]\")\n",
    "    NO_SPACE = \"\"\n",
    "    SPACE = \" \"  \n",
    "    review = [REPLACE_NO_SPACE.sub(NO_SPACE, line.lower()) for line in review]\n",
    "    review = [REPLACE_WITH_SPACE.sub(SPACE, line) for line in review]\n",
    "    review = [NON_LETTERS.sub(SPACE, line) for line in review]  \n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of reviews\n",
    "clean_train_reviews = review_to_words(df_train.Review)\n",
    "clean_test_reviews = review_to_words(df_test.Review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'story man unnatural feelings pig starts opening scene terrific example absurd comedy formal orchestra audience turned insane violent mob crazy chantings singers unfortunately stays absurd whole time general narrative eventually making putting even era turned off cryptic dialogue would make shakespeare seem easy third grader technical level better might think good cinematography future great vilmos zsigmond future stars sally kirkland frederic forrest seen briefly'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing these clean data into dataframe again\n",
    "df_train = df_train.drop(columns='Review')\n",
    "df_test = df_test.drop(columns='Review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.insert(0,'Review', clean_train_reviews)\n",
    "df_test.insert(0,'Review', clean_test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Review Polarity\n",
      "0      story man unnatural feelings pig starts openin...        0\n",
      "1      airport  starts brand new luxury  plane loaded...        0\n",
      "2      film lacked something put finger first charism...        0\n",
      "3      sorry everyone know supposed art film wow hand...        0\n",
      "4      little parents took along theater see interior...        0\n",
      "...                                                  ...      ...\n",
      "24995  seeing vote average pretty low fact clerk vide...        1\n",
      "24996  plot wretched unbelievable twists however chem...        1\n",
      "24997  amazed movieand others average  stars lower cr...        1\n",
      "24998  christmas together actually came time ive rais...        1\n",
      "24999  working class romantic drama director martin r...        1\n",
      "\n",
      "[25000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Shuffling the data so that the neg and pos polarities are not in order and get mixed </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>haunting film boasts really creepy house good ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reading rave reviews film give so so finally d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one person says this movie beautiful delicate ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bar questionable acting there musicians end da...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>powerfully wonderful movie held death grip let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Polarity\n",
       "0  haunting film boasts really creepy house good ...        1\n",
       "1  reading rave reviews film give so so finally d...        0\n",
       "2  one person says this movie beautiful delicate ...        1\n",
       "3  bar questionable acting there musicians end da...        1\n",
       "4  powerfully wonderful movie held death grip let...        1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saw mystery science theater  even show really ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>best thing say american version jane turner gi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>claude lelouchs movie pretty good moment cinem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drug runner archie moses introduces friend roc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>questions sometimes hover us answer two women ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Polarity\n",
       "0  saw mystery science theater  even show really ...        0\n",
       "1  best thing say american version jane turner gi...        0\n",
       "2  claude lelouchs movie pretty good moment cinem...        1\n",
       "3  drug runner archie moses introduces friend roc...        0\n",
       "4  questions sometimes hover us answer two women ...        1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making list of reviews\n",
    "Train_reviews_clean = df_train['Review'].tolist()\n",
    "Test_reviews_clean = df_test['Review'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making list of polarity\n",
    "y_train_polarity = df_train['Polarity'].tolist()\n",
    "y_test_polarity = df_test['Polarity'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Feed Forward Neural Network for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokeniser\n",
    "tok = keras.preprocessing.text.Tokenizer()\n",
    "tok.fit_on_texts(Train_reviews_clean) \n",
    "X_train_clean = tok.texts_to_sequences(Train_reviews_clean)\n",
    "X_test_clean = tok.texts_to_sequences(Test_reviews_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Padding \n",
    "X_train_padded = keras.preprocessing.sequence.pad_sequences(X_train_clean,padding='post',maxlen=1000)\n",
    "X_test_padded = keras.preprocessing.sequence.pad_sequences(X_test_clean,padding='post',maxlen=1000)\n",
    "\n",
    "#Splitting train dataset into train and validation sets for training\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_padded, y_train_polarity, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1676, 9211,  103, ...,    0,    0,    0],\n",
       "       [8494,   39,  300, ...,    0,    0,    0],\n",
       "       [ 126,  822, 9662, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [1819,   79,  368, ...,    0,    0,    0],\n",
       "       [ 767, 1047,   72, ...,    0,    0,    0],\n",
       "       [ 726,   51,    2, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, None, 16)          1448624   \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, None, 16)          528       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_6 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,449,729\n",
      "Trainable params: 1,449,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building Model\n",
    "# input shape is the vocabulary count used for the movie reviews (10,000 words)\n",
    "word_size = len(tok.word_index)+1\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(word_size, 16))\n",
    "model.add(keras.layers.Dropout(0.1))\n",
    "model.add(keras.layers.Conv1D(filters=16,kernel_size=2,padding='valid',activation='relu'))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dropout(0.1))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.1))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "35/35 [==============================] - 17s 442ms/step - loss: 0.6931 - acc: 0.5033 - val_loss: 0.6930 - val_acc: 0.4952\n",
      "Epoch 2/20\n",
      "35/35 [==============================] - 15s 428ms/step - loss: 0.6927 - acc: 0.5185 - val_loss: 0.6922 - val_acc: 0.5207\n",
      "Epoch 3/20\n",
      "35/35 [==============================] - 15s 429ms/step - loss: 0.6903 - acc: 0.5593 - val_loss: 0.6875 - val_acc: 0.6408\n",
      "Epoch 4/20\n",
      "35/35 [==============================] - 15s 424ms/step - loss: 0.6812 - acc: 0.6135 - val_loss: 0.6727 - val_acc: 0.6228\n",
      "Epoch 5/20\n",
      "35/35 [==============================] - 15s 436ms/step - loss: 0.6555 - acc: 0.6503 - val_loss: 0.6412 - val_acc: 0.6683\n",
      "Epoch 6/20\n",
      "35/35 [==============================] - 15s 430ms/step - loss: 0.6068 - acc: 0.7106 - val_loss: 0.5878 - val_acc: 0.7623\n",
      "Epoch 7/20\n",
      "35/35 [==============================] - 15s 429ms/step - loss: 0.5294 - acc: 0.7785 - val_loss: 0.5045 - val_acc: 0.7948\n",
      "Epoch 8/20\n",
      "35/35 [==============================] - 15s 432ms/step - loss: 0.4339 - acc: 0.8430 - val_loss: 0.4242 - val_acc: 0.8415\n",
      "Epoch 9/20\n",
      "35/35 [==============================] - 15s 423ms/step - loss: 0.3545 - acc: 0.8766 - val_loss: 0.3706 - val_acc: 0.8604\n",
      "Epoch 10/20\n",
      "35/35 [==============================] - 15s 420ms/step - loss: 0.2962 - acc: 0.8990 - val_loss: 0.3388 - val_acc: 0.8692\n",
      "Epoch 11/20\n",
      "35/35 [==============================] - 15s 428ms/step - loss: 0.2567 - acc: 0.9098 - val_loss: 0.3191 - val_acc: 0.8772\n",
      "Epoch 12/20\n",
      "35/35 [==============================] - 15s 432ms/step - loss: 0.2286 - acc: 0.9207 - val_loss: 0.3048 - val_acc: 0.8817\n",
      "Epoch 13/20\n",
      "35/35 [==============================] - 15s 431ms/step - loss: 0.2024 - acc: 0.9314 - val_loss: 0.2966 - val_acc: 0.8847\n",
      "Epoch 14/20\n",
      "35/35 [==============================] - 15s 427ms/step - loss: 0.1797 - acc: 0.9390 - val_loss: 0.2908 - val_acc: 0.8869\n",
      "Epoch 15/20\n",
      "35/35 [==============================] - 15s 435ms/step - loss: 0.1638 - acc: 0.9455 - val_loss: 0.2875 - val_acc: 0.8876\n",
      "Epoch 16/20\n",
      "35/35 [==============================] - 15s 423ms/step - loss: 0.1495 - acc: 0.9505 - val_loss: 0.2849 - val_acc: 0.8892\n",
      "Epoch 17/20\n",
      "35/35 [==============================] - 15s 427ms/step - loss: 0.1366 - acc: 0.9542 - val_loss: 0.2854 - val_acc: 0.8903\n",
      "Epoch 18/20\n",
      "35/35 [==============================] - 14s 413ms/step - loss: 0.1267 - acc: 0.9600 - val_loss: 0.2848 - val_acc: 0.8923\n",
      "Epoch 19/20\n",
      "35/35 [==============================] - 15s 426ms/step - loss: 0.1146 - acc: 0.9637 - val_loss: 0.2863 - val_acc: 0.8925\n",
      "Epoch 20/20\n",
      "35/35 [==============================] - 15s 431ms/step - loss: 0.1035 - acc: 0.9673 - val_loss: 0.2885 - val_acc: 0.8935\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(tf.convert_to_tensor(X_train),tf.convert_to_tensor(y_train),epochs=20,validation_data=(tf.convert_to_tensor(X_val), tf.convert_to_tensor(y_val)),verbose=1,batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/20892602Group44_NLP_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.models.load_model('./models/20892602Group44_NLP_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 7s 9ms/step - loss: 0.3189 - acc: 0.8789\n",
      "accuracy on testing set: 87.88800239562988\n"
     ]
    }
   ],
   "source": [
    "#accuracy on test set\n",
    "scores = model.evaluate(tf.convert_to_tensor(X_test_padded),tf.convert_to_tensor(y_test_polarity))\n",
    "test_accuracy = scores[1]\n",
    "print('accuracy on testing set:',test_accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The test Accuracy came as 87.88 after using Feed Forward Neural Network which is the best accuracy so far in our modelling network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the training dataset:\n",
      "Removing stop words from training dataset:\n",
      "Removing special characters from training dataset:\n",
      "Training data set is:                                              Review Polarity\n",
      "0  saw film twice space one week times cinema orp...        1\n",
      "1  doc savage man bronze  outta  stars dreadful d...        0\n",
      "2  movie similar play entitled blithe spirit writ...        0\n",
      "3  one harder hitting stories thats real strength...        1\n",
      "4  ive recently went back watched movie seeing ye...        1 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tokenizing words\n",
      "Padding Sequence:\n",
      "Training Model\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 16)          1448624   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          528       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,449,729\n",
      "Trainable params: 1,449,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "35/35 [==============================] - 27s 728ms/step - loss: 0.6933 - acc: 0.5023 - val_loss: 0.6929 - val_acc: 0.5009\n",
      "Epoch 2/20\n",
      "35/35 [==============================] - 25s 709ms/step - loss: 0.6926 - acc: 0.5275 - val_loss: 0.6919 - val_acc: 0.5980\n",
      "Epoch 3/20\n",
      "35/35 [==============================] - 25s 726ms/step - loss: 0.6897 - acc: 0.5437 - val_loss: 0.6860 - val_acc: 0.6276\n",
      "Epoch 4/20\n",
      "35/35 [==============================] - 25s 709ms/step - loss: 0.6773 - acc: 0.6341 - val_loss: 0.6670 - val_acc: 0.6497\n",
      "Epoch 5/20\n",
      "35/35 [==============================] - 25s 720ms/step - loss: 0.6476 - acc: 0.6666 - val_loss: 0.6335 - val_acc: 0.6688\n",
      "Epoch 6/20\n",
      "35/35 [==============================] - 23s 651ms/step - loss: 0.6011 - acc: 0.7025 - val_loss: 0.5903 - val_acc: 0.7057\n",
      "Epoch 7/20\n",
      "35/35 [==============================] - 23s 660ms/step - loss: 0.5377 - acc: 0.7620 - val_loss: 0.5255 - val_acc: 0.7667\n",
      "Epoch 8/20\n",
      "35/35 [==============================] - 24s 690ms/step - loss: 0.4504 - acc: 0.8294 - val_loss: 0.4465 - val_acc: 0.8192\n",
      "Epoch 9/20\n",
      "35/35 [==============================] - 24s 692ms/step - loss: 0.3628 - acc: 0.8766 - val_loss: 0.3825 - val_acc: 0.8483\n",
      "Epoch 10/20\n",
      "35/35 [==============================] - 22s 620ms/step - loss: 0.2984 - acc: 0.8977 - val_loss: 0.3448 - val_acc: 0.8604\n",
      "Epoch 11/20\n",
      "35/35 [==============================] - 21s 610ms/step - loss: 0.2537 - acc: 0.9111 - val_loss: 0.3240 - val_acc: 0.8691\n",
      "Epoch 12/20\n",
      "35/35 [==============================] - 21s 614ms/step - loss: 0.2185 - acc: 0.9251 - val_loss: 0.3116 - val_acc: 0.8731\n",
      "Epoch 13/20\n",
      "35/35 [==============================] - 22s 621ms/step - loss: 0.1944 - acc: 0.9341 - val_loss: 0.3060 - val_acc: 0.8732\n",
      "Epoch 14/20\n",
      "35/35 [==============================] - 21s 613ms/step - loss: 0.1730 - acc: 0.9422 - val_loss: 0.3012 - val_acc: 0.8787\n",
      "Epoch 15/20\n",
      "35/35 [==============================] - 22s 617ms/step - loss: 0.1554 - acc: 0.9462 - val_loss: 0.3013 - val_acc: 0.8787\n",
      "Epoch 16/20\n",
      "35/35 [==============================] - 22s 617ms/step - loss: 0.1393 - acc: 0.9534 - val_loss: 0.3026 - val_acc: 0.8805\n",
      "Epoch 17/20\n",
      "35/35 [==============================] - 22s 620ms/step - loss: 0.1258 - acc: 0.9588 - val_loss: 0.3035 - val_acc: 0.8811\n",
      "Epoch 18/20\n",
      "35/35 [==============================] - 22s 621ms/step - loss: 0.1155 - acc: 0.9614 - val_loss: 0.3059 - val_acc: 0.8833\n",
      "Epoch 19/20\n",
      "35/35 [==============================] - 22s 619ms/step - loss: 0.1064 - acc: 0.9650 - val_loss: 0.3091 - val_acc: 0.8845\n",
      "Epoch 20/20\n",
      "35/35 [==============================] - 22s 618ms/step - loss: 0.0973 - acc: 0.9701 - val_loss: 0.3123 - val_acc: 0.8857\n",
      "The final training Validation accuracy is  97.00571298599243\n"
     ]
    }
   ],
   "source": [
    "%run train_NLP.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the testing dataset:\n",
      "Removing special characters from testing Data:\n",
      "Removing stop words from testing Data:\n",
      "Tokenizing words\n",
      "Padding Sequence:\n",
      "782/782 [==============================] - 8s 9ms/step - loss: 0.3359 - acc: 0.8758\n",
      "accuracy on testing dataset is: 87.5760018825531\n"
     ]
    }
   ],
   "source": [
    "%run test_NLP.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy on testing dataset is: 87.5760018825531"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorization\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(df_train['Review'])\n",
    "X_train1 = cv.transform(df_train['Review'])\n",
    "X_test1 = cv.transform(df_test['Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.8772\n",
      "Accuracy for C=0.05: 0.881\n",
      "Accuracy for C=0.25: 0.87448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yash Tiwari\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.5: 0.87164\n",
      "Accuracy for C=1: 0.86904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yash Tiwari\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "y_train1 = df_train['Polarity']\n",
    "#y_train1 = y_train_polarity.astype('int')\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train1, y_train_polarity)\n",
    "    print (\"Accuracy for C=%s: %s\" % (c, accuracy_score(df_test['Polarity'].astype('int'), lr.predict(X_test1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best Accuracy came for C=0.01: 0.8772 while using Logestic Regression but its not as good as the one in feed Forward Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using CNN and LSTM for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making list of reviews\n",
    "Train_reviews_clean = df_train['Review'].tolist()\n",
    "Test_reviews_clean = df_test['Review'].tolist()\n",
    "#making list of polarity\n",
    "y_train_polarity = df_train['Polarity'].tolist()\n",
    "y_test_polarity = df_test['Polarity'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokeniser\n",
    "tok = keras.preprocessing.text.Tokenizer()\n",
    "tok.fit_on_texts(Train_reviews_clean) \n",
    "X_train_clean = tok.texts_to_sequences(Train_reviews_clean)\n",
    "X_test_clean = tok.texts_to_sequences(Test_reviews_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Padding \n",
    "X_train_padded = keras.preprocessing.sequence.pad_sequences(X_train_clean,padding='post',maxlen=1000)\n",
    "X_test_padded = keras.preprocessing.sequence.pad_sequences(X_test_clean,padding='post',maxlen=1000)\n",
    "\n",
    "#Splitting train dataset into train and validation sets for training\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_padded, y_train_polarity, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, None, 16)          1448624   \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, None, 64)          3136      \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, None, 32)          6176      \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, None, 16)          1552      \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, None, 32)          544       \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, None, 1)           33        \n",
      "=================================================================\n",
      "Total params: 1,460,065\n",
      "Trainable params: 1,460,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Using embedding from Keras\n",
    "word_size = len(tok.word_index)+1\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(word_size, 16))\n",
    "\n",
    "# Convolutional model (3x conv, flatten, 2x dense)\n",
    "model.add(keras.layers.Conv1D(filters=64,kernel_size=3,padding='valid',activation='relu'))\n",
    "model.add(keras.layers.Conv1D(filters=32,kernel_size=3,padding='valid',activation='relu'))\n",
    "model.add(keras.layers.Conv1D(filters=16,kernel_size=3,padding='valid',activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.1))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.1))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "35/35 [==============================] - 46s 1s/step - loss: 0.6932 - acc: 0.5005 - val_loss: 0.6932 - val_acc: 0.5013\n",
      "Epoch 2/20\n",
      "35/35 [==============================] - 44s 1s/step - loss: 0.6922 - acc: 0.5136 - val_loss: 0.6901 - val_acc: 0.5123\n",
      "Epoch 3/20\n",
      "35/35 [==============================] - 44s 1s/step - loss: 0.6852 - acc: 0.5178 - val_loss: 0.6831 - val_acc: 0.5173\n",
      "Epoch 4/20\n",
      "35/35 [==============================] - 44s 1s/step - loss: 0.6784 - acc: 0.5290 - val_loss: 0.6811 - val_acc: 0.5257\n",
      "Epoch 5/20\n",
      "35/35 [==============================] - 44s 1s/step - loss: 0.6737 - acc: 0.5282 - val_loss: 0.6809 - val_acc: 0.5196\n",
      "Epoch 6/20\n",
      "35/35 [==============================] - 43s 1s/step - loss: 0.6706 - acc: 0.5338 - val_loss: 0.6818 - val_acc: 0.5259\n",
      "Epoch 7/20\n",
      "35/35 [==============================] - 44s 1s/step - loss: 0.6681 - acc: 0.5353 - val_loss: 0.6829 - val_acc: 0.5193\n",
      "Epoch 8/20\n",
      "35/35 [==============================] - 45s 1s/step - loss: 0.6664 - acc: 0.5349 - val_loss: 0.6846 - val_acc: 0.5193\n",
      "Epoch 9/20\n",
      "35/35 [==============================] - 44s 1s/step - loss: 0.6647 - acc: 0.5358 - val_loss: 0.6857 - val_acc: 0.5192\n",
      "Epoch 10/20\n",
      "35/35 [==============================] - 43s 1s/step - loss: 0.6633 - acc: 0.5344 - val_loss: 0.6868 - val_acc: 0.5187\n",
      "Epoch 11/20\n",
      "35/35 [==============================] - 34s 955ms/step - loss: 0.6620 - acc: 0.5380 - val_loss: 0.6892 - val_acc: 0.5187\n",
      "Epoch 12/20\n",
      "35/35 [==============================] - 32s 926ms/step - loss: 0.6609 - acc: 0.5386 - val_loss: 0.6906 - val_acc: 0.5189\n",
      "Epoch 13/20\n",
      "35/35 [==============================] - 31s 885ms/step - loss: 0.6598 - acc: 0.5394 - val_loss: 0.6930 - val_acc: 0.5187\n",
      "Epoch 14/20\n",
      "35/35 [==============================] - 32s 914ms/step - loss: 0.6591 - acc: 0.5351 - val_loss: 0.6940 - val_acc: 0.5187\n",
      "Epoch 15/20\n",
      "35/35 [==============================] - 32s 920ms/step - loss: 0.6582 - acc: 0.5398 - val_loss: 0.6968 - val_acc: 0.5186\n",
      "Epoch 16/20\n",
      "35/35 [==============================] - 31s 885ms/step - loss: 0.6575 - acc: 0.5388 - val_loss: 0.6976 - val_acc: 0.5183\n",
      "Epoch 17/20\n",
      "35/35 [==============================] - 32s 919ms/step - loss: 0.6568 - acc: 0.5400 - val_loss: 0.7025 - val_acc: 0.5183\n",
      "Epoch 18/20\n",
      "35/35 [==============================] - 32s 918ms/step - loss: 0.6560 - acc: 0.5384 - val_loss: 0.7050 - val_acc: 0.5181\n",
      "Epoch 19/20\n",
      "35/35 [==============================] - 32s 914ms/step - loss: 0.6551 - acc: 0.5411 - val_loss: 0.7070 - val_acc: 0.5176\n",
      "Epoch 20/20\n",
      "35/35 [==============================] - 32s 905ms/step - loss: 0.6545 - acc: 0.5416 - val_loss: 0.7093 - val_acc: 0.5178\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(tf.convert_to_tensor(X_train),tf.convert_to_tensor(y_train),epochs=20,validation_data=(tf.convert_to_tensor(X_val), tf.convert_to_tensor(y_val)),verbose=1,batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 11s 14ms/step - loss: 0.7221 - acc: 0.5164\n",
      "accuracy on testing set: 51.643335819244385\n"
     ]
    }
   ],
   "source": [
    "#accuracy on test set\n",
    "scores = model.evaluate(tf.convert_to_tensor(X_test_padded),tf.convert_to_tensor(y_test_polarity))\n",
    "test_accuracy = scores[1]\n",
    "print('accuracy on testing set:',test_accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 16)          1448624   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, None, 50)          13400     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 20)                5680      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                672       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,468,409\n",
      "Trainable params: 1,468,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Using embedding from Keras for LSTM\n",
    "word_size = len(tok.word_index)+1\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(word_size, 16))\n",
    "model.add(keras.layers.SpatialDropout1D(0.2))\n",
    "\n",
    "# Convolutional model (3x conv, flatten, 2x dense)\n",
    "#model.add(keras.layers.LSTM(units=100,activation='relu',dropout=0.2,recurrent_dropout=0.2,return_sequences=True))\n",
    "model.add(keras.layers.LSTM(units=50,activation='relu',dropout=0.2,recurrent_dropout=0.2,return_sequences=True))\n",
    "model.add(keras.layers.LSTM(units=20,activation='relu',dropout=0.2,recurrent_dropout=0.2))\n",
    "model.add(keras.layers.Dropout(0.1))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.1))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "35/35 [==============================] - 1031s 29s/step - loss: 0.6932 - acc: 0.5023 - val_loss: 0.6933 - val_acc: 0.4920\n",
      "Epoch 2/5\n",
      "35/35 [==============================] - 1186s 34s/step - loss: 0.6932 - acc: 0.5034 - val_loss: 0.6933 - val_acc: 0.4920\n",
      "Epoch 3/5\n",
      "35/35 [==============================] - 1318s 38s/step - loss: 0.6931 - acc: 0.5034 - val_loss: 0.6933 - val_acc: 0.4920\n",
      "Epoch 4/5\n",
      "33/35 [===========================>..] - ETA: 1:18 - loss: 0.6931 - acc: 0.4990"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-02b8858e4c0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(tf.convert_to_tensor(X_train),tf.convert_to_tensor(y_train),epochs=5,validation_data=(tf.convert_to_tensor(X_val), tf.convert_to_tensor(y_val)),verbose=1,batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
