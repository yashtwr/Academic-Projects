{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: KNN\n",
    "# [CM 7] Weighted KNN, Different NN Algorithms, accuracy, AUC and f-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Iris Data\n",
    "<b> Now that we have achieved best value of k, we will be using different weights and metrics to improve performance. For iris dataset k=5.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>5.567296</td>\n",
       "      <td>2.850709</td>\n",
       "      <td>4.948188</td>\n",
       "      <td>2.066787</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>6.815965</td>\n",
       "      <td>3.113561</td>\n",
       "      <td>4.828897</td>\n",
       "      <td>1.597867</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>6.060116</td>\n",
       "      <td>2.943939</td>\n",
       "      <td>3.933661</td>\n",
       "      <td>1.176246</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.205868</td>\n",
       "      <td>3.366333</td>\n",
       "      <td>1.675654</td>\n",
       "      <td>0.112269</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.472064</td>\n",
       "      <td>3.467159</td>\n",
       "      <td>1.365865</td>\n",
       "      <td>0.343669</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal_length  sepal_width  petal_length  petal_width          species\n",
       "66      5.567296     2.850709      4.948188     2.066787   Iris-virginica\n",
       "59      6.815965     3.113561      4.828897     1.597867  Iris-versicolor\n",
       "48      6.060116     2.943939      3.933661     1.176246  Iris-versicolor\n",
       "7       5.205868     3.366333      1.675654     0.112269      Iris-setosa\n",
       "20      5.472064     3.467159      1.365865     0.343669      Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iris = pd.read_csv('cleaned_data_iris.csv')\n",
    "df_iris.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted KNN\n",
    "<b> Uniform weight is selected by default. An accuracy of 96.2% was achieved.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. For weights='distance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_iris.iloc[:,:-1]\n",
    "y = df_iris.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Iris Dataset when weights='distance': 97.14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "accuracy_kfold_iris = []\n",
    "for train, test in kf.split(x):\n",
    "    x1_train,x1_test,y1_train,y1_test=x.iloc[train],x.iloc[test],y.iloc[train],y.loc[test]\n",
    "    kfold_knn=KNeighborsClassifier(weights='distance')\n",
    "    kfold_knn.fit(x1_train,y1_train)\n",
    "    accuracy_kfold_iris.append(accuracy_score(kfold_knn.predict(x1_test),y1_test))\n",
    "average_accuracy=np.mean(accuracy_kfold_iris)\n",
    "print(\"Accuracy of Iris Dataset when weights='distance':\", np.round(average_accuracy*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Thus, the accuracy of the model is improved by using weights='distance'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. For metric = ['euclidean','manhattan','chebyshev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracies for Iris Data metric 'euclidean','manhattan','chebyshev' are: [0.9714285714285713, 0.9619047619047618, 0.9714285714285713]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "metric_score = []\n",
    "metric = ['euclidean','manhattan','chebyshev']\n",
    "for m in metric:\n",
    "    accuracy_kfold_iris = []\n",
    "    for train, test in kf.split(x):\n",
    "        x1_train,x1_test,y1_train,y1_test = x.iloc[train],x.iloc[test],y.iloc[train],y.loc[test]\n",
    "        kfold_knn = KNeighborsClassifier(weights='distance', metric=m)\n",
    "        kfold_knn.fit(x1_train,y1_train)\n",
    "        accuracy_kfold_iris.append(accuracy_score(kfold_knn.predict(x1_test),y1_test))\n",
    "    metric_score.append(np.mean(accuracy_kfold_iris))\n",
    "print(\"The Accuracies for Iris Data metric 'euclidean','manhattan','chebyshev' are:\", metric_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> The euclidean metric gives the highest accuracy of 97.14 %.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. For Algorithm = [‘ball_tree’, ‘kd_tree’, ‘brute’]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ball_tree   execution time : 0.018001556396484375   accuracy: 0.9714285714285713\n",
      "kd_tree   execution time : 0.014005184173583984   accuracy: 0.9714285714285713\n",
      "brute   execution time : 0.014774322509765625   accuracy: 0.9714285714285713\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "kf = KFold(n_splits=5)\n",
    "Algorithm = ['ball_tree', 'kd_tree', 'brute']\n",
    "for a in Algorithm:\n",
    "    accuracy_kfold_iris = []\n",
    "    start_time = time.time()\n",
    "    for train, test in kf.split(x):\n",
    "        x1_train,x1_test,y1_train,y1_test = x.iloc[train],x.iloc[test],y.iloc[train],y.loc[test]\n",
    "        kfold_knn = KNeighborsClassifier(weights='distance', metric='euclidean', algorithm=a)\n",
    "        kfold_knn.fit(x1_train,y1_train)\n",
    "        accuracy_kfold_iris.append(accuracy_score(kfold_knn.predict(x1_test),y1_test))\n",
    "    stop_time = time.time()\n",
    "    print(a,' ', 'execution time :', (stop_time-start_time), ' ', \"accuracy:\", np.mean(accuracy_kfold_iris))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> All the three algorithms produce same accuracies but the execution time is lowest for brute.</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Accuracy, auc and F-score for the best parameters\n",
    "<b> From the above operations it is clear that the best fit parameters are k = 5, weight = 'distance', metric = 'euclidean' and algorithm = 'brute'. These parameters are used for new classification calculation. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_iris = KNeighborsClassifier(n_neighbors=5, weights='distance', metric='euclidean', algorithm='brute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score = cross_val_score(knn_iris, x, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(knn_iris, x, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Iris Dataset is: 97.14 %\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Iris Dataset is:', np.round( np.mean(accuracy_score)*100,2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score of Iris Dataset is: 0.9714285714285714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "fsc = f1_score(y,y_pred,average='micro')\n",
    "print('F-score of Iris Dataset is:', fsc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for Iris Dataset is: 0.9785714285714286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "encode = OneHotEncoder()\n",
    "y_encode = encode.fit_transform(np.array(y).reshape(-1,1)).todense()\n",
    "pred_encode = encode.fit_transform(y_pred.reshape(-1,1)).todense()\n",
    "auc_iris = roc_auc_score(y_encode,pred_encode)\n",
    "print(\"AUC for Iris Dataset is:\", auc_iris)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Heart Data\n",
    "<b> Now that we have achieved best value of k, we will be using different weights and metrics to improve performance. For heart dataset k=14.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heart = pd.read_csv('heart_disease_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. For weights=['uniform','distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_heart.iloc[:,:-1]\n",
    "y = df_heart.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Heart Disease Dataset when weights=['uniform','distance']: [0.5914772727272727, 0.6399621212121213]\n"
     ]
    }
   ],
   "source": [
    "weights = ['uniform','distance']\n",
    "acc_weights = []\n",
    "for w in weights:\n",
    "    knn_heart = KNeighborsClassifier(n_neighbors=15, weights=w)\n",
    "    score_heart = cross_val_score(knn_heart, x, y, cv=5)\n",
    "    acc_weights.append(np.mean(score_heart))\n",
    "print(\"Accuracy of Heart Disease Dataset when weights=['uniform','distance']:\", acc_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Thus higher accuracy is achieved by using weights='distance'. </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. metric = ['euclidean','manhattan','chebyshev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracies for Iris Data metric 'euclidean','manhattan','chebyshev' are: [0.6399621212121213, 0.6704545454545455, 0.5852272727272727]\n"
     ]
    }
   ],
   "source": [
    "metric =  ['euclidean','manhattan','chebyshev']\n",
    "acc_metric = []\n",
    "for m in metric:\n",
    "    knn_heart = KNeighborsClassifier(n_neighbors=15, weights='distance', metric=m)\n",
    "    score_heart = cross_val_score(knn_heart, x, y, cv=5)\n",
    "    acc_metric.append(np.mean(score_heart))\n",
    "print(\"The Accuracies for Iris Data metric 'euclidean','manhattan','chebyshev' are:\", acc_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Higher accuracy is achieved by using manhattan distance. </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3. Algorithm = [‘ball_tree’, ‘kd_tree’, ‘brute’]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ball_tree   execution time : 0.016816139221191406   accuracy: 0.6704545454545455\n",
      "kd_tree   execution time : 0.022608518600463867   accuracy: 0.6704545454545455\n",
      "brute   execution time : 0.015000104904174805   accuracy: 0.6704545454545455\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "alg_heart = ['ball_tree', 'kd_tree', 'brute']\n",
    "alg_score = []\n",
    "alg_time = []\n",
    "for a in alg_heart:\n",
    "    start_time = time.time()\n",
    "    knn_heart = KNeighborsClassifier(n_neighbors=15, weights='distance', metric='manhattan', algorithm=a)\n",
    "    score_heart = cross_val_score(knn_heart,x,y,cv=5)\n",
    "    stop_time=time.time()\n",
    "    print(a,' ','execution time :',(stop_time-start_time),' ',\"accuracy:\",np.mean(score_heart))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> The accuracy remains the same but the execution time is lowest for'brute'. </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Accuracy, auc and F-score for the best parameters\n",
    "<b> From the above operations it is clear that the best fit parameters are k = 14, weight = 'distance', metric = 'manhattan' and algorithm = 'brute'. These parameters are used for new classification calculation. </b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_heart = KNeighborsClassifier(n_neighbors=15, weights='distance', metric='manhattan', algorithm='brute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_heart = cross_val_score(knn_heart, x, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(knn_heart, x, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Heart Disease Dataset using best fit parameters is: 67.05 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Heart Disease Dataset using best fit parameters is:\", np.round(np.mean(accuracy_heart)*100,2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score for Heart Disease Dataset is: 0.6707317073170732\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "fsc = f1_score(y, y_pred, average='micro')\n",
    "print('F-score for Heart Disease Dataset is:', fsc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for Heart Disease Dataset is: 0.6671650717703349\n"
     ]
    }
   ],
   "source": [
    "auc_heart = roc_auc_score(y, y_pred, average='weighted')\n",
    "print('AUC for Heart Disease Dataset is:', auc_heart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
