{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: KNN\n",
    "# [CM 7] Weighted KNN, Different NN Algorithms, accuracy, AUC and f-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Iris Data\n",
    "<b> Now that we have achieved best value of k, we will be using different weights and metrics to improve performance. For iris dataset k=5.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>7.795561</td>\n",
       "      <td>2.643068</td>\n",
       "      <td>6.768611</td>\n",
       "      <td>2.424502</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>6.633922</td>\n",
       "      <td>2.865580</td>\n",
       "      <td>5.464554</td>\n",
       "      <td>2.119895</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5.564197</td>\n",
       "      <td>2.771731</td>\n",
       "      <td>3.483588</td>\n",
       "      <td>1.074754</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5.743375</td>\n",
       "      <td>2.987622</td>\n",
       "      <td>4.092458</td>\n",
       "      <td>1.460286</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>4.511538</td>\n",
       "      <td>2.242837</td>\n",
       "      <td>1.253850</td>\n",
       "      <td>0.165851</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width          species\n",
       "71       7.795561     2.643068      6.768611     2.424502   Iris-virginica\n",
       "78       6.633922     2.865580      5.464554     2.119895   Iris-virginica\n",
       "101      5.564197     2.771731      3.483588     1.074754  Iris-versicolor\n",
       "94       5.743375     2.987622      4.092458     1.460286  Iris-versicolor\n",
       "51       4.511538     2.242837      1.253850     0.165851      Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iris = pd.read_csv('cleaned_data_iris.csv')\n",
    "df_iris.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted KNN\n",
    "<b> Uniform weight is selected by default. An accuracy of 96.2% was achieved.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. For weights='distance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_iris.iloc[:,:-1]\n",
    "y = df_iris.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Iris Dataset when weights='distance': 97.14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "accuracy_kfold_iris = []\n",
    "for train, test in kf.split(x):\n",
    "    x1_train,x1_test,y1_train,y1_test=x.iloc[train],x.iloc[test],y.iloc[train],y.loc[test]\n",
    "    kfold_knn=KNeighborsClassifier(weights='distance')\n",
    "    kfold_knn.fit(x1_train,y1_train)\n",
    "    accuracy_kfold_iris.append(accuracy_score(kfold_knn.predict(x1_test),y1_test))\n",
    "average_accuracy=np.mean(accuracy_kfold_iris)\n",
    "print(\"Accuracy of Iris Dataset when weights='distance':\", np.round(average_accuracy*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Thus, the accuracy of the model is improved by using weights='distance'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. For metric = ['euclidean','manhattan','chebyshev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracies for Iris Data metric 'euclidean','manhattan','chebyshev' are: [0.9714285714285713, 0.9619047619047618, 0.9714285714285713]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "metric_score = []\n",
    "metric = ['euclidean','manhattan','chebyshev']\n",
    "for m in metric:\n",
    "    accuracy_kfold_iris = []\n",
    "    for train, test in kf.split(x):\n",
    "        x1_train,x1_test,y1_train,y1_test = x.iloc[train],x.iloc[test],y.iloc[train],y.loc[test]\n",
    "        kfold_knn = KNeighborsClassifier(weights='distance', metric=m)\n",
    "        kfold_knn.fit(x1_train,y1_train)\n",
    "        accuracy_kfold_iris.append(accuracy_score(kfold_knn.predict(x1_test),y1_test))\n",
    "    metric_score.append(np.mean(accuracy_kfold_iris))\n",
    "print(\"The Accuracies for Iris Data metric 'euclidean','manhattan','chebyshev' are:\", metric_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> The euclidean metric gives the highest accuracy of 97.14 %.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. For Algorithm = [‘ball_tree’, ‘kd_tree’, ‘brute’]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ball_tree   execution time : 0.019993305206298828   accuracy: 0.9714285714285713\n",
      "kd_tree   execution time : 0.016994714736938477   accuracy: 0.9714285714285713\n",
      "brute   execution time : 0.01500558853149414   accuracy: 0.9714285714285713\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "kf = KFold(n_splits=5)\n",
    "Algorithm = ['ball_tree', 'kd_tree', 'brute']\n",
    "for a in Algorithm:\n",
    "    accuracy_kfold_iris = []\n",
    "    start_time = time.time()\n",
    "    for train, test in kf.split(x):\n",
    "        x1_train,x1_test,y1_train,y1_test = x.iloc[train],x.iloc[test],y.iloc[train],y.loc[test]\n",
    "        kfold_knn = KNeighborsClassifier(weights='distance', metric='euclidean', algorithm=a)\n",
    "        kfold_knn.fit(x1_train,y1_train)\n",
    "        accuracy_kfold_iris.append(accuracy_score(kfold_knn.predict(x1_test),y1_test))\n",
    "    stop_time = time.time()\n",
    "    print(a,' ', 'execution time :', (stop_time-start_time), ' ', \"accuracy:\", np.mean(accuracy_kfold_iris))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> All the three algorithms produce same accuracies but the execution time is lowest for brute.</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Accuracy, auc and F-score for the best parameters\n",
    "<b> From the above operations it is clear that the best fit parameters are k = 5, weight = 'distance', metric = 'euclidean' and algorithm = 'brute'. These parameters are used for new classification calculation. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_iris = KNeighborsClassifier(n_neighbors=5, weights='distance', metric='euclidean', algorithm='brute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score = cross_val_score(knn_iris, x, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(knn_iris, x, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Iris Dataset is: 97.14 %\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Iris Dataset is:', np.round( np.mean(accuracy_score)*100,2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score of Iris Dataset is: 0.9714285714285714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "fsc = f1_score(y,y_pred,average='micro')\n",
    "print('F-score of Iris Dataset is:', fsc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for Iris Dataset is: 0.9785714285714286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "encode = OneHotEncoder()\n",
    "y_encode = encode.fit_transform(np.array(y).reshape(-1,1)).todense()\n",
    "pred_encode = encode.fit_transform(y_pred.reshape(-1,1)).todense()\n",
    "auc_iris = roc_auc_score(y_encode,pred_encode)\n",
    "print(\"AUC for Iris Dataset is:\", auc_iris)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Heart Data\n",
    "<b> Now that we have achieved best value of k, we will be using different weights and metrics to improve performance. For heart dataset k=14.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heart = pd.read_csv('heart_disease_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. For weights=['uniform','distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_heart.iloc[:,:-1]\n",
    "y = df_heart.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Heart Disease Dataset when weights=['uniform','distance']: [0.634469696969697, 0.628030303030303]\n"
     ]
    }
   ],
   "source": [
    "weights = ['uniform','distance']\n",
    "acc_weights = []\n",
    "for w in weights:\n",
    "    knn_heart = KNeighborsClassifier(n_neighbors=14, weights=w)\n",
    "    score_heart = cross_val_score(knn_heart, x, y, cv=5)\n",
    "    acc_weights.append(np.mean(score_heart))\n",
    "print(\"Accuracy of Heart Disease Dataset when weights=['uniform','distance']:\", acc_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Thus higher accuracy is achieved by using weights='uniform'. </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. metric = ['euclidean','manhattan','chebyshev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracies for Heart Data metric 'euclidean','manhattan','chebyshev' are: [0.634469696969697, 0.6587121212121213, 0.5856060606060607]\n"
     ]
    }
   ],
   "source": [
    "metric =  ['euclidean','manhattan','chebyshev']\n",
    "acc_metric = []\n",
    "for m in metric:\n",
    "    knn_heart = KNeighborsClassifier(n_neighbors=14, weights='uniform', metric=m)\n",
    "    score_heart = cross_val_score(knn_heart, x, y, cv=5)\n",
    "    acc_metric.append(np.mean(score_heart))\n",
    "print(\"The Accuracies for Heart Data metric 'euclidean','manhattan','chebyshev' are:\", acc_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Higher accuracy is achieved by using manhattan distance. </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3. Algorithm = [‘ball_tree’, ‘kd_tree’, ‘brute’]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ball_tree   execution time : 0.02507162094116211   accuracy: 0.6587121212121213\n",
      "kd_tree   execution time : 0.022931337356567383   accuracy: 0.6587121212121213\n",
      "brute   execution time : 0.01999521255493164   accuracy: 0.6587121212121213\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "alg_heart = ['ball_tree', 'kd_tree', 'brute']\n",
    "alg_score = []\n",
    "alg_time = []\n",
    "for a in alg_heart:\n",
    "    start_time = time.time()\n",
    "    knn_heart = KNeighborsClassifier(n_neighbors=14, weights='uniform', metric='manhattan', algorithm=a)\n",
    "    score_heart = cross_val_score(knn_heart,x,y,cv=5)\n",
    "    stop_time=time.time()\n",
    "    print(a,' ','execution time :',(stop_time-start_time),' ',\"accuracy:\",np.mean(score_heart))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> The accuracy remains the same but the execution time is lowest for'brute'. </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Accuracy, auc and F-score for the best parameters\n",
    "<b> From the above operations it is clear that the best fit parameters are k = 14, weight = 'uniform', metric = 'manhattan' and algorithm = 'brute'. These parameters are used for new classification calculation. </b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_heart = KNeighborsClassifier(n_neighbors=14, weights='uniform', metric='manhattan', algorithm='brute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_heart = cross_val_score(knn_heart, x, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(knn_heart, x, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Heart Disease Dataset using best fit parameters is: 65.87 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Heart Disease Dataset using best fit parameters is:\", np.round(np.mean(accuracy_heart)*100,2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score for Heart Disease Dataset is: 0.6585365853658537\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "fsc = f1_score(y, y_pred, average='micro')\n",
    "print('F-score for Heart Disease Dataset is:', fsc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for Heart Disease Dataset is: 0.6602870813397128\n"
     ]
    }
   ],
   "source": [
    "auc_heart = roc_auc_score(y, y_pred, average='weighted')\n",
    "print('AUC for Heart Disease Dataset is:', auc_heart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
