{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading cleaned and normalized dataset\n",
    "load_dataset = pd.read_csv(\"cleaned_normalized_coviddata.csv\")\n",
    "df = load_dataset.iloc[:,3:]\n",
    "# Splitting the data into input and output values\n",
    "x=df.iloc[:,:-3]\n",
    "y=df.iloc[:,-3:].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data in training and testing dataset\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1104, 11)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP on input dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                240       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 63        \n",
      "=================================================================\n",
      "Total params: 723\n",
      "Trainable params: 723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "mlp = tf.keras.Sequential([     tf.keras.Input(shape=(11,)),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(3,activation = 'softmax')])\n",
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.compile(optimizer='adam',\n",
    "              loss='BinaryCrossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28/28 [==============================] - 1s 6ms/step - loss: 0.5540 - accuracy: 0.6976 - val_loss: 0.4871 - val_accuracy: 0.8281\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.8403 - val_loss: 0.4034 - val_accuracy: 0.9186\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.9139 - val_loss: 0.3565 - val_accuracy: 0.9729\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.9626 - val_loss: 0.3297 - val_accuracy: 0.9729\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.9706 - val_loss: 0.3111 - val_accuracy: 0.9955\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3177 - accuracy: 0.9864 - val_loss: 0.2968 - val_accuracy: 0.9955\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3050 - accuracy: 0.9864 - val_loss: 0.2857 - val_accuracy: 0.9955\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2949 - accuracy: 0.9864 - val_loss: 0.2767 - val_accuracy: 0.9955\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2861 - accuracy: 0.9864 - val_loss: 0.2687 - val_accuracy: 0.9955\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2795 - accuracy: 0.9762 - val_loss: 0.2617 - val_accuracy: 0.9864\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2725 - accuracy: 0.9694 - val_loss: 0.2559 - val_accuracy: 0.9819\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2669 - accuracy: 0.9547 - val_loss: 0.2511 - val_accuracy: 0.9593\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2619 - accuracy: 0.9388 - val_loss: 0.2462 - val_accuracy: 0.9548\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2578 - accuracy: 0.9139 - val_loss: 0.2422 - val_accuracy: 0.9367\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2532 - accuracy: 0.8811 - val_loss: 0.2394 - val_accuracy: 0.9095\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.8607 - val_loss: 0.2360 - val_accuracy: 0.8643\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.8267 - val_loss: 0.2325 - val_accuracy: 0.8235\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2429 - accuracy: 0.8267 - val_loss: 0.2299 - val_accuracy: 0.8100\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2390 - accuracy: 0.7803 - val_loss: 0.2271 - val_accuracy: 0.7919\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2362 - accuracy: 0.7735 - val_loss: 0.2249 - val_accuracy: 0.7919\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2336 - accuracy: 0.7497 - val_loss: 0.2223 - val_accuracy: 0.7919\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2308 - accuracy: 0.7667 - val_loss: 0.2202 - val_accuracy: 0.7557\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2286 - accuracy: 0.7237 - val_loss: 0.2187 - val_accuracy: 0.7376\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2263 - accuracy: 0.6829 - val_loss: 0.2177 - val_accuracy: 0.7195\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2233 - accuracy: 0.7067 - val_loss: 0.2142 - val_accuracy: 0.7240\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2213 - accuracy: 0.7180 - val_loss: 0.2127 - val_accuracy: 0.7240\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2200 - accuracy: 0.6636 - val_loss: 0.2112 - val_accuracy: 0.7014\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2172 - accuracy: 0.6591 - val_loss: 0.2092 - val_accuracy: 0.7014\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2161 - accuracy: 0.6489 - val_loss: 0.2083 - val_accuracy: 0.6833\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2134 - accuracy: 0.6591 - val_loss: 0.2070 - val_accuracy: 0.6923\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2122 - accuracy: 0.6399 - val_loss: 0.2062 - val_accuracy: 0.6652\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2100 - accuracy: 0.6285 - val_loss: 0.2047 - val_accuracy: 0.6606\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2083 - accuracy: 0.6082 - val_loss: 0.2029 - val_accuracy: 0.6471\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2070 - accuracy: 0.6059 - val_loss: 0.2017 - val_accuracy: 0.6471\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2049 - accuracy: 0.5980 - val_loss: 0.2010 - val_accuracy: 0.6290\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2035 - accuracy: 0.5866 - val_loss: 0.2011 - val_accuracy: 0.6290\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2028 - accuracy: 0.5980 - val_loss: 0.1987 - val_accuracy: 0.6335\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2003 - accuracy: 0.5968 - val_loss: 0.1972 - val_accuracy: 0.6244\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1995 - accuracy: 0.5719 - val_loss: 0.1966 - val_accuracy: 0.6335\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1980 - accuracy: 0.5674 - val_loss: 0.1957 - val_accuracy: 0.6109\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1965 - accuracy: 0.5663 - val_loss: 0.1944 - val_accuracy: 0.6063\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1954 - accuracy: 0.5561 - val_loss: 0.1942 - val_accuracy: 0.6244\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1943 - accuracy: 0.5561 - val_loss: 0.1923 - val_accuracy: 0.6244\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1931 - accuracy: 0.5651 - val_loss: 0.1922 - val_accuracy: 0.5973\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1920 - accuracy: 0.5447 - val_loss: 0.1902 - val_accuracy: 0.5747\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1911 - accuracy: 0.5730 - val_loss: 0.1909 - val_accuracy: 0.6018\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1895 - accuracy: 0.5391 - val_loss: 0.1891 - val_accuracy: 0.5339\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 0.5357 - val_loss: 0.1892 - val_accuracy: 0.5701\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.5629 - val_loss: 0.1871 - val_accuracy: 0.5792\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1865 - accuracy: 0.5810 - val_loss: 0.1874 - val_accuracy: 0.5701\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.5481 - val_loss: 0.1866 - val_accuracy: 0.5747\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.5289 - val_loss: 0.1867 - val_accuracy: 0.5339\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1842 - accuracy: 0.5368 - val_loss: 0.1852 - val_accuracy: 0.5294\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.5379 - val_loss: 0.1841 - val_accuracy: 0.5475\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.5232 - val_loss: 0.1848 - val_accuracy: 0.5430\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1804 - accuracy: 0.5696 - val_loss: 0.1827 - val_accuracy: 0.5656\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1794 - accuracy: 0.5798 - val_loss: 0.1828 - val_accuracy: 0.5837\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1788 - accuracy: 0.6059 - val_loss: 0.1828 - val_accuracy: 0.5656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1784 - accuracy: 0.5753 - val_loss: 0.1822 - val_accuracy: 0.5837\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1777 - accuracy: 0.5832 - val_loss: 0.1816 - val_accuracy: 0.6063\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1773 - accuracy: 0.5810 - val_loss: 0.1812 - val_accuracy: 0.5611\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.5764 - val_loss: 0.1807 - val_accuracy: 0.5566\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.5674 - val_loss: 0.1796 - val_accuracy: 0.6290\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1743 - accuracy: 0.6014 - val_loss: 0.1805 - val_accuracy: 0.5430\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1743 - accuracy: 0.5730 - val_loss: 0.1802 - val_accuracy: 0.5837\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1738 - accuracy: 0.6138 - val_loss: 0.1789 - val_accuracy: 0.6244\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1729 - accuracy: 0.6002 - val_loss: 0.1784 - val_accuracy: 0.6018\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1720 - accuracy: 0.6036 - val_loss: 0.1791 - val_accuracy: 0.6018\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1712 - accuracy: 0.6104 - val_loss: 0.1779 - val_accuracy: 0.5973\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1708 - accuracy: 0.6025 - val_loss: 0.1774 - val_accuracy: 0.6109\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1706 - accuracy: 0.6172 - val_loss: 0.1764 - val_accuracy: 0.6063\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1695 - accuracy: 0.6138 - val_loss: 0.1766 - val_accuracy: 0.6199\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1691 - accuracy: 0.6104 - val_loss: 0.1765 - val_accuracy: 0.5973\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1687 - accuracy: 0.6036 - val_loss: 0.1760 - val_accuracy: 0.6154\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1683 - accuracy: 0.6195 - val_loss: 0.1762 - val_accuracy: 0.6290\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1678 - accuracy: 0.5934 - val_loss: 0.1759 - val_accuracy: 0.6109\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1671 - accuracy: 0.5968 - val_loss: 0.1754 - val_accuracy: 0.6063\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1675 - accuracy: 0.5980 - val_loss: 0.1769 - val_accuracy: 0.6199\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1664 - accuracy: 0.5957 - val_loss: 0.1742 - val_accuracy: 0.6516\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1664 - accuracy: 0.6421 - val_loss: 0.1753 - val_accuracy: 0.6244\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1654 - accuracy: 0.6002 - val_loss: 0.1758 - val_accuracy: 0.6018\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1646 - accuracy: 0.5821 - val_loss: 0.1754 - val_accuracy: 0.5656\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1641 - accuracy: 0.5980 - val_loss: 0.1752 - val_accuracy: 0.6063\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1635 - accuracy: 0.6319 - val_loss: 0.1741 - val_accuracy: 0.6335\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1638 - accuracy: 0.6014 - val_loss: 0.1741 - val_accuracy: 0.6109\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1642 - accuracy: 0.5912 - val_loss: 0.1738 - val_accuracy: 0.6787\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1633 - accuracy: 0.5878 - val_loss: 0.1748 - val_accuracy: 0.6018\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1623 - accuracy: 0.5844 - val_loss: 0.1743 - val_accuracy: 0.6063\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1627 - accuracy: 0.6138 - val_loss: 0.1739 - val_accuracy: 0.6199\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1615 - accuracy: 0.5798 - val_loss: 0.1738 - val_accuracy: 0.5973\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1612 - accuracy: 0.6025 - val_loss: 0.1742 - val_accuracy: 0.6290\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1613 - accuracy: 0.6025 - val_loss: 0.1749 - val_accuracy: 0.6018\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1611 - accuracy: 0.6059 - val_loss: 0.1749 - val_accuracy: 0.6471\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1610 - accuracy: 0.5900 - val_loss: 0.1740 - val_accuracy: 0.6561\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1602 - accuracy: 0.6297 - val_loss: 0.1728 - val_accuracy: 0.6154\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1605 - accuracy: 0.6240 - val_loss: 0.1734 - val_accuracy: 0.6471\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1596 - accuracy: 0.5912 - val_loss: 0.1749 - val_accuracy: 0.6109\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1588 - accuracy: 0.5934 - val_loss: 0.1747 - val_accuracy: 0.6154\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1594 - accuracy: 0.5923 - val_loss: 0.1748 - val_accuracy: 0.6335\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1591 - accuracy: 0.6036 - val_loss: 0.1730 - val_accuracy: 0.6335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22f12a8f610>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(x_train,y_train,epochs = 100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 947us/step - loss: 0.2077 - accuracy: 0.6232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.20768921077251434, 0.6231883764266968]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label: Recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                240       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 681\n",
      "Trainable params: 681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "mlp_recovered = tf.keras.Sequential([     tf.keras.Input(shape=(11,)),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(1,activation = 'softmax')])\n",
    "mlp_recovered.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_recovered.compile(optimizer='adam',\n",
    "              loss='BinaryCrossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.6988 - accuracy: 0.6195 - val_loss: 0.6746 - val_accuracy: 0.6516\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.6426 - accuracy: 0.6195 - val_loss: 0.6226 - val_accuracy: 0.6516\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5929 - accuracy: 0.6195 - val_loss: 0.5726 - val_accuracy: 0.6516\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.6195 - val_loss: 0.5270 - val_accuracy: 0.6516\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.6195 - val_loss: 0.4892 - val_accuracy: 0.6516\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.6195 - val_loss: 0.4587 - val_accuracy: 0.6516\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.6195 - val_loss: 0.4378 - val_accuracy: 0.6516\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.6195 - val_loss: 0.4197 - val_accuracy: 0.6516\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.6195 - val_loss: 0.4032 - val_accuracy: 0.6516\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3750 - accuracy: 0.6195 - val_loss: 0.3951 - val_accuracy: 0.6516\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.6195 - val_loss: 0.3822 - val_accuracy: 0.6516\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3534 - accuracy: 0.6195 - val_loss: 0.3748 - val_accuracy: 0.6516\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3444 - accuracy: 0.6195 - val_loss: 0.3669 - val_accuracy: 0.6516\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.6195 - val_loss: 0.3573 - val_accuracy: 0.6516\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.6195 - val_loss: 0.3484 - val_accuracy: 0.6516\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.6195 - val_loss: 0.3447 - val_accuracy: 0.6516\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.6195 - val_loss: 0.3385 - val_accuracy: 0.6516\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3096 - accuracy: 0.6195 - val_loss: 0.3330 - val_accuracy: 0.6516\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3014 - accuracy: 0.6195 - val_loss: 0.3244 - val_accuracy: 0.6516\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2958 - accuracy: 0.6195 - val_loss: 0.3211 - val_accuracy: 0.6516\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2914 - accuracy: 0.6195 - val_loss: 0.3151 - val_accuracy: 0.6516\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2855 - accuracy: 0.6195 - val_loss: 0.3106 - val_accuracy: 0.6516\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2807 - accuracy: 0.6195 - val_loss: 0.3043 - val_accuracy: 0.6516\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2734 - accuracy: 0.6195 - val_loss: 0.2985 - val_accuracy: 0.6516\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2693 - accuracy: 0.6195 - val_loss: 0.2923 - val_accuracy: 0.6516\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2635 - accuracy: 0.6195 - val_loss: 0.2851 - val_accuracy: 0.6516\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2591 - accuracy: 0.6195 - val_loss: 0.2842 - val_accuracy: 0.6516\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2544 - accuracy: 0.6195 - val_loss: 0.2781 - val_accuracy: 0.6516\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.6195 - val_loss: 0.2749 - val_accuracy: 0.6516\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2441 - accuracy: 0.6195 - val_loss: 0.2688 - val_accuracy: 0.6516\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2399 - accuracy: 0.6195 - val_loss: 0.2697 - val_accuracy: 0.6516\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2351 - accuracy: 0.6195 - val_loss: 0.2612 - val_accuracy: 0.6516\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2329 - accuracy: 0.6195 - val_loss: 0.2585 - val_accuracy: 0.6516\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2286 - accuracy: 0.6195 - val_loss: 0.2543 - val_accuracy: 0.6516\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2256 - accuracy: 0.6195 - val_loss: 0.2531 - val_accuracy: 0.6516\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2215 - accuracy: 0.6195 - val_loss: 0.2501 - val_accuracy: 0.6516\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2186 - accuracy: 0.6195 - val_loss: 0.2465 - val_accuracy: 0.6516\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2151 - accuracy: 0.6195 - val_loss: 0.2418 - val_accuracy: 0.6516\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2125 - accuracy: 0.6195 - val_loss: 0.2429 - val_accuracy: 0.6516\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2115 - accuracy: 0.6195 - val_loss: 0.2384 - val_accuracy: 0.6516\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2089 - accuracy: 0.6195 - val_loss: 0.2364 - val_accuracy: 0.6516\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2063 - accuracy: 0.6195 - val_loss: 0.2345 - val_accuracy: 0.6516\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2050 - accuracy: 0.6195 - val_loss: 0.2317 - val_accuracy: 0.6516\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2028 - accuracy: 0.6195 - val_loss: 0.2314 - val_accuracy: 0.6516\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2003 - accuracy: 0.6195 - val_loss: 0.2288 - val_accuracy: 0.6516\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1981 - accuracy: 0.6195 - val_loss: 0.2290 - val_accuracy: 0.6516\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1990 - accuracy: 0.6195 - val_loss: 0.2272 - val_accuracy: 0.6516\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1963 - accuracy: 0.6195 - val_loss: 0.2253 - val_accuracy: 0.6516\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1955 - accuracy: 0.6195 - val_loss: 0.2259 - val_accuracy: 0.6516\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.6195 - val_loss: 0.2241 - val_accuracy: 0.6516\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1916 - accuracy: 0.6195 - val_loss: 0.2228 - val_accuracy: 0.6516\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1901 - accuracy: 0.6195 - val_loss: 0.2237 - val_accuracy: 0.6516\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1896 - accuracy: 0.6195 - val_loss: 0.2211 - val_accuracy: 0.6516\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1867 - accuracy: 0.6195 - val_loss: 0.2213 - val_accuracy: 0.6516\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1863 - accuracy: 0.6195 - val_loss: 0.2205 - val_accuracy: 0.6516\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.6195 - val_loss: 0.2199 - val_accuracy: 0.6516\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.6195 - val_loss: 0.2213 - val_accuracy: 0.6516\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.6195 - val_loss: 0.2182 - val_accuracy: 0.6516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.6195 - val_loss: 0.2182 - val_accuracy: 0.6516\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.6195 - val_loss: 0.2167 - val_accuracy: 0.6516\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.6195 - val_loss: 0.2211 - val_accuracy: 0.6516\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1799 - accuracy: 0.6195 - val_loss: 0.2155 - val_accuracy: 0.6516\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1808 - accuracy: 0.6195 - val_loss: 0.2152 - val_accuracy: 0.6516\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.6195 - val_loss: 0.2175 - val_accuracy: 0.6516\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1787 - accuracy: 0.6195 - val_loss: 0.2196 - val_accuracy: 0.6516\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.6195 - val_loss: 0.2162 - val_accuracy: 0.6516\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1779 - accuracy: 0.6195 - val_loss: 0.2148 - val_accuracy: 0.6516\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1780 - accuracy: 0.6195 - val_loss: 0.2176 - val_accuracy: 0.6516\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1778 - accuracy: 0.6195 - val_loss: 0.2164 - val_accuracy: 0.6516\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1760 - accuracy: 0.6195 - val_loss: 0.2140 - val_accuracy: 0.6516\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1750 - accuracy: 0.6195 - val_loss: 0.2188 - val_accuracy: 0.6516\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.6195 - val_loss: 0.2151 - val_accuracy: 0.6516\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1761 - accuracy: 0.6195 - val_loss: 0.2156 - val_accuracy: 0.6516\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1726 - accuracy: 0.6195 - val_loss: 0.2140 - val_accuracy: 0.6516\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1734 - accuracy: 0.6195 - val_loss: 0.2153 - val_accuracy: 0.6516\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1734 - accuracy: 0.6195 - val_loss: 0.2166 - val_accuracy: 0.6516\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1716 - accuracy: 0.6195 - val_loss: 0.2153 - val_accuracy: 0.6516\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1725 - accuracy: 0.6195 - val_loss: 0.2160 - val_accuracy: 0.6516\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1706 - accuracy: 0.6195 - val_loss: 0.2142 - val_accuracy: 0.6516\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1715 - accuracy: 0.6195 - val_loss: 0.2170 - val_accuracy: 0.6516\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1717 - accuracy: 0.6195 - val_loss: 0.2163 - val_accuracy: 0.6516\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1702 - accuracy: 0.6195 - val_loss: 0.2168 - val_accuracy: 0.6516\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1712 - accuracy: 0.6195 - val_loss: 0.2161 - val_accuracy: 0.6516\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1704 - accuracy: 0.6195 - val_loss: 0.2153 - val_accuracy: 0.6516\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1694 - accuracy: 0.6195 - val_loss: 0.2117 - val_accuracy: 0.6516\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1685 - accuracy: 0.6195 - val_loss: 0.2180 - val_accuracy: 0.6516\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1694 - accuracy: 0.6195 - val_loss: 0.2188 - val_accuracy: 0.6516\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1687 - accuracy: 0.6195 - val_loss: 0.2160 - val_accuracy: 0.6516\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1700 - accuracy: 0.6195 - val_loss: 0.2184 - val_accuracy: 0.6516\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1679 - accuracy: 0.6195 - val_loss: 0.2169 - val_accuracy: 0.6516\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1679 - accuracy: 0.6195 - val_loss: 0.2163 - val_accuracy: 0.6516\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1682 - accuracy: 0.6195 - val_loss: 0.2182 - val_accuracy: 0.6516\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1677 - accuracy: 0.6195 - val_loss: 0.2197 - val_accuracy: 0.6516\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1672 - accuracy: 0.6195 - val_loss: 0.2145 - val_accuracy: 0.6516\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1679 - accuracy: 0.6195 - val_loss: 0.2183 - val_accuracy: 0.6516\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1668 - accuracy: 0.6195 - val_loss: 0.2152 - val_accuracy: 0.6516\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1662 - accuracy: 0.6195 - val_loss: 0.2181 - val_accuracy: 0.6516\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1670 - accuracy: 0.6195 - val_loss: 0.2156 - val_accuracy: 0.6516\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1649 - accuracy: 0.6195 - val_loss: 0.2139 - val_accuracy: 0.6516\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1655 - accuracy: 0.6195 - val_loss: 0.2178 - val_accuracy: 0.6516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22f1731a4c0>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_recovered.fit(x_train,y_train.iloc[:,-1],epochs = 100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1608 - accuracy: 0.6268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1607934683561325, 0.6268116235733032]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_recovered.evaluate(x_test,y_test.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label: Deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                240       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 681\n",
      "Trainable params: 681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "mlp_deaths = tf.keras.Sequential([     tf.keras.Input(shape=(11,)),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(1,activation = 'softmax')])\n",
    "mlp_deaths.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_deaths.compile(optimizer='adam',\n",
    "              loss='BinaryCrossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.4694 - accuracy: 0.9094 - val_loss: 0.4210 - val_accuracy: 0.9005\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3686 - accuracy: 0.9094 - val_loss: 0.3540 - val_accuracy: 0.9005\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3247 - accuracy: 0.9094 - val_loss: 0.3231 - val_accuracy: 0.9005\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3023 - accuracy: 0.9094 - val_loss: 0.3049 - val_accuracy: 0.9005\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 0.9094 - val_loss: 0.2922 - val_accuracy: 0.9005\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2747 - accuracy: 0.9094 - val_loss: 0.2819 - val_accuracy: 0.9005\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2642 - accuracy: 0.9094 - val_loss: 0.2751 - val_accuracy: 0.9005\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2558 - accuracy: 0.9094 - val_loss: 0.2695 - val_accuracy: 0.9005\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.9094 - val_loss: 0.2676 - val_accuracy: 0.9005\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.9094 - val_loss: 0.2638 - val_accuracy: 0.9005\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2391 - accuracy: 0.9094 - val_loss: 0.2610 - val_accuracy: 0.9005\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2359 - accuracy: 0.9094 - val_loss: 0.2598 - val_accuracy: 0.9005\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2319 - accuracy: 0.9094 - val_loss: 0.2566 - val_accuracy: 0.9005\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2289 - accuracy: 0.9094 - val_loss: 0.2568 - val_accuracy: 0.9005\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2266 - accuracy: 0.9094 - val_loss: 0.2545 - val_accuracy: 0.9005\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2235 - accuracy: 0.9094 - val_loss: 0.2530 - val_accuracy: 0.9005\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2210 - accuracy: 0.9094 - val_loss: 0.2523 - val_accuracy: 0.9005\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2190 - accuracy: 0.9094 - val_loss: 0.2534 - val_accuracy: 0.9005\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2175 - accuracy: 0.9094 - val_loss: 0.2511 - val_accuracy: 0.9005\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2164 - accuracy: 0.9094 - val_loss: 0.2520 - val_accuracy: 0.9005\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2145 - accuracy: 0.9094 - val_loss: 0.2517 - val_accuracy: 0.9005\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2127 - accuracy: 0.9094 - val_loss: 0.2506 - val_accuracy: 0.9005\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2113 - accuracy: 0.9094 - val_loss: 0.2509 - val_accuracy: 0.9005\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2098 - accuracy: 0.9094 - val_loss: 0.2498 - val_accuracy: 0.9005\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2089 - accuracy: 0.9094 - val_loss: 0.2496 - val_accuracy: 0.9005\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2071 - accuracy: 0.9094 - val_loss: 0.2495 - val_accuracy: 0.9005\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2081 - accuracy: 0.9094 - val_loss: 0.2517 - val_accuracy: 0.9005\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2064 - accuracy: 0.9094 - val_loss: 0.2494 - val_accuracy: 0.9005\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2051 - accuracy: 0.9094 - val_loss: 0.2514 - val_accuracy: 0.9005\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2043 - accuracy: 0.9094 - val_loss: 0.2494 - val_accuracy: 0.9005\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2028 - accuracy: 0.9094 - val_loss: 0.2501 - val_accuracy: 0.9005\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2020 - accuracy: 0.9094 - val_loss: 0.2508 - val_accuracy: 0.9005\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2022 - accuracy: 0.9094 - val_loss: 0.2492 - val_accuracy: 0.9005\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2019 - accuracy: 0.9094 - val_loss: 0.2514 - val_accuracy: 0.9005\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2017 - accuracy: 0.9094 - val_loss: 0.2495 - val_accuracy: 0.9005\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2000 - accuracy: 0.9094 - val_loss: 0.2494 - val_accuracy: 0.9005\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1992 - accuracy: 0.9094 - val_loss: 0.2507 - val_accuracy: 0.9005\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1977 - accuracy: 0.9094 - val_loss: 0.2503 - val_accuracy: 0.9005\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1995 - accuracy: 0.9094 - val_loss: 0.2505 - val_accuracy: 0.9005\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1982 - accuracy: 0.9094 - val_loss: 0.2509 - val_accuracy: 0.9005\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1964 - accuracy: 0.9094 - val_loss: 0.2497 - val_accuracy: 0.9005\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1962 - accuracy: 0.9094 - val_loss: 0.2504 - val_accuracy: 0.9005\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1960 - accuracy: 0.9094 - val_loss: 0.2496 - val_accuracy: 0.9005\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1964 - accuracy: 0.9094 - val_loss: 0.2501 - val_accuracy: 0.9005\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1947 - accuracy: 0.9094 - val_loss: 0.2513 - val_accuracy: 0.9005\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1941 - accuracy: 0.9094 - val_loss: 0.2499 - val_accuracy: 0.9005\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1957 - accuracy: 0.9094 - val_loss: 0.2518 - val_accuracy: 0.9005\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1944 - accuracy: 0.9094 - val_loss: 0.2498 - val_accuracy: 0.9005\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1933 - accuracy: 0.9094 - val_loss: 0.2503 - val_accuracy: 0.9005\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1934 - accuracy: 0.9094 - val_loss: 0.2514 - val_accuracy: 0.9005\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1947 - accuracy: 0.9094 - val_loss: 0.2499 - val_accuracy: 0.9005\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1916 - accuracy: 0.9094 - val_loss: 0.2512 - val_accuracy: 0.9005\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1925 - accuracy: 0.9094 - val_loss: 0.2510 - val_accuracy: 0.9005\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1911 - accuracy: 0.9094 - val_loss: 0.2520 - val_accuracy: 0.9005\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1912 - accuracy: 0.9094 - val_loss: 0.2523 - val_accuracy: 0.9005\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1910 - accuracy: 0.9094 - val_loss: 0.2502 - val_accuracy: 0.9005\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1913 - accuracy: 0.9094 - val_loss: 0.2526 - val_accuracy: 0.9005\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1899 - accuracy: 0.9094 - val_loss: 0.2506 - val_accuracy: 0.9005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1895 - accuracy: 0.9094 - val_loss: 0.2530 - val_accuracy: 0.9005\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1933 - accuracy: 0.9094 - val_loss: 0.2511 - val_accuracy: 0.9005\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1897 - accuracy: 0.9094 - val_loss: 0.2514 - val_accuracy: 0.9005\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1884 - accuracy: 0.9094 - val_loss: 0.2526 - val_accuracy: 0.9005\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1895 - accuracy: 0.9094 - val_loss: 0.2539 - val_accuracy: 0.9005\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1886 - accuracy: 0.9094 - val_loss: 0.2523 - val_accuracy: 0.9005\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1878 - accuracy: 0.9094 - val_loss: 0.2539 - val_accuracy: 0.9005\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1879 - accuracy: 0.9094 - val_loss: 0.2516 - val_accuracy: 0.9005\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.9094 - val_loss: 0.2522 - val_accuracy: 0.9005\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.9094 - val_loss: 0.2519 - val_accuracy: 0.9005\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1864 - accuracy: 0.9094 - val_loss: 0.2535 - val_accuracy: 0.9005\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 0.9094 - val_loss: 0.2539 - val_accuracy: 0.9005\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1858 - accuracy: 0.9094 - val_loss: 0.2530 - val_accuracy: 0.9005\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.9094 - val_loss: 0.2533 - val_accuracy: 0.9005\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.9094 - val_loss: 0.2542 - val_accuracy: 0.9005\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1861 - accuracy: 0.9094 - val_loss: 0.2558 - val_accuracy: 0.9005\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1847 - accuracy: 0.9094 - val_loss: 0.2533 - val_accuracy: 0.9005\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.9094 - val_loss: 0.2542 - val_accuracy: 0.9005\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.9094 - val_loss: 0.2540 - val_accuracy: 0.9005\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1838 - accuracy: 0.9094 - val_loss: 0.2545 - val_accuracy: 0.9005\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1855 - accuracy: 0.9094 - val_loss: 0.2543 - val_accuracy: 0.9005\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.9094 - val_loss: 0.2538 - val_accuracy: 0.9005\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1838 - accuracy: 0.9094 - val_loss: 0.2542 - val_accuracy: 0.9005\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.9094 - val_loss: 0.2549 - val_accuracy: 0.9005\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1836 - accuracy: 0.9094 - val_loss: 0.2556 - val_accuracy: 0.9005\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 0.9094 - val_loss: 0.2549 - val_accuracy: 0.9005\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.9094 - val_loss: 0.2576 - val_accuracy: 0.9005\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1844 - accuracy: 0.9094 - val_loss: 0.2554 - val_accuracy: 0.9005\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.9094 - val_loss: 0.2554 - val_accuracy: 0.9005\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.9094 - val_loss: 0.2561 - val_accuracy: 0.9005\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1826 - accuracy: 0.9094 - val_loss: 0.2562 - val_accuracy: 0.9005\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1813 - accuracy: 0.9094 - val_loss: 0.2563 - val_accuracy: 0.9005\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.9094 - val_loss: 0.2546 - val_accuracy: 0.9005\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1816 - accuracy: 0.9094 - val_loss: 0.2560 - val_accuracy: 0.9005\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.9094 - val_loss: 0.2570 - val_accuracy: 0.9005\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1843 - accuracy: 0.9094 - val_loss: 0.2553 - val_accuracy: 0.9005\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.9094 - val_loss: 0.2565 - val_accuracy: 0.9005\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1806 - accuracy: 0.9094 - val_loss: 0.2570 - val_accuracy: 0.9005\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.9094 - val_loss: 0.2570 - val_accuracy: 0.9005\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.9094 - val_loss: 0.2564 - val_accuracy: 0.9005\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1805 - accuracy: 0.9094 - val_loss: 0.2587 - val_accuracy: 0.9005\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1821 - accuracy: 0.9094 - val_loss: 0.2570 - val_accuracy: 0.9005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22f183f4bb0>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_deaths.fit(x_train,y_train.iloc[:,-2],epochs = 100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3055 - accuracy: 0.9493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30546361207962036, 0.9492753744125366]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_deaths.evaluate(x_test,y_test.iloc[:,:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_deaths.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label: Confirmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                240       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 681\n",
      "Trainable params: 681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "mlp_confirmed = tf.keras.Sequential([     tf.keras.Input(shape=(11,)),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(1,activation = 'softmax')])\n",
    "mlp_confirmed.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_confirmed.compile(optimizer='adam',\n",
    "              loss='BinaryCrossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3442 - accuracy: 0.9604 - val_loss: 0.2149 - val_accuracy: 0.9910\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2335 - accuracy: 0.9604 - val_loss: 0.1287 - val_accuracy: 0.9910\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1848 - accuracy: 0.9604 - val_loss: 0.0864 - val_accuracy: 0.9910\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1644 - accuracy: 0.9604 - val_loss: 0.0711 - val_accuracy: 0.9910\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1551 - accuracy: 0.9604 - val_loss: 0.0605 - val_accuracy: 0.9910\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1485 - accuracy: 0.9604 - val_loss: 0.0579 - val_accuracy: 0.9910\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1439 - accuracy: 0.9604 - val_loss: 0.0557 - val_accuracy: 0.9910\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1407 - accuracy: 0.9604 - val_loss: 0.0540 - val_accuracy: 0.9910\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1372 - accuracy: 0.9604 - val_loss: 0.0510 - val_accuracy: 0.9910\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1346 - accuracy: 0.9604 - val_loss: 0.0518 - val_accuracy: 0.9910\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1327 - accuracy: 0.9604 - val_loss: 0.0491 - val_accuracy: 0.9910\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1302 - accuracy: 0.9604 - val_loss: 0.0498 - val_accuracy: 0.9910\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1287 - accuracy: 0.9604 - val_loss: 0.0487 - val_accuracy: 0.9910\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1270 - accuracy: 0.9604 - val_loss: 0.0480 - val_accuracy: 0.9910\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1254 - accuracy: 0.9604 - val_loss: 0.0488 - val_accuracy: 0.9910\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1242 - accuracy: 0.9604 - val_loss: 0.0493 - val_accuracy: 0.9910\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1231 - accuracy: 0.9604 - val_loss: 0.0474 - val_accuracy: 0.9910\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1220 - accuracy: 0.9604 - val_loss: 0.0480 - val_accuracy: 0.9910\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1214 - accuracy: 0.9604 - val_loss: 0.0481 - val_accuracy: 0.9910\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1200 - accuracy: 0.9604 - val_loss: 0.0489 - val_accuracy: 0.9910\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1196 - accuracy: 0.9604 - val_loss: 0.0486 - val_accuracy: 0.9910\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1184 - accuracy: 0.9604 - val_loss: 0.0475 - val_accuracy: 0.9910\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1191 - accuracy: 0.9604 - val_loss: 0.0486 - val_accuracy: 0.9910\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1180 - accuracy: 0.9604 - val_loss: 0.0474 - val_accuracy: 0.9910\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1175 - accuracy: 0.9604 - val_loss: 0.0476 - val_accuracy: 0.9910\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1171 - accuracy: 0.9604 - val_loss: 0.0486 - val_accuracy: 0.9910\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1169 - accuracy: 0.9604 - val_loss: 0.0481 - val_accuracy: 0.9910\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1159 - accuracy: 0.9604 - val_loss: 0.0464 - val_accuracy: 0.9910\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1159 - accuracy: 0.9604 - val_loss: 0.0479 - val_accuracy: 0.9910\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1147 - accuracy: 0.9604 - val_loss: 0.0469 - val_accuracy: 0.9910\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1151 - accuracy: 0.9604 - val_loss: 0.0490 - val_accuracy: 0.9910\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1140 - accuracy: 0.9604 - val_loss: 0.0469 - val_accuracy: 0.9910\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1143 - accuracy: 0.9604 - val_loss: 0.0476 - val_accuracy: 0.9910\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1140 - accuracy: 0.9604 - val_loss: 0.0468 - val_accuracy: 0.9910\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1134 - accuracy: 0.9604 - val_loss: 0.0476 - val_accuracy: 0.9910\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1133 - accuracy: 0.9604 - val_loss: 0.0484 - val_accuracy: 0.9910\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1131 - accuracy: 0.9604 - val_loss: 0.0473 - val_accuracy: 0.9910\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1127 - accuracy: 0.9604 - val_loss: 0.0468 - val_accuracy: 0.9910\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1126 - accuracy: 0.9604 - val_loss: 0.0477 - val_accuracy: 0.9910\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1122 - accuracy: 0.9604 - val_loss: 0.0495 - val_accuracy: 0.9910\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1118 - accuracy: 0.9604 - val_loss: 0.0468 - val_accuracy: 0.9910\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1114 - accuracy: 0.9604 - val_loss: 0.0469 - val_accuracy: 0.9910\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1110 - accuracy: 0.9604 - val_loss: 0.0477 - val_accuracy: 0.9910\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1108 - accuracy: 0.9604 - val_loss: 0.0473 - val_accuracy: 0.9910\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1102 - accuracy: 0.9604 - val_loss: 0.0482 - val_accuracy: 0.9910\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1105 - accuracy: 0.9604 - val_loss: 0.0486 - val_accuracy: 0.9910\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1101 - accuracy: 0.9604 - val_loss: 0.0476 - val_accuracy: 0.9910\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.2204 - accuracy: 0.84 - 0s 2ms/step - loss: 0.1098 - accuracy: 0.9604 - val_loss: 0.0479 - val_accuracy: 0.9910\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1103 - accuracy: 0.9604 - val_loss: 0.0449 - val_accuracy: 0.9910\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1098 - accuracy: 0.9604 - val_loss: 0.0493 - val_accuracy: 0.9910\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1088 - accuracy: 0.9604 - val_loss: 0.0471 - val_accuracy: 0.9910\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1102 - accuracy: 0.9604 - val_loss: 0.0486 - val_accuracy: 0.9910\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1096 - accuracy: 0.9604 - val_loss: 0.0466 - val_accuracy: 0.9910\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1082 - accuracy: 0.9604 - val_loss: 0.0483 - val_accuracy: 0.9910\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1083 - accuracy: 0.9604 - val_loss: 0.0464 - val_accuracy: 0.9910\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1081 - accuracy: 0.9604 - val_loss: 0.0487 - val_accuracy: 0.9910\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1081 - accuracy: 0.9604 - val_loss: 0.0458 - val_accuracy: 0.9910\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1076 - accuracy: 0.9604 - val_loss: 0.0485 - val_accuracy: 0.9910\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1078 - accuracy: 0.9604 - val_loss: 0.0475 - val_accuracy: 0.9910\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1069 - accuracy: 0.9604 - val_loss: 0.0460 - val_accuracy: 0.9910\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1073 - accuracy: 0.9604 - val_loss: 0.0482 - val_accuracy: 0.9910\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1071 - accuracy: 0.9604 - val_loss: 0.0470 - val_accuracy: 0.9910\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1061 - accuracy: 0.9604 - val_loss: 0.0478 - val_accuracy: 0.9910\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1068 - accuracy: 0.9604 - val_loss: 0.0482 - val_accuracy: 0.9910\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1066 - accuracy: 0.9604 - val_loss: 0.0480 - val_accuracy: 0.9910\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1070 - accuracy: 0.9604 - val_loss: 0.0478 - val_accuracy: 0.9910\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1064 - accuracy: 0.9604 - val_loss: 0.0476 - val_accuracy: 0.9910\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1064 - accuracy: 0.9604 - val_loss: 0.0464 - val_accuracy: 0.9910\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9604 - val_loss: 0.0482 - val_accuracy: 0.9910\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1060 - accuracy: 0.9604 - val_loss: 0.0461 - val_accuracy: 0.9910\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1054 - accuracy: 0.9604 - val_loss: 0.0472 - val_accuracy: 0.9910\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1051 - accuracy: 0.9604 - val_loss: 0.0477 - val_accuracy: 0.9910\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.9604 - val_loss: 0.0449 - val_accuracy: 0.9910\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1052 - accuracy: 0.9604 - val_loss: 0.0483 - val_accuracy: 0.9910\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1048 - accuracy: 0.9604 - val_loss: 0.0475 - val_accuracy: 0.9910\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1044 - accuracy: 0.9604 - val_loss: 0.0448 - val_accuracy: 0.9910\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1040 - accuracy: 0.9604 - val_loss: 0.0463 - val_accuracy: 0.9910\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1055 - accuracy: 0.9604 - val_loss: 0.0465 - val_accuracy: 0.9910\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1042 - accuracy: 0.9604 - val_loss: 0.0480 - val_accuracy: 0.9910\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1037 - accuracy: 0.9604 - val_loss: 0.0463 - val_accuracy: 0.9910\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1047 - accuracy: 0.9604 - val_loss: 0.0476 - val_accuracy: 0.9910\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1040 - accuracy: 0.9604 - val_loss: 0.0473 - val_accuracy: 0.9910\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1046 - accuracy: 0.9604 - val_loss: 0.0455 - val_accuracy: 0.9910\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1033 - accuracy: 0.9604 - val_loss: 0.0482 - val_accuracy: 0.9910\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1029 - accuracy: 0.9604 - val_loss: 0.0452 - val_accuracy: 0.9910\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1044 - accuracy: 0.9604 - val_loss: 0.0472 - val_accuracy: 0.9910\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1034 - accuracy: 0.9604 - val_loss: 0.0455 - val_accuracy: 0.9910\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1020 - accuracy: 0.9604 - val_loss: 0.0480 - val_accuracy: 0.9910\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1030 - accuracy: 0.9604 - val_loss: 0.0477 - val_accuracy: 0.9910\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1030 - accuracy: 0.9604 - val_loss: 0.0481 - val_accuracy: 0.9910\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1024 - accuracy: 0.9604 - val_loss: 0.0476 - val_accuracy: 0.9910\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1027 - accuracy: 0.9604 - val_loss: 0.0463 - val_accuracy: 0.9910\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1020 - accuracy: 0.9604 - val_loss: 0.0448 - val_accuracy: 0.9910\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1019 - accuracy: 0.9604 - val_loss: 0.0477 - val_accuracy: 0.9910\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1025 - accuracy: 0.9604 - val_loss: 0.0473 - val_accuracy: 0.9910\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1018 - accuracy: 0.9604 - val_loss: 0.0453 - val_accuracy: 0.9910\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1017 - accuracy: 0.9604 - val_loss: 0.0479 - val_accuracy: 0.9910\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1014 - accuracy: 0.9604 - val_loss: 0.0482 - val_accuracy: 0.9910\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1014 - accuracy: 0.9604 - val_loss: 0.0443 - val_accuracy: 0.9910\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1011 - accuracy: 0.9604 - val_loss: 0.0474 - val_accuracy: 0.9910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22f18609820>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_confirmed.fit(x_train,y_train.iloc[:,-3],epochs = 100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 989us/step - loss: 0.1608 - accuracy: 0.9493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16078488528728485, 0.9492753744125366]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_confirmed.evaluate(x_test,y_test.iloc[:,-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_confirmed.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP on PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r pca_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ptrain,x_ptest,y_ptrain,y_ptest=train_test_split(pca_features[:,0:4],y,test_size = 0.2,random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                100       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 63        \n",
      "=================================================================\n",
      "Total params: 583\n",
      "Trainable params: 583\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "mlp_pca = tf.keras.Sequential([ tf.keras.Input(shape=(4,)),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(3,activation = 'softmax')])\n",
    "mlp_pca.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_pca.compile(optimizer='adam',\n",
    "              loss='BinaryCrossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.7081 - accuracy: 0.7350 - val_loss: 0.6439 - val_accuracy: 0.7376\n",
      "Epoch 2/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.6036 - accuracy: 0.6569 - val_loss: 0.5460 - val_accuracy: 0.6290\n",
      "Epoch 3/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.5798 - val_loss: 0.4620 - val_accuracy: 0.5882\n",
      "Epoch 4/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4389 - accuracy: 0.6353 - val_loss: 0.4008 - val_accuracy: 0.6244\n",
      "Epoch 5/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.6693 - val_loss: 0.3617 - val_accuracy: 0.6742\n",
      "Epoch 6/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.7123 - val_loss: 0.3387 - val_accuracy: 0.6923\n",
      "Epoch 7/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3490 - accuracy: 0.7293 - val_loss: 0.3207 - val_accuracy: 0.7059\n",
      "Epoch 8/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.7384 - val_loss: 0.3102 - val_accuracy: 0.7285\n",
      "Epoch 9/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8007 - val_loss: 0.3016 - val_accuracy: 0.7602\n",
      "Epoch 10/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.7905 - val_loss: 0.2959 - val_accuracy: 0.7602\n",
      "Epoch 11/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3196 - accuracy: 0.7780 - val_loss: 0.2926 - val_accuracy: 0.7466\n",
      "Epoch 12/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.7475 - val_loss: 0.2882 - val_accuracy: 0.6878\n",
      "Epoch 13/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.7418 - val_loss: 0.2841 - val_accuracy: 0.7149\n",
      "Epoch 14/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.7089 - val_loss: 0.2818 - val_accuracy: 0.6878\n",
      "Epoch 15/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3039 - accuracy: 0.6908 - val_loss: 0.2785 - val_accuracy: 0.6742\n",
      "Epoch 16/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3008 - accuracy: 0.6874 - val_loss: 0.2751 - val_accuracy: 0.6380\n",
      "Epoch 17/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2977 - accuracy: 0.6784 - val_loss: 0.2726 - val_accuracy: 0.6335\n",
      "Epoch 18/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2951 - accuracy: 0.6614 - val_loss: 0.2705 - val_accuracy: 0.6335\n",
      "Epoch 19/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2931 - accuracy: 0.6602 - val_loss: 0.2694 - val_accuracy: 0.6154\n",
      "Epoch 20/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2897 - accuracy: 0.6591 - val_loss: 0.2647 - val_accuracy: 0.6380\n",
      "Epoch 21/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2879 - accuracy: 0.6591 - val_loss: 0.2637 - val_accuracy: 0.6290\n",
      "Epoch 22/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2851 - accuracy: 0.6931 - val_loss: 0.2604 - val_accuracy: 0.6742\n",
      "Epoch 23/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2830 - accuracy: 0.6761 - val_loss: 0.2583 - val_accuracy: 0.6606\n",
      "Epoch 24/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2815 - accuracy: 0.7089 - val_loss: 0.2563 - val_accuracy: 0.6561\n",
      "Epoch 25/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2793 - accuracy: 0.6965 - val_loss: 0.2553 - val_accuracy: 0.6652\n",
      "Epoch 26/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2767 - accuracy: 0.6897 - val_loss: 0.2526 - val_accuracy: 0.6697\n",
      "Epoch 27/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2750 - accuracy: 0.7078 - val_loss: 0.2500 - val_accuracy: 0.6742\n",
      "Epoch 28/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2729 - accuracy: 0.6988 - val_loss: 0.2486 - val_accuracy: 0.6561\n",
      "Epoch 29/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2712 - accuracy: 0.7055 - val_loss: 0.2467 - val_accuracy: 0.6697\n",
      "Epoch 30/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2695 - accuracy: 0.6920 - val_loss: 0.2446 - val_accuracy: 0.6606\n",
      "Epoch 31/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.6874 - val_loss: 0.2431 - val_accuracy: 0.6697\n",
      "Epoch 32/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2664 - accuracy: 0.6954 - val_loss: 0.2419 - val_accuracy: 0.6923\n",
      "Epoch 33/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2650 - accuracy: 0.6942 - val_loss: 0.2408 - val_accuracy: 0.6742\n",
      "Epoch 34/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2642 - accuracy: 0.7044 - val_loss: 0.2403 - val_accuracy: 0.6652\n",
      "Epoch 35/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2632 - accuracy: 0.6761 - val_loss: 0.2397 - val_accuracy: 0.6697\n",
      "Epoch 36/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2617 - accuracy: 0.6795 - val_loss: 0.2367 - val_accuracy: 0.6923\n",
      "Epoch 37/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2610 - accuracy: 0.6954 - val_loss: 0.2372 - val_accuracy: 0.6878\n",
      "Epoch 38/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2598 - accuracy: 0.6874 - val_loss: 0.2357 - val_accuracy: 0.6923\n",
      "Epoch 39/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2590 - accuracy: 0.6829 - val_loss: 0.2351 - val_accuracy: 0.6697\n",
      "Epoch 40/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2571 - accuracy: 0.6750 - val_loss: 0.2328 - val_accuracy: 0.6878\n",
      "Epoch 41/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2574 - accuracy: 0.6659 - val_loss: 0.2334 - val_accuracy: 0.6516\n",
      "Epoch 42/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2560 - accuracy: 0.6580 - val_loss: 0.2340 - val_accuracy: 0.6471\n",
      "Epoch 43/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2554 - accuracy: 0.6602 - val_loss: 0.2335 - val_accuracy: 0.6516\n",
      "Epoch 44/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2548 - accuracy: 0.6625 - val_loss: 0.2306 - val_accuracy: 0.6471\n",
      "Epoch 45/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2539 - accuracy: 0.6535 - val_loss: 0.2326 - val_accuracy: 0.6425\n",
      "Epoch 46/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2525 - accuracy: 0.6591 - val_loss: 0.2295 - val_accuracy: 0.6425\n",
      "Epoch 47/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2523 - accuracy: 0.6580 - val_loss: 0.2293 - val_accuracy: 0.6380\n",
      "Epoch 48/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.6501 - val_loss: 0.2280 - val_accuracy: 0.6471\n",
      "Epoch 49/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.6512 - val_loss: 0.2284 - val_accuracy: 0.6380\n",
      "Epoch 50/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.6489 - val_loss: 0.2277 - val_accuracy: 0.6380\n",
      "Epoch 51/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.6478 - val_loss: 0.2263 - val_accuracy: 0.6425\n",
      "Epoch 52/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.6512 - val_loss: 0.2273 - val_accuracy: 0.6380\n",
      "Epoch 53/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2480 - accuracy: 0.6467 - val_loss: 0.2259 - val_accuracy: 0.6425\n",
      "Epoch 54/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.6467 - val_loss: 0.2262 - val_accuracy: 0.6380\n",
      "Epoch 55/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.6433 - val_loss: 0.2247 - val_accuracy: 0.6380\n",
      "Epoch 56/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.6444 - val_loss: 0.2259 - val_accuracy: 0.6380\n",
      "Epoch 57/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.6410 - val_loss: 0.2245 - val_accuracy: 0.6380\n",
      "Epoch 58/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.6353 - val_loss: 0.2232 - val_accuracy: 0.6380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6399 - val_loss: 0.2231 - val_accuracy: 0.6290\n",
      "Epoch 60/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.6376 - val_loss: 0.2229 - val_accuracy: 0.6290\n",
      "Epoch 61/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2434 - accuracy: 0.6421 - val_loss: 0.2226 - val_accuracy: 0.6290\n",
      "Epoch 62/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2423 - accuracy: 0.6399 - val_loss: 0.2216 - val_accuracy: 0.6380\n",
      "Epoch 63/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2423 - accuracy: 0.6376 - val_loss: 0.2212 - val_accuracy: 0.6290\n",
      "Epoch 64/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2422 - accuracy: 0.6319 - val_loss: 0.2216 - val_accuracy: 0.6335\n",
      "Epoch 65/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2414 - accuracy: 0.6376 - val_loss: 0.2225 - val_accuracy: 0.6244\n",
      "Epoch 66/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2409 - accuracy: 0.6376 - val_loss: 0.2208 - val_accuracy: 0.6290\n",
      "Epoch 67/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2398 - accuracy: 0.6478 - val_loss: 0.2196 - val_accuracy: 0.6425\n",
      "Epoch 68/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2395 - accuracy: 0.6433 - val_loss: 0.2209 - val_accuracy: 0.6335\n",
      "Epoch 69/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2390 - accuracy: 0.6455 - val_loss: 0.2193 - val_accuracy: 0.6471\n",
      "Epoch 70/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2381 - accuracy: 0.6455 - val_loss: 0.2188 - val_accuracy: 0.6561\n",
      "Epoch 71/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2379 - accuracy: 0.6501 - val_loss: 0.2188 - val_accuracy: 0.6516\n",
      "Epoch 72/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2376 - accuracy: 0.6410 - val_loss: 0.2178 - val_accuracy: 0.6290\n",
      "Epoch 73/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2368 - accuracy: 0.6455 - val_loss: 0.2173 - val_accuracy: 0.6516\n",
      "Epoch 74/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2365 - accuracy: 0.6546 - val_loss: 0.2164 - val_accuracy: 0.6606\n",
      "Epoch 75/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2362 - accuracy: 0.6523 - val_loss: 0.2182 - val_accuracy: 0.6561\n",
      "Epoch 76/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2358 - accuracy: 0.6478 - val_loss: 0.2149 - val_accuracy: 0.6471\n",
      "Epoch 77/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2353 - accuracy: 0.6467 - val_loss: 0.2180 - val_accuracy: 0.6516\n",
      "Epoch 78/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2351 - accuracy: 0.6387 - val_loss: 0.2149 - val_accuracy: 0.6471\n",
      "Epoch 79/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2344 - accuracy: 0.6523 - val_loss: 0.2150 - val_accuracy: 0.6471\n",
      "Epoch 80/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2335 - accuracy: 0.6501 - val_loss: 0.2159 - val_accuracy: 0.6335\n",
      "Epoch 81/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2330 - accuracy: 0.6489 - val_loss: 0.2145 - val_accuracy: 0.6335\n",
      "Epoch 82/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2328 - accuracy: 0.6489 - val_loss: 0.2147 - val_accuracy: 0.6425\n",
      "Epoch 83/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2321 - accuracy: 0.6535 - val_loss: 0.2139 - val_accuracy: 0.6425\n",
      "Epoch 84/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2316 - accuracy: 0.6410 - val_loss: 0.2123 - val_accuracy: 0.6425\n",
      "Epoch 85/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2314 - accuracy: 0.6535 - val_loss: 0.2130 - val_accuracy: 0.6652\n",
      "Epoch 86/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2309 - accuracy: 0.6433 - val_loss: 0.2122 - val_accuracy: 0.6335\n",
      "Epoch 87/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2308 - accuracy: 0.6331 - val_loss: 0.2128 - val_accuracy: 0.6380\n",
      "Epoch 88/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2303 - accuracy: 0.6444 - val_loss: 0.2123 - val_accuracy: 0.6335\n",
      "Epoch 89/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2295 - accuracy: 0.6489 - val_loss: 0.2119 - val_accuracy: 0.6335\n",
      "Epoch 90/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2291 - accuracy: 0.6591 - val_loss: 0.2115 - val_accuracy: 0.6697\n",
      "Epoch 91/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2288 - accuracy: 0.6501 - val_loss: 0.2106 - val_accuracy: 0.6425\n",
      "Epoch 92/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2283 - accuracy: 0.6535 - val_loss: 0.2105 - val_accuracy: 0.6516\n",
      "Epoch 93/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2279 - accuracy: 0.6636 - val_loss: 0.2107 - val_accuracy: 0.6652\n",
      "Epoch 94/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2280 - accuracy: 0.6625 - val_loss: 0.2116 - val_accuracy: 0.6380\n",
      "Epoch 95/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2280 - accuracy: 0.6512 - val_loss: 0.2105 - val_accuracy: 0.6697\n",
      "Epoch 96/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2267 - accuracy: 0.6557 - val_loss: 0.2076 - val_accuracy: 0.6742\n",
      "Epoch 97/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2262 - accuracy: 0.6501 - val_loss: 0.2101 - val_accuracy: 0.6697\n",
      "Epoch 98/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2261 - accuracy: 0.6512 - val_loss: 0.2094 - val_accuracy: 0.6652\n",
      "Epoch 99/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 0.6557 - val_loss: 0.2085 - val_accuracy: 0.6606\n",
      "Epoch 100/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2259 - accuracy: 0.6614 - val_loss: 0.2092 - val_accuracy: 0.6787\n",
      "Epoch 101/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2248 - accuracy: 0.6659 - val_loss: 0.2082 - val_accuracy: 0.6742\n",
      "Epoch 102/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2240 - accuracy: 0.6580 - val_loss: 0.2084 - val_accuracy: 0.6697\n",
      "Epoch 103/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2242 - accuracy: 0.6580 - val_loss: 0.2081 - val_accuracy: 0.6787\n",
      "Epoch 104/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2240 - accuracy: 0.6602 - val_loss: 0.2079 - val_accuracy: 0.6742\n",
      "Epoch 105/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2238 - accuracy: 0.6727 - val_loss: 0.2060 - val_accuracy: 0.6697\n",
      "Epoch 106/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2229 - accuracy: 0.6602 - val_loss: 0.2070 - val_accuracy: 0.6742\n",
      "Epoch 107/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2229 - accuracy: 0.6648 - val_loss: 0.2067 - val_accuracy: 0.6742\n",
      "Epoch 108/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2217 - accuracy: 0.6591 - val_loss: 0.2065 - val_accuracy: 0.6697\n",
      "Epoch 109/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2214 - accuracy: 0.6716 - val_loss: 0.2045 - val_accuracy: 0.6833\n",
      "Epoch 110/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2211 - accuracy: 0.6625 - val_loss: 0.2056 - val_accuracy: 0.6833\n",
      "Epoch 111/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.6682 - val_loss: 0.2058 - val_accuracy: 0.6833\n",
      "Epoch 112/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.6625 - val_loss: 0.2049 - val_accuracy: 0.6787\n",
      "Epoch 113/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2200 - accuracy: 0.6591 - val_loss: 0.2057 - val_accuracy: 0.6652\n",
      "Epoch 114/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2200 - accuracy: 0.6591 - val_loss: 0.2045 - val_accuracy: 0.6742\n",
      "Epoch 115/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2203 - accuracy: 0.6569 - val_loss: 0.2041 - val_accuracy: 0.6697\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2194 - accuracy: 0.6591 - val_loss: 0.2028 - val_accuracy: 0.6561\n",
      "Epoch 117/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2185 - accuracy: 0.6614 - val_loss: 0.2035 - val_accuracy: 0.6742\n",
      "Epoch 118/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2186 - accuracy: 0.6670 - val_loss: 0.2024 - val_accuracy: 0.6742\n",
      "Epoch 119/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2181 - accuracy: 0.6512 - val_loss: 0.2036 - val_accuracy: 0.6787\n",
      "Epoch 120/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2180 - accuracy: 0.6648 - val_loss: 0.2023 - val_accuracy: 0.6787\n",
      "Epoch 121/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2169 - accuracy: 0.6602 - val_loss: 0.2022 - val_accuracy: 0.6697\n",
      "Epoch 122/150\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.2311 - accuracy: 0.46 - 0s 1ms/step - loss: 0.2169 - accuracy: 0.6682 - val_loss: 0.2010 - val_accuracy: 0.6833\n",
      "Epoch 123/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.6580 - val_loss: 0.2012 - val_accuracy: 0.6787\n",
      "Epoch 124/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2164 - accuracy: 0.6569 - val_loss: 0.2014 - val_accuracy: 0.6154\n",
      "Epoch 125/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2163 - accuracy: 0.6331 - val_loss: 0.2026 - val_accuracy: 0.6606\n",
      "Epoch 126/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2155 - accuracy: 0.6478 - val_loss: 0.2009 - val_accuracy: 0.6290\n",
      "Epoch 127/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2156 - accuracy: 0.6535 - val_loss: 0.2014 - val_accuracy: 0.6425\n",
      "Epoch 128/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2158 - accuracy: 0.6467 - val_loss: 0.2006 - val_accuracy: 0.6652\n",
      "Epoch 129/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2146 - accuracy: 0.6557 - val_loss: 0.2022 - val_accuracy: 0.6652\n",
      "Epoch 130/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2153 - accuracy: 0.6319 - val_loss: 0.1995 - val_accuracy: 0.6244\n",
      "Epoch 131/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2143 - accuracy: 0.6240 - val_loss: 0.2006 - val_accuracy: 0.6697\n",
      "Epoch 132/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2146 - accuracy: 0.6297 - val_loss: 0.2007 - val_accuracy: 0.6290\n",
      "Epoch 133/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2145 - accuracy: 0.6149 - val_loss: 0.1994 - val_accuracy: 0.6697\n",
      "Epoch 134/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2142 - accuracy: 0.6625 - val_loss: 0.1998 - val_accuracy: 0.6154\n",
      "Epoch 135/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2131 - accuracy: 0.6229 - val_loss: 0.1997 - val_accuracy: 0.6471\n",
      "Epoch 136/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2135 - accuracy: 0.6229 - val_loss: 0.1993 - val_accuracy: 0.6335\n",
      "Epoch 137/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2133 - accuracy: 0.6206 - val_loss: 0.1977 - val_accuracy: 0.6109\n",
      "Epoch 138/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2130 - accuracy: 0.6082 - val_loss: 0.1998 - val_accuracy: 0.6471\n",
      "Epoch 139/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2125 - accuracy: 0.6048 - val_loss: 0.1987 - val_accuracy: 0.6154\n",
      "Epoch 140/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2121 - accuracy: 0.6070 - val_loss: 0.1995 - val_accuracy: 0.6199\n",
      "Epoch 141/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2123 - accuracy: 0.6274 - val_loss: 0.1960 - val_accuracy: 0.6199\n",
      "Epoch 142/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2122 - accuracy: 0.6217 - val_loss: 0.1978 - val_accuracy: 0.6109\n",
      "Epoch 143/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2112 - accuracy: 0.6127 - val_loss: 0.1970 - val_accuracy: 0.6154\n",
      "Epoch 144/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2102 - accuracy: 0.6059 - val_loss: 0.1988 - val_accuracy: 0.6290\n",
      "Epoch 145/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2102 - accuracy: 0.6206 - val_loss: 0.1963 - val_accuracy: 0.6199\n",
      "Epoch 146/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2095 - accuracy: 0.6070 - val_loss: 0.1964 - val_accuracy: 0.6199\n",
      "Epoch 147/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2104 - accuracy: 0.6161 - val_loss: 0.1970 - val_accuracy: 0.6290\n",
      "Epoch 148/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.6365 - val_loss: 0.1976 - val_accuracy: 0.6335\n",
      "Epoch 149/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2088 - accuracy: 0.6070 - val_loss: 0.1978 - val_accuracy: 0.6244\n",
      "Epoch 150/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2099 - accuracy: 0.6036 - val_loss: 0.1969 - val_accuracy: 0.6063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22f1974a400>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_pca.fit(x_ptrain,y_ptrain,epochs = 150,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label: Recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                100       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 541\n",
      "Trainable params: 541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "mlp_pca_recovered = tf.keras.Sequential([    tf.keras.Input(shape=(4,)),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(1,activation = 'softmax')])\n",
    "mlp_pca_recovered.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_pca_recovered.compile(optimizer='adam',\n",
    "              loss='BinaryCrossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.7099 - accuracy: 0.6195 - val_loss: 0.6771 - val_accuracy: 0.6516\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.6541 - accuracy: 0.6195 - val_loss: 0.6389 - val_accuracy: 0.6516\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.6154 - accuracy: 0.6195 - val_loss: 0.6101 - val_accuracy: 0.6516\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5832 - accuracy: 0.6195 - val_loss: 0.5830 - val_accuracy: 0.6516\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.6195 - val_loss: 0.5614 - val_accuracy: 0.6516\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5267 - accuracy: 0.6195 - val_loss: 0.5425 - val_accuracy: 0.6516\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4999 - accuracy: 0.6195 - val_loss: 0.5180 - val_accuracy: 0.6516\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.6195 - val_loss: 0.4962 - val_accuracy: 0.6516\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.6195 - val_loss: 0.4795 - val_accuracy: 0.6516\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.6195 - val_loss: 0.4649 - val_accuracy: 0.6516\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4209 - accuracy: 0.6195 - val_loss: 0.4508 - val_accuracy: 0.6516\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4097 - accuracy: 0.6195 - val_loss: 0.4411 - val_accuracy: 0.6516\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3990 - accuracy: 0.6195 - val_loss: 0.4292 - val_accuracy: 0.6516\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.6195 - val_loss: 0.4187 - val_accuracy: 0.6516\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3821 - accuracy: 0.6195 - val_loss: 0.4122 - val_accuracy: 0.6516\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3733 - accuracy: 0.6195 - val_loss: 0.4019 - val_accuracy: 0.6516\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3660 - accuracy: 0.6195 - val_loss: 0.3948 - val_accuracy: 0.6516\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3598 - accuracy: 0.6195 - val_loss: 0.3864 - val_accuracy: 0.6516\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.6195 - val_loss: 0.3801 - val_accuracy: 0.6516\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3484 - accuracy: 0.6195 - val_loss: 0.3750 - val_accuracy: 0.6516\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3438 - accuracy: 0.6195 - val_loss: 0.3688 - val_accuracy: 0.6516\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3401 - accuracy: 0.6195 - val_loss: 0.3659 - val_accuracy: 0.6516\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3356 - accuracy: 0.6195 - val_loss: 0.3610 - val_accuracy: 0.6516\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.6195 - val_loss: 0.3547 - val_accuracy: 0.6516\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.6195 - val_loss: 0.3514 - val_accuracy: 0.6516\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3261 - accuracy: 0.6195 - val_loss: 0.3499 - val_accuracy: 0.6516\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.6195 - val_loss: 0.3429 - val_accuracy: 0.6516\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.6195 - val_loss: 0.3434 - val_accuracy: 0.6516\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3201 - accuracy: 0.6195 - val_loss: 0.3363 - val_accuracy: 0.6516\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3161 - accuracy: 0.6195 - val_loss: 0.3362 - val_accuracy: 0.6516\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3132 - accuracy: 0.6195 - val_loss: 0.3317 - val_accuracy: 0.6516\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.6195 - val_loss: 0.3295 - val_accuracy: 0.6516\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.6195 - val_loss: 0.3259 - val_accuracy: 0.6516\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3073 - accuracy: 0.6195 - val_loss: 0.3291 - val_accuracy: 0.6516\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3041 - accuracy: 0.6195 - val_loss: 0.3217 - val_accuracy: 0.6516\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3020 - accuracy: 0.6195 - val_loss: 0.3170 - val_accuracy: 0.6516\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2998 - accuracy: 0.6195 - val_loss: 0.3174 - val_accuracy: 0.6516\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2980 - accuracy: 0.6195 - val_loss: 0.3152 - val_accuracy: 0.6516\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2961 - accuracy: 0.6195 - val_loss: 0.3134 - val_accuracy: 0.6516\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2948 - accuracy: 0.6195 - val_loss: 0.3111 - val_accuracy: 0.6516\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2920 - accuracy: 0.6195 - val_loss: 0.3094 - val_accuracy: 0.6516\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2916 - accuracy: 0.6195 - val_loss: 0.3084 - val_accuracy: 0.6516\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2889 - accuracy: 0.6195 - val_loss: 0.3067 - val_accuracy: 0.6516\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2877 - accuracy: 0.6195 - val_loss: 0.3019 - val_accuracy: 0.6516\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2856 - accuracy: 0.6195 - val_loss: 0.3024 - val_accuracy: 0.6516\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2829 - accuracy: 0.6195 - val_loss: 0.3002 - val_accuracy: 0.6516\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2829 - accuracy: 0.6195 - val_loss: 0.2997 - val_accuracy: 0.6516\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2808 - accuracy: 0.6195 - val_loss: 0.2955 - val_accuracy: 0.6516\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2800 - accuracy: 0.6195 - val_loss: 0.2953 - val_accuracy: 0.6516\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2783 - accuracy: 0.6195 - val_loss: 0.2936 - val_accuracy: 0.6516\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2762 - accuracy: 0.6195 - val_loss: 0.2943 - val_accuracy: 0.6516\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2763 - accuracy: 0.6195 - val_loss: 0.2916 - val_accuracy: 0.6516\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2769 - accuracy: 0.6195 - val_loss: 0.2924 - val_accuracy: 0.6516\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2719 - accuracy: 0.6195 - val_loss: 0.2900 - val_accuracy: 0.6516\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2718 - accuracy: 0.6195 - val_loss: 0.2886 - val_accuracy: 0.6516\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2705 - accuracy: 0.6195 - val_loss: 0.2869 - val_accuracy: 0.6516\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2706 - accuracy: 0.6195 - val_loss: 0.2852 - val_accuracy: 0.6516\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2676 - accuracy: 0.6195 - val_loss: 0.2886 - val_accuracy: 0.6516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2679 - accuracy: 0.6195 - val_loss: 0.2852 - val_accuracy: 0.6516\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2662 - accuracy: 0.6195 - val_loss: 0.2837 - val_accuracy: 0.6516\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2658 - accuracy: 0.6195 - val_loss: 0.2830 - val_accuracy: 0.6516\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2661 - accuracy: 0.6195 - val_loss: 0.2812 - val_accuracy: 0.6516\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2645 - accuracy: 0.6195 - val_loss: 0.2828 - val_accuracy: 0.6516\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2627 - accuracy: 0.6195 - val_loss: 0.2822 - val_accuracy: 0.6516\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2618 - accuracy: 0.6195 - val_loss: 0.2800 - val_accuracy: 0.6516\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2603 - accuracy: 0.6195 - val_loss: 0.2826 - val_accuracy: 0.6516\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2588 - accuracy: 0.6195 - val_loss: 0.2791 - val_accuracy: 0.6516\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.6195 - val_loss: 0.2794 - val_accuracy: 0.6516\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2574 - accuracy: 0.6195 - val_loss: 0.2770 - val_accuracy: 0.6516\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2556 - accuracy: 0.6195 - val_loss: 0.2761 - val_accuracy: 0.6516\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2547 - accuracy: 0.6195 - val_loss: 0.2760 - val_accuracy: 0.6516\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2581 - accuracy: 0.6195 - val_loss: 0.2801 - val_accuracy: 0.6516\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2547 - accuracy: 0.6195 - val_loss: 0.2729 - val_accuracy: 0.6516\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2536 - accuracy: 0.6195 - val_loss: 0.2730 - val_accuracy: 0.6516\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2536 - accuracy: 0.6195 - val_loss: 0.2731 - val_accuracy: 0.6516\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2510 - accuracy: 0.6195 - val_loss: 0.2714 - val_accuracy: 0.6516\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2500 - accuracy: 0.6195 - val_loss: 0.2712 - val_accuracy: 0.6516\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.6195 - val_loss: 0.2705 - val_accuracy: 0.6516\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.6195 - val_loss: 0.2711 - val_accuracy: 0.6516\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2484 - accuracy: 0.6195 - val_loss: 0.2693 - val_accuracy: 0.6516\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2477 - accuracy: 0.6195 - val_loss: 0.2674 - val_accuracy: 0.6516\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2489 - accuracy: 0.6195 - val_loss: 0.2697 - val_accuracy: 0.6516\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2474 - accuracy: 0.6195 - val_loss: 0.2689 - val_accuracy: 0.6516\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.6195 - val_loss: 0.2658 - val_accuracy: 0.6516\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2438 - accuracy: 0.6195 - val_loss: 0.2660 - val_accuracy: 0.6516\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2429 - accuracy: 0.6195 - val_loss: 0.2664 - val_accuracy: 0.6516\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2431 - accuracy: 0.6195 - val_loss: 0.2646 - val_accuracy: 0.6516\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2418 - accuracy: 0.6195 - val_loss: 0.2650 - val_accuracy: 0.6516\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2415 - accuracy: 0.6195 - val_loss: 0.2659 - val_accuracy: 0.6516\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2412 - accuracy: 0.6195 - val_loss: 0.2628 - val_accuracy: 0.6516\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2415 - accuracy: 0.6195 - val_loss: 0.2619 - val_accuracy: 0.6516\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2395 - accuracy: 0.6195 - val_loss: 0.2622 - val_accuracy: 0.6516\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2380 - accuracy: 0.6195 - val_loss: 0.2608 - val_accuracy: 0.6516\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2378 - accuracy: 0.6195 - val_loss: 0.2589 - val_accuracy: 0.6516\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2374 - accuracy: 0.6195 - val_loss: 0.2608 - val_accuracy: 0.6516\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2353 - accuracy: 0.6195 - val_loss: 0.2575 - val_accuracy: 0.6516\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2349 - accuracy: 0.6195 - val_loss: 0.2582 - val_accuracy: 0.6516\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2354 - accuracy: 0.6195 - val_loss: 0.2618 - val_accuracy: 0.6516\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 0.6195 - val_loss: 0.2577 - val_accuracy: 0.6516\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2332 - accuracy: 0.6195 - val_loss: 0.2555 - val_accuracy: 0.6516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22f1985e250>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_pca_recovered.fit(x_ptrain,y_ptrain.iloc[:,-1],epochs = 100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.6268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2453708052635193, 0.6268116235733032]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_pca_recovered.evaluate(x_ptest,y_ptest.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label: Deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                100       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 541\n",
      "Trainable params: 541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "mlp_pca_deaths = tf.keras.Sequential([     tf.keras.Input(shape=(4,)),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(1,activation = 'softmax')])\n",
    "mlp_pca_deaths.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_pca_deaths.compile(optimizer='adam',\n",
    "              loss='BinaryCrossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5367 - accuracy: 0.9094 - val_loss: 0.4971 - val_accuracy: 0.9005\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4508 - accuracy: 0.9094 - val_loss: 0.4307 - val_accuracy: 0.9005\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3920 - accuracy: 0.9094 - val_loss: 0.3725 - val_accuracy: 0.9005\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.9094 - val_loss: 0.3368 - val_accuracy: 0.9005\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 814us/step - loss: 0.3300 - accuracy: 0.9094 - val_loss: 0.3218 - val_accuracy: 0.9005\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.3190 - accuracy: 0.9094 - val_loss: 0.3091 - val_accuracy: 0.9005\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3106 - accuracy: 0.9094 - val_loss: 0.3035 - val_accuracy: 0.9005\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3055 - accuracy: 0.9094 - val_loss: 0.2975 - val_accuracy: 0.9005\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3011 - accuracy: 0.9094 - val_loss: 0.2941 - val_accuracy: 0.9005\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2963 - accuracy: 0.9094 - val_loss: 0.2886 - val_accuracy: 0.9005\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2929 - accuracy: 0.9094 - val_loss: 0.2861 - val_accuracy: 0.9005\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2900 - accuracy: 0.9094 - val_loss: 0.2824 - val_accuracy: 0.9005\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.2879 - accuracy: 0.9094 - val_loss: 0.2796 - val_accuracy: 0.9005\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2839 - accuracy: 0.9094 - val_loss: 0.2780 - val_accuracy: 0.9005\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2804 - accuracy: 0.9094 - val_loss: 0.2758 - val_accuracy: 0.9005\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2782 - accuracy: 0.9094 - val_loss: 0.2750 - val_accuracy: 0.9005\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 983us/step - loss: 0.2757 - accuracy: 0.9094 - val_loss: 0.2726 - val_accuracy: 0.9005\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2731 - accuracy: 0.9094 - val_loss: 0.2715 - val_accuracy: 0.9005\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2708 - accuracy: 0.9094 - val_loss: 0.2688 - val_accuracy: 0.9005\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2680 - accuracy: 0.9094 - val_loss: 0.2683 - val_accuracy: 0.9005\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2667 - accuracy: 0.9094 - val_loss: 0.2679 - val_accuracy: 0.9005\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.2188 - accuracy: 0.93 - 0s 1ms/step - loss: 0.2655 - accuracy: 0.9094 - val_loss: 0.2670 - val_accuracy: 0.9005\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 966us/step - loss: 0.2623 - accuracy: 0.9094 - val_loss: 0.2679 - val_accuracy: 0.9005\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.9094 - val_loss: 0.2641 - val_accuracy: 0.9005\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2575 - accuracy: 0.9094 - val_loss: 0.2636 - val_accuracy: 0.9005\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2561 - accuracy: 0.9094 - val_loss: 0.2618 - val_accuracy: 0.9005\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.2563 - accuracy: 0.9094 - val_loss: 0.2606 - val_accuracy: 0.9005\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 980us/step - loss: 0.2536 - accuracy: 0.9094 - val_loss: 0.2607 - val_accuracy: 0.9005\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 971us/step - loss: 0.2517 - accuracy: 0.9094 - val_loss: 0.2593 - val_accuracy: 0.9005\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.2502 - accuracy: 0.9094 - val_loss: 0.2612 - val_accuracy: 0.9005\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2486 - accuracy: 0.9094 - val_loss: 0.2592 - val_accuracy: 0.9005\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.9094 - val_loss: 0.2587 - val_accuracy: 0.9005\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.9094 - val_loss: 0.2575 - val_accuracy: 0.9005\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.9094 - val_loss: 0.2585 - val_accuracy: 0.9005\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2440 - accuracy: 0.9094 - val_loss: 0.2574 - val_accuracy: 0.9005\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2423 - accuracy: 0.9094 - val_loss: 0.2578 - val_accuracy: 0.9005\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2422 - accuracy: 0.9094 - val_loss: 0.2572 - val_accuracy: 0.9005\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2395 - accuracy: 0.9094 - val_loss: 0.2569 - val_accuracy: 0.9005\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2397 - accuracy: 0.9094 - val_loss: 0.2560 - val_accuracy: 0.9005\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2387 - accuracy: 0.9094 - val_loss: 0.2574 - val_accuracy: 0.9005\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2394 - accuracy: 0.9094 - val_loss: 0.2580 - val_accuracy: 0.9005\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2384 - accuracy: 0.9094 - val_loss: 0.2561 - val_accuracy: 0.9005\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2355 - accuracy: 0.9094 - val_loss: 0.2563 - val_accuracy: 0.9005\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2350 - accuracy: 0.9094 - val_loss: 0.2555 - val_accuracy: 0.9005\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 0.9094 - val_loss: 0.2565 - val_accuracy: 0.9005\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 0.9094 - val_loss: 0.2567 - val_accuracy: 0.9005\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2326 - accuracy: 0.9094 - val_loss: 0.2564 - val_accuracy: 0.9005\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2327 - accuracy: 0.9094 - val_loss: 0.2560 - val_accuracy: 0.9005\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2335 - accuracy: 0.9094 - val_loss: 0.2557 - val_accuracy: 0.9005\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2312 - accuracy: 0.9094 - val_loss: 0.2576 - val_accuracy: 0.9005\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2322 - accuracy: 0.9094 - val_loss: 0.2558 - val_accuracy: 0.9005\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2321 - accuracy: 0.9094 - val_loss: 0.2629 - val_accuracy: 0.9005\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2325 - accuracy: 0.9094 - val_loss: 0.2546 - val_accuracy: 0.9005\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2286 - accuracy: 0.9094 - val_loss: 0.2561 - val_accuracy: 0.9005\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2296 - accuracy: 0.9094 - val_loss: 0.2556 - val_accuracy: 0.9005\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2283 - accuracy: 0.9094 - val_loss: 0.2552 - val_accuracy: 0.9005\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2273 - accuracy: 0.9094 - val_loss: 0.2568 - val_accuracy: 0.9005\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2260 - accuracy: 0.9094 - val_loss: 0.2536 - val_accuracy: 0.9005\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2265 - accuracy: 0.9094 - val_loss: 0.2538 - val_accuracy: 0.9005\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2251 - accuracy: 0.9094 - val_loss: 0.2554 - val_accuracy: 0.9005\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2262 - accuracy: 0.9094 - val_loss: 0.2560 - val_accuracy: 0.9005\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2268 - accuracy: 0.9094 - val_loss: 0.2548 - val_accuracy: 0.9005\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2252 - accuracy: 0.9094 - val_loss: 0.2555 - val_accuracy: 0.9005\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2234 - accuracy: 0.9094 - val_loss: 0.2547 - val_accuracy: 0.9005\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2248 - accuracy: 0.9094 - val_loss: 0.2537 - val_accuracy: 0.9005\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2243 - accuracy: 0.9094 - val_loss: 0.2563 - val_accuracy: 0.9005\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2222 - accuracy: 0.9094 - val_loss: 0.2543 - val_accuracy: 0.9005\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2221 - accuracy: 0.9094 - val_loss: 0.2548 - val_accuracy: 0.9005\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2222 - accuracy: 0.9094 - val_loss: 0.2541 - val_accuracy: 0.9005\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2216 - accuracy: 0.9094 - val_loss: 0.2537 - val_accuracy: 0.9005\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2215 - accuracy: 0.9094 - val_loss: 0.2565 - val_accuracy: 0.9005\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2208 - accuracy: 0.9094 - val_loss: 0.2543 - val_accuracy: 0.9005\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2200 - accuracy: 0.9094 - val_loss: 0.2534 - val_accuracy: 0.9005\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2213 - accuracy: 0.9094 - val_loss: 0.2545 - val_accuracy: 0.9005\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2210 - accuracy: 0.9094 - val_loss: 0.2536 - val_accuracy: 0.9005\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2224 - accuracy: 0.9094 - val_loss: 0.2527 - val_accuracy: 0.9005\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2191 - accuracy: 0.9094 - val_loss: 0.2565 - val_accuracy: 0.9005\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2191 - accuracy: 0.9094 - val_loss: 0.2541 - val_accuracy: 0.9005\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2180 - accuracy: 0.9094 - val_loss: 0.2542 - val_accuracy: 0.9005\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2169 - accuracy: 0.9094 - val_loss: 0.2539 - val_accuracy: 0.9005\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2167 - accuracy: 0.9094 - val_loss: 0.2528 - val_accuracy: 0.9005\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2180 - accuracy: 0.9094 - val_loss: 0.2548 - val_accuracy: 0.9005\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2169 - accuracy: 0.9094 - val_loss: 0.2539 - val_accuracy: 0.9005\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.2170 - accuracy: 0.9094 - val_loss: 0.2552 - val_accuracy: 0.9005\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2168 - accuracy: 0.9094 - val_loss: 0.2537 - val_accuracy: 0.9005\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2152 - accuracy: 0.9094 - val_loss: 0.2561 - val_accuracy: 0.9005\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2165 - accuracy: 0.9094 - val_loss: 0.2561 - val_accuracy: 0.9005\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2183 - accuracy: 0.9094 - val_loss: 0.2541 - val_accuracy: 0.9005\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2144 - accuracy: 0.9094 - val_loss: 0.2535 - val_accuracy: 0.9005\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2151 - accuracy: 0.9094 - val_loss: 0.2531 - val_accuracy: 0.9005\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2140 - accuracy: 0.9094 - val_loss: 0.2539 - val_accuracy: 0.9005\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2143 - accuracy: 0.9094 - val_loss: 0.2536 - val_accuracy: 0.9005\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2161 - accuracy: 0.9094 - val_loss: 0.2535 - val_accuracy: 0.9005\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2138 - accuracy: 0.9094 - val_loss: 0.2531 - val_accuracy: 0.9005\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2130 - accuracy: 0.9094 - val_loss: 0.2547 - val_accuracy: 0.9005\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2147 - accuracy: 0.9094 - val_loss: 0.2549 - val_accuracy: 0.9005\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2132 - accuracy: 0.9094 - val_loss: 0.2544 - val_accuracy: 0.9005\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2140 - accuracy: 0.9094 - val_loss: 0.2553 - val_accuracy: 0.9005\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2124 - accuracy: 0.9094 - val_loss: 0.2561 - val_accuracy: 0.9005\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2130 - accuracy: 0.9094 - val_loss: 0.2524 - val_accuracy: 0.9005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22f1a9d9130>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_pca_deaths.fit(x_ptrain,y_ptrain.iloc[:,-2],epochs = 100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 667us/step - loss: 0.2718 - accuracy: 0.9493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.27184930443763733, 0.9492753744125366]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_pca_deaths.evaluate(x_ptest,y_ptest.iloc[:,:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label: Confirmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                100       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 541\n",
      "Trainable params: 541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "mlp_pca_confirmed = tf.keras.Sequential([     tf.keras.Input(shape=(4,)),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(1,activation = 'softmax')])\n",
    "mlp_pca_confirmed.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_pca_confirmed.compile(optimizer='adam',\n",
    "              loss='BinaryCrossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28/28 [==============================] - 1s 4ms/step - loss: 0.6044 - accuracy: 0.9604 - val_loss: 0.4472 - val_accuracy: 0.9910\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3918 - accuracy: 0.9604 - val_loss: 0.2627 - val_accuracy: 0.9910\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2622 - accuracy: 0.9604 - val_loss: 0.1543 - val_accuracy: 0.9910\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.9604 - val_loss: 0.1053 - val_accuracy: 0.9910\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1745 - accuracy: 0.9604 - val_loss: 0.0845 - val_accuracy: 0.9910\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1655 - accuracy: 0.9604 - val_loss: 0.0727 - val_accuracy: 0.9910\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1604 - accuracy: 0.9604 - val_loss: 0.0686 - val_accuracy: 0.9910\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1571 - accuracy: 0.9604 - val_loss: 0.0645 - val_accuracy: 0.9910\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1546 - accuracy: 0.9604 - val_loss: 0.0618 - val_accuracy: 0.9910\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1521 - accuracy: 0.9604 - val_loss: 0.0592 - val_accuracy: 0.9910\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1504 - accuracy: 0.9604 - val_loss: 0.0593 - val_accuracy: 0.9910\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1487 - accuracy: 0.9604 - val_loss: 0.0575 - val_accuracy: 0.9910\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1472 - accuracy: 0.9604 - val_loss: 0.0566 - val_accuracy: 0.9910\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1463 - accuracy: 0.9604 - val_loss: 0.0562 - val_accuracy: 0.9910\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1444 - accuracy: 0.9604 - val_loss: 0.0547 - val_accuracy: 0.9910\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1432 - accuracy: 0.9604 - val_loss: 0.0526 - val_accuracy: 0.9910\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1422 - accuracy: 0.9604 - val_loss: 0.0522 - val_accuracy: 0.9910\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1414 - accuracy: 0.9604 - val_loss: 0.0543 - val_accuracy: 0.9910\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1402 - accuracy: 0.9604 - val_loss: 0.0530 - val_accuracy: 0.9910\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1393 - accuracy: 0.9604 - val_loss: 0.0517 - val_accuracy: 0.9910\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1386 - accuracy: 0.9604 - val_loss: 0.0519 - val_accuracy: 0.9910\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1375 - accuracy: 0.9604 - val_loss: 0.0518 - val_accuracy: 0.9910\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1367 - accuracy: 0.9604 - val_loss: 0.0508 - val_accuracy: 0.9910\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1359 - accuracy: 0.9604 - val_loss: 0.0507 - val_accuracy: 0.9910\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1355 - accuracy: 0.9604 - val_loss: 0.0496 - val_accuracy: 0.9910\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1352 - accuracy: 0.9604 - val_loss: 0.0514 - val_accuracy: 0.9910\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1344 - accuracy: 0.9604 - val_loss: 0.0490 - val_accuracy: 0.9910\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1337 - accuracy: 0.9604 - val_loss: 0.0508 - val_accuracy: 0.9910\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1336 - accuracy: 0.9604 - val_loss: 0.0496 - val_accuracy: 0.9910\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1330 - accuracy: 0.9604 - val_loss: 0.0492 - val_accuracy: 0.9910\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1326 - accuracy: 0.9604 - val_loss: 0.0511 - val_accuracy: 0.9910\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1319 - accuracy: 0.9604 - val_loss: 0.0499 - val_accuracy: 0.9910\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1315 - accuracy: 0.9604 - val_loss: 0.0494 - val_accuracy: 0.9910\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1309 - accuracy: 0.9604 - val_loss: 0.0498 - val_accuracy: 0.9910\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1306 - accuracy: 0.9604 - val_loss: 0.0485 - val_accuracy: 0.9910\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1303 - accuracy: 0.9604 - val_loss: 0.0479 - val_accuracy: 0.9910\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1298 - accuracy: 0.9604 - val_loss: 0.0491 - val_accuracy: 0.9910\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1295 - accuracy: 0.9604 - val_loss: 0.0500 - val_accuracy: 0.9910\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1291 - accuracy: 0.9604 - val_loss: 0.0501 - val_accuracy: 0.9910\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1288 - accuracy: 0.9604 - val_loss: 0.0490 - val_accuracy: 0.9910\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1290 - accuracy: 0.9604 - val_loss: 0.0500 - val_accuracy: 0.9910\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1288 - accuracy: 0.9604 - val_loss: 0.0479 - val_accuracy: 0.9910\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1282 - accuracy: 0.9604 - val_loss: 0.0508 - val_accuracy: 0.9910\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1279 - accuracy: 0.9604 - val_loss: 0.0494 - val_accuracy: 0.9910\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1273 - accuracy: 0.9604 - val_loss: 0.0519 - val_accuracy: 0.9910\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1267 - accuracy: 0.9604 - val_loss: 0.0479 - val_accuracy: 0.9910\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1270 - accuracy: 0.9604 - val_loss: 0.0495 - val_accuracy: 0.9910\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1266 - accuracy: 0.9604 - val_loss: 0.0488 - val_accuracy: 0.9910\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1264 - accuracy: 0.9604 - val_loss: 0.0467 - val_accuracy: 0.9910\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1267 - accuracy: 0.9604 - val_loss: 0.0476 - val_accuracy: 0.9910\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1255 - accuracy: 0.9604 - val_loss: 0.0524 - val_accuracy: 0.9910\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1253 - accuracy: 0.9604 - val_loss: 0.0486 - val_accuracy: 0.9910\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1252 - accuracy: 0.9604 - val_loss: 0.0487 - val_accuracy: 0.9910\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1252 - accuracy: 0.9604 - val_loss: 0.0513 - val_accuracy: 0.9910\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1241 - accuracy: 0.9604 - val_loss: 0.0474 - val_accuracy: 0.9910\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1247 - accuracy: 0.9604 - val_loss: 0.0476 - val_accuracy: 0.9910\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1250 - accuracy: 0.9604 - val_loss: 0.0493 - val_accuracy: 0.9910\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1239 - accuracy: 0.9604 - val_loss: 0.0484 - val_accuracy: 0.9910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1233 - accuracy: 0.9604 - val_loss: 0.0500 - val_accuracy: 0.9910\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1230 - accuracy: 0.9604 - val_loss: 0.0494 - val_accuracy: 0.9910\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1229 - accuracy: 0.9604 - val_loss: 0.0501 - val_accuracy: 0.9910\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1229 - accuracy: 0.9604 - val_loss: 0.0502 - val_accuracy: 0.9910\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1229 - accuracy: 0.9604 - val_loss: 0.0482 - val_accuracy: 0.9910\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1222 - accuracy: 0.9604 - val_loss: 0.0492 - val_accuracy: 0.9910\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1221 - accuracy: 0.9604 - val_loss: 0.0501 - val_accuracy: 0.9910\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1221 - accuracy: 0.9604 - val_loss: 0.0467 - val_accuracy: 0.9910\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1221 - accuracy: 0.9604 - val_loss: 0.0499 - val_accuracy: 0.9910\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1213 - accuracy: 0.9604 - val_loss: 0.0473 - val_accuracy: 0.9910\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1225 - accuracy: 0.9604 - val_loss: 0.0478 - val_accuracy: 0.9910\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1225 - accuracy: 0.9604 - val_loss: 0.0513 - val_accuracy: 0.9910\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1210 - accuracy: 0.9604 - val_loss: 0.0473 - val_accuracy: 0.9910\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1206 - accuracy: 0.9604 - val_loss: 0.0490 - val_accuracy: 0.9910\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1211 - accuracy: 0.9604 - val_loss: 0.0460 - val_accuracy: 0.9910\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1207 - accuracy: 0.9604 - val_loss: 0.0490 - val_accuracy: 0.9910\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1201 - accuracy: 0.9604 - val_loss: 0.0498 - val_accuracy: 0.9910\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1204 - accuracy: 0.9604 - val_loss: 0.0500 - val_accuracy: 0.9910\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1204 - accuracy: 0.9604 - val_loss: 0.0489 - val_accuracy: 0.9910\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1199 - accuracy: 0.9604 - val_loss: 0.0504 - val_accuracy: 0.9910\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1200 - accuracy: 0.9604 - val_loss: 0.0491 - val_accuracy: 0.9910\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1199 - accuracy: 0.9604 - val_loss: 0.0494 - val_accuracy: 0.9910\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1200 - accuracy: 0.9604 - val_loss: 0.0480 - val_accuracy: 0.9910\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1192 - accuracy: 0.9604 - val_loss: 0.0497 - val_accuracy: 0.9910\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1189 - accuracy: 0.9604 - val_loss: 0.0478 - val_accuracy: 0.9910\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1194 - accuracy: 0.9604 - val_loss: 0.0482 - val_accuracy: 0.9910\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1190 - accuracy: 0.9604 - val_loss: 0.0520 - val_accuracy: 0.9910\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1184 - accuracy: 0.9604 - val_loss: 0.0471 - val_accuracy: 0.9910\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1188 - accuracy: 0.9604 - val_loss: 0.0490 - val_accuracy: 0.9910\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1185 - accuracy: 0.9604 - val_loss: 0.0488 - val_accuracy: 0.9910\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1185 - accuracy: 0.9604 - val_loss: 0.0495 - val_accuracy: 0.9910\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1185 - accuracy: 0.9604 - val_loss: 0.0495 - val_accuracy: 0.9910\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1178 - accuracy: 0.9604 - val_loss: 0.0499 - val_accuracy: 0.9910\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1184 - accuracy: 0.9604 - val_loss: 0.0473 - val_accuracy: 0.9910\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1177 - accuracy: 0.9604 - val_loss: 0.0501 - val_accuracy: 0.9910\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1177 - accuracy: 0.9604 - val_loss: 0.0498 - val_accuracy: 0.9910\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1180 - accuracy: 0.9604 - val_loss: 0.0492 - val_accuracy: 0.9910\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1185 - accuracy: 0.9604 - val_loss: 0.0499 - val_accuracy: 0.9910\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1176 - accuracy: 0.9604 - val_loss: 0.0478 - val_accuracy: 0.9910\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1172 - accuracy: 0.9604 - val_loss: 0.0493 - val_accuracy: 0.9910\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1168 - accuracy: 0.9604 - val_loss: 0.0490 - val_accuracy: 0.9910\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1172 - accuracy: 0.9604 - val_loss: 0.0472 - val_accuracy: 0.9910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22f1bb37e50>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_pca_confirmed.fit(x_ptrain,y_ptrain.iloc[:,-3],epochs = 100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1676 - accuracy: 0.9493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1676435023546219, 0.9492753744125366]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_pca_confirmed.evaluate(x_ptest,y_ptest.iloc[:,-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
