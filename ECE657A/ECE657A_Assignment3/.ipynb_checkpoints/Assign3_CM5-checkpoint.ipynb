{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CM[5] Kaggle Competition Group38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dkmacovid_kaggletest_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Day</th>\n",
       "      <th>State ID</th>\n",
       "      <th>State</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Active</th>\n",
       "      <th>Incident_Rate</th>\n",
       "      <th>Total_Test_Results</th>\n",
       "      <th>Case_Fatality_Ratio</th>\n",
       "      <th>Testing_Rate</th>\n",
       "      <th>Resident Population 2020 Census</th>\n",
       "      <th>Population Density 2020 Census</th>\n",
       "      <th>Density Rank 2020 Census</th>\n",
       "      <th>SexRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>40.3495</td>\n",
       "      <td>-88.9861</td>\n",
       "      <td>957138</td>\n",
       "      <td>7697.015291</td>\n",
       "      <td>13436652</td>\n",
       "      <td>1.867428</td>\n",
       "      <td>106035.6834</td>\n",
       "      <td>12,812,508</td>\n",
       "      <td>230.8</td>\n",
       "      <td>14</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>40.3495</td>\n",
       "      <td>-88.9861</td>\n",
       "      <td>961499</td>\n",
       "      <td>7732.282519</td>\n",
       "      <td>13482117</td>\n",
       "      <td>1.869933</td>\n",
       "      <td>106394.4716</td>\n",
       "      <td>12,812,508</td>\n",
       "      <td>230.8</td>\n",
       "      <td>14</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>40.3495</td>\n",
       "      <td>-88.9861</td>\n",
       "      <td>966468</td>\n",
       "      <td>7772.205747</td>\n",
       "      <td>13530371</td>\n",
       "      <td>1.869466</td>\n",
       "      <td>106775.2693</td>\n",
       "      <td>12,812,508</td>\n",
       "      <td>230.8</td>\n",
       "      <td>14</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>40.3495</td>\n",
       "      <td>-88.9861</td>\n",
       "      <td>973157</td>\n",
       "      <td>7826.175891</td>\n",
       "      <td>13617454</td>\n",
       "      <td>1.871700</td>\n",
       "      <td>107462.4870</td>\n",
       "      <td>12,812,508</td>\n",
       "      <td>230.8</td>\n",
       "      <td>14</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>40.3495</td>\n",
       "      <td>-88.9861</td>\n",
       "      <td>980553</td>\n",
       "      <td>7885.906848</td>\n",
       "      <td>13698428</td>\n",
       "      <td>1.874835</td>\n",
       "      <td>108101.4954</td>\n",
       "      <td>12,812,508</td>\n",
       "      <td>230.8</td>\n",
       "      <td>14</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Day  State ID     State      Lat    Long_  Active  Incident_Rate  \\\n",
       "0   0    2        14  Illinois  40.3495 -88.9861  957138    7697.015291   \n",
       "1   5    3        14  Illinois  40.3495 -88.9861  961499    7732.282519   \n",
       "2  10    4        14  Illinois  40.3495 -88.9861  966468    7772.205747   \n",
       "3  15    5        14  Illinois  40.3495 -88.9861  973157    7826.175891   \n",
       "4  20    6        14  Illinois  40.3495 -88.9861  980553    7885.906848   \n",
       "\n",
       "   Total_Test_Results  Case_Fatality_Ratio  Testing_Rate  \\\n",
       "0            13436652             1.867428   106035.6834   \n",
       "1            13482117             1.869933   106394.4716   \n",
       "2            13530371             1.869466   106775.2693   \n",
       "3            13617454             1.871700   107462.4870   \n",
       "4            13698428             1.874835   108101.4954   \n",
       "\n",
       "  Resident Population 2020 Census  Population Density 2020 Census  \\\n",
       "0                      12,812,508                           230.8   \n",
       "1                      12,812,508                           230.8   \n",
       "2                      12,812,508                           230.8   \n",
       "3                      12,812,508                           230.8   \n",
       "4                      12,812,508                           230.8   \n",
       "\n",
       "   Density Rank 2020 Census  SexRatio  \n",
       "0                        14        97  \n",
       "1                        14        97  \n",
       "2                        14        97  \n",
       "3                        14        97  \n",
       "4                        14        97  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Resident Population 2020 Census'] = df['Resident Population 2020 Census'].str.replace(',','').astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iowa Case_Fatality_Ratio 1\n",
      "Washington Case_Fatality_Ratio 2\n"
     ]
    }
   ],
   "source": [
    "df_gstate = df.groupby('State')\n",
    "for key,value in df_gstate:\n",
    "    groups = df_gstate.get_group(key)\n",
    "    temp = groups.iloc[:,4:]\n",
    "    for columns in temp:\n",
    "        Q1 = np.percentile(temp[columns],25)\n",
    "        Q3 = np.percentile(temp[columns],75)\n",
    "        IQR = Q3 - Q1\n",
    "        right_limit = Q3 + 1.5*IQR\n",
    "        left_limit = Q1 - 1.5*IQR\n",
    "        outlier_right_index = groups[groups[columns] > right_limit][columns].index\n",
    "        outlier_left_index = groups[groups[columns] < left_limit][columns].index\n",
    "        n_outliers = len(outlier_right_index) + len(outlier_left_index)\n",
    "        if(n_outliers > 0):\n",
    "            print(key,columns,n_outliers)\n",
    "            df.loc[outlier_right_index,columns] = right_limit\n",
    "            df.loc[outlier_left_index,columns] = left_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = (X_test - X_test.mean())/ X_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Active</th>\n",
       "      <th>Incident_Rate</th>\n",
       "      <th>Total_Test_Results</th>\n",
       "      <th>Case_Fatality_Ratio</th>\n",
       "      <th>Testing_Rate</th>\n",
       "      <th>Resident Population 2020 Census</th>\n",
       "      <th>Population Density 2020 Census</th>\n",
       "      <th>Density Rank 2020 Census</th>\n",
       "      <th>SexRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.185758</td>\n",
       "      <td>0.685045</td>\n",
       "      <td>1.624921</td>\n",
       "      <td>-0.034555</td>\n",
       "      <td>0.871610</td>\n",
       "      <td>1.714293</td>\n",
       "      <td>1.248503</td>\n",
       "      <td>0.093862</td>\n",
       "      <td>1.600344</td>\n",
       "      <td>-1.387770</td>\n",
       "      <td>-0.557150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.185758</td>\n",
       "      <td>0.685045</td>\n",
       "      <td>1.636807</td>\n",
       "      <td>-0.019067</td>\n",
       "      <td>0.879419</td>\n",
       "      <td>1.725587</td>\n",
       "      <td>1.261108</td>\n",
       "      <td>0.093862</td>\n",
       "      <td>1.600344</td>\n",
       "      <td>-1.387770</td>\n",
       "      <td>-0.557150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.185758</td>\n",
       "      <td>0.685045</td>\n",
       "      <td>1.650350</td>\n",
       "      <td>-0.001535</td>\n",
       "      <td>0.887708</td>\n",
       "      <td>1.723482</td>\n",
       "      <td>1.274487</td>\n",
       "      <td>0.093862</td>\n",
       "      <td>1.600344</td>\n",
       "      <td>-1.387770</td>\n",
       "      <td>-0.557150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.185758</td>\n",
       "      <td>0.685045</td>\n",
       "      <td>1.668580</td>\n",
       "      <td>0.022167</td>\n",
       "      <td>0.902667</td>\n",
       "      <td>1.733551</td>\n",
       "      <td>1.298632</td>\n",
       "      <td>0.093862</td>\n",
       "      <td>1.600344</td>\n",
       "      <td>-1.387770</td>\n",
       "      <td>-0.557150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.185758</td>\n",
       "      <td>0.685045</td>\n",
       "      <td>1.688737</td>\n",
       "      <td>0.048398</td>\n",
       "      <td>0.916576</td>\n",
       "      <td>1.747687</td>\n",
       "      <td>1.321083</td>\n",
       "      <td>0.093862</td>\n",
       "      <td>1.600344</td>\n",
       "      <td>-1.387770</td>\n",
       "      <td>-0.557150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1.449287</td>\n",
       "      <td>-1.903393</td>\n",
       "      <td>-0.163129</td>\n",
       "      <td>-1.654112</td>\n",
       "      <td>-0.672606</td>\n",
       "      <td>-0.486315</td>\n",
       "      <td>-0.425243</td>\n",
       "      <td>-0.463803</td>\n",
       "      <td>-0.351668</td>\n",
       "      <td>-0.102798</td>\n",
       "      <td>1.114301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>1.449287</td>\n",
       "      <td>-1.903393</td>\n",
       "      <td>-0.156348</td>\n",
       "      <td>-1.639579</td>\n",
       "      <td>-0.668592</td>\n",
       "      <td>-0.490357</td>\n",
       "      <td>-0.414460</td>\n",
       "      <td>-0.463803</td>\n",
       "      <td>-0.351668</td>\n",
       "      <td>-0.102798</td>\n",
       "      <td>1.114301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1.449287</td>\n",
       "      <td>-1.903393</td>\n",
       "      <td>-0.151034</td>\n",
       "      <td>-1.628091</td>\n",
       "      <td>-0.664255</td>\n",
       "      <td>-0.469195</td>\n",
       "      <td>-0.402811</td>\n",
       "      <td>-0.463803</td>\n",
       "      <td>-0.351668</td>\n",
       "      <td>-0.102798</td>\n",
       "      <td>1.114301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1.449287</td>\n",
       "      <td>-1.903393</td>\n",
       "      <td>-0.146139</td>\n",
       "      <td>-1.617734</td>\n",
       "      <td>-0.659315</td>\n",
       "      <td>-0.505139</td>\n",
       "      <td>-0.389542</td>\n",
       "      <td>-0.463803</td>\n",
       "      <td>-0.351668</td>\n",
       "      <td>-0.102798</td>\n",
       "      <td>1.114301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1.449287</td>\n",
       "      <td>-1.903393</td>\n",
       "      <td>-0.146139</td>\n",
       "      <td>-1.617734</td>\n",
       "      <td>-0.655189</td>\n",
       "      <td>-0.505139</td>\n",
       "      <td>-0.378461</td>\n",
       "      <td>-0.463803</td>\n",
       "      <td>-0.351668</td>\n",
       "      <td>-0.102798</td>\n",
       "      <td>1.114301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Lat     Long_    Active  Incident_Rate  Total_Test_Results  \\\n",
       "0    0.185758  0.685045  1.624921      -0.034555            0.871610   \n",
       "1    0.185758  0.685045  1.636807      -0.019067            0.879419   \n",
       "2    0.185758  0.685045  1.650350      -0.001535            0.887708   \n",
       "3    0.185758  0.685045  1.668580       0.022167            0.902667   \n",
       "4    0.185758  0.685045  1.688737       0.048398            0.916576   \n",
       "..        ...       ...       ...            ...                 ...   \n",
       "145  1.449287 -1.903393 -0.163129      -1.654112           -0.672606   \n",
       "146  1.449287 -1.903393 -0.156348      -1.639579           -0.668592   \n",
       "147  1.449287 -1.903393 -0.151034      -1.628091           -0.664255   \n",
       "148  1.449287 -1.903393 -0.146139      -1.617734           -0.659315   \n",
       "149  1.449287 -1.903393 -0.146139      -1.617734           -0.655189   \n",
       "\n",
       "     Case_Fatality_Ratio  Testing_Rate  Resident Population 2020 Census  \\\n",
       "0               1.714293      1.248503                         0.093862   \n",
       "1               1.725587      1.261108                         0.093862   \n",
       "2               1.723482      1.274487                         0.093862   \n",
       "3               1.733551      1.298632                         0.093862   \n",
       "4               1.747687      1.321083                         0.093862   \n",
       "..                   ...           ...                              ...   \n",
       "145            -0.486315     -0.425243                        -0.463803   \n",
       "146            -0.490357     -0.414460                        -0.463803   \n",
       "147            -0.469195     -0.402811                        -0.463803   \n",
       "148            -0.505139     -0.389542                        -0.463803   \n",
       "149            -0.505139     -0.378461                        -0.463803   \n",
       "\n",
       "     Population Density 2020 Census  Density Rank 2020 Census  SexRatio  \n",
       "0                          1.600344                 -1.387770 -0.557150  \n",
       "1                          1.600344                 -1.387770 -0.557150  \n",
       "2                          1.600344                 -1.387770 -0.557150  \n",
       "3                          1.600344                 -1.387770 -0.557150  \n",
       "4                          1.600344                 -1.387770 -0.557150  \n",
       "..                              ...                       ...       ...  \n",
       "145                       -0.351668                 -0.102798  1.114301  \n",
       "146                       -0.351668                 -0.102798  1.114301  \n",
       "147                       -0.351668                 -0.102798  1.114301  \n",
       "148                       -0.351668                 -0.102798  1.114301  \n",
       "149                       -0.351668                 -0.102798  1.114301  \n",
       "\n",
       "[150 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(X_test)\n",
    "x_test1 = np.reshape(x_test,(x_test.shape[0],x_test.shape[1],1))\n",
    "%store -r x_train1 y_train x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-e4edcbeeb006>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx_train_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 42)\n",
    "x_train_new, y_train_new = sm.fit_sample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label: Recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                240       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 681\n",
      "Trainable params: 681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "lstm_recovered = tf.keras.Sequential([\n",
    "                                tf.keras.Input(shape=(11,)),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(1,activation = 'sigmoid')])\n",
    "lstm_recovered.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_recovered.compile(optimizer='adam',\n",
    "              loss='BinaryCrossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.7558 - accuracy: 0.3682 - val_loss: 0.7183 - val_accuracy: 0.4464\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7227 - accuracy: 0.4227 - val_loss: 0.7010 - val_accuracy: 0.5714\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6954 - accuracy: 0.5591 - val_loss: 0.6880 - val_accuracy: 0.5714\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6707 - accuracy: 0.6955 - val_loss: 0.6790 - val_accuracy: 0.6250\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6510 - accuracy: 0.7636 - val_loss: 0.6722 - val_accuracy: 0.6071\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6357 - accuracy: 0.7773 - val_loss: 0.6659 - val_accuracy: 0.6250\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6202 - accuracy: 0.7364 - val_loss: 0.6601 - val_accuracy: 0.6250\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6067 - accuracy: 0.7318 - val_loss: 0.6550 - val_accuracy: 0.6250\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5945 - accuracy: 0.7182 - val_loss: 0.6513 - val_accuracy: 0.6071\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 0.7227 - val_loss: 0.6466 - val_accuracy: 0.6071\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5716 - accuracy: 0.7273 - val_loss: 0.6420 - val_accuracy: 0.6250\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5609 - accuracy: 0.7591 - val_loss: 0.6370 - val_accuracy: 0.6429\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5512 - accuracy: 0.7636 - val_loss: 0.6310 - val_accuracy: 0.6429\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5411 - accuracy: 0.7636 - val_loss: 0.6260 - val_accuracy: 0.6429\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5315 - accuracy: 0.7636 - val_loss: 0.6190 - val_accuracy: 0.6429\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5219 - accuracy: 0.7636 - val_loss: 0.6115 - val_accuracy: 0.6429\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7818 - val_loss: 0.6048 - val_accuracy: 0.6429\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7909 - val_loss: 0.5973 - val_accuracy: 0.6429\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4940 - accuracy: 0.7955 - val_loss: 0.5907 - val_accuracy: 0.6786\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4855 - accuracy: 0.8000 - val_loss: 0.5826 - val_accuracy: 0.6786\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4779 - accuracy: 0.8045 - val_loss: 0.5726 - val_accuracy: 0.6786\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.8091 - val_loss: 0.5670 - val_accuracy: 0.6786\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4615 - accuracy: 0.8091 - val_loss: 0.5606 - val_accuracy: 0.6786\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.8091 - val_loss: 0.5539 - val_accuracy: 0.6786\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.8091 - val_loss: 0.5483 - val_accuracy: 0.7143\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.8136 - val_loss: 0.5412 - val_accuracy: 0.7143\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4337 - accuracy: 0.8273 - val_loss: 0.5335 - val_accuracy: 0.7500\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8273 - val_loss: 0.5250 - val_accuracy: 0.7857\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.8318 - val_loss: 0.5183 - val_accuracy: 0.8036\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.8364 - val_loss: 0.5123 - val_accuracy: 0.8036\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8409 - val_loss: 0.5069 - val_accuracy: 0.8036\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.8409 - val_loss: 0.5030 - val_accuracy: 0.8036\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.8455 - val_loss: 0.4983 - val_accuracy: 0.8036\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3955 - accuracy: 0.8455 - val_loss: 0.4908 - val_accuracy: 0.8036\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3903 - accuracy: 0.8500 - val_loss: 0.4859 - val_accuracy: 0.8036\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3855 - accuracy: 0.8545 - val_loss: 0.4781 - val_accuracy: 0.8036\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3804 - accuracy: 0.8545 - val_loss: 0.4721 - val_accuracy: 0.8036\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3764 - accuracy: 0.8545 - val_loss: 0.4644 - val_accuracy: 0.8036\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3714 - accuracy: 0.8545 - val_loss: 0.4608 - val_accuracy: 0.8036\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3670 - accuracy: 0.8545 - val_loss: 0.4587 - val_accuracy: 0.8036\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3628 - accuracy: 0.8591 - val_loss: 0.4536 - val_accuracy: 0.8214\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3578 - accuracy: 0.8636 - val_loss: 0.4487 - val_accuracy: 0.8214\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3540 - accuracy: 0.8636 - val_loss: 0.4468 - val_accuracy: 0.8214\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3502 - accuracy: 0.8682 - val_loss: 0.4376 - val_accuracy: 0.8214\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3449 - accuracy: 0.8773 - val_loss: 0.4334 - val_accuracy: 0.8214\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3409 - accuracy: 0.8773 - val_loss: 0.4281 - val_accuracy: 0.8214\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3370 - accuracy: 0.8773 - val_loss: 0.4247 - val_accuracy: 0.8214\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3336 - accuracy: 0.8818 - val_loss: 0.4179 - val_accuracy: 0.8214\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3295 - accuracy: 0.8818 - val_loss: 0.4114 - val_accuracy: 0.8214\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3251 - accuracy: 0.8909 - val_loss: 0.4074 - val_accuracy: 0.8214\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3217 - accuracy: 0.9045 - val_loss: 0.4051 - val_accuracy: 0.8214\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3180 - accuracy: 0.9091 - val_loss: 0.4008 - val_accuracy: 0.8214\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3150 - accuracy: 0.9091 - val_loss: 0.3939 - val_accuracy: 0.8214\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3108 - accuracy: 0.9091 - val_loss: 0.3878 - val_accuracy: 0.8214\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3075 - accuracy: 0.9091 - val_loss: 0.3878 - val_accuracy: 0.8214\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3037 - accuracy: 0.9091 - val_loss: 0.3795 - val_accuracy: 0.8214\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3002 - accuracy: 0.9091 - val_loss: 0.3733 - val_accuracy: 0.8571\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2967 - accuracy: 0.9182 - val_loss: 0.3714 - val_accuracy: 0.8571\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2927 - accuracy: 0.9182 - val_loss: 0.3670 - val_accuracy: 0.8571\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2893 - accuracy: 0.9182 - val_loss: 0.3607 - val_accuracy: 0.8571\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2861 - accuracy: 0.9182 - val_loss: 0.3569 - val_accuracy: 0.8750\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2822 - accuracy: 0.9227 - val_loss: 0.3562 - val_accuracy: 0.8571\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2790 - accuracy: 0.9227 - val_loss: 0.3539 - val_accuracy: 0.8750\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2761 - accuracy: 0.9227 - val_loss: 0.3487 - val_accuracy: 0.8750\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2724 - accuracy: 0.9227 - val_loss: 0.3461 - val_accuracy: 0.9107\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2695 - accuracy: 0.9182 - val_loss: 0.3366 - val_accuracy: 0.8929\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2664 - accuracy: 0.9273 - val_loss: 0.3367 - val_accuracy: 0.8929\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2626 - accuracy: 0.9318 - val_loss: 0.3304 - val_accuracy: 0.8929\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2596 - accuracy: 0.9318 - val_loss: 0.3254 - val_accuracy: 0.8929\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2564 - accuracy: 0.9364 - val_loss: 0.3257 - val_accuracy: 0.8929\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2538 - accuracy: 0.9364 - val_loss: 0.3257 - val_accuracy: 0.8929\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2504 - accuracy: 0.9364 - val_loss: 0.3229 - val_accuracy: 0.8929\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2477 - accuracy: 0.9409 - val_loss: 0.3188 - val_accuracy: 0.8929\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2449 - accuracy: 0.9364 - val_loss: 0.3105 - val_accuracy: 0.8929\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2420 - accuracy: 0.9409 - val_loss: 0.3106 - val_accuracy: 0.8929\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2394 - accuracy: 0.9409 - val_loss: 0.3055 - val_accuracy: 0.8929\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2366 - accuracy: 0.9409 - val_loss: 0.3038 - val_accuracy: 0.8929\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2338 - accuracy: 0.9409 - val_loss: 0.3015 - val_accuracy: 0.8929\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2313 - accuracy: 0.9409 - val_loss: 0.2993 - val_accuracy: 0.8929\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2288 - accuracy: 0.9409 - val_loss: 0.2977 - val_accuracy: 0.8929\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2261 - accuracy: 0.9409 - val_loss: 0.2957 - val_accuracy: 0.8929\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2235 - accuracy: 0.9409 - val_loss: 0.2907 - val_accuracy: 0.8929\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2213 - accuracy: 0.9409 - val_loss: 0.2873 - val_accuracy: 0.8929\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2190 - accuracy: 0.9409 - val_loss: 0.2853 - val_accuracy: 0.8929\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2168 - accuracy: 0.9409 - val_loss: 0.2813 - val_accuracy: 0.8929\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2145 - accuracy: 0.9409 - val_loss: 0.2849 - val_accuracy: 0.8929\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2122 - accuracy: 0.9409 - val_loss: 0.2793 - val_accuracy: 0.8929\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9409 - val_loss: 0.2802 - val_accuracy: 0.8929\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2070 - accuracy: 0.9409 - val_loss: 0.2777 - val_accuracy: 0.8929\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2052 - accuracy: 0.9409 - val_loss: 0.2784 - val_accuracy: 0.8929\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2030 - accuracy: 0.9409 - val_loss: 0.2731 - val_accuracy: 0.8929\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2007 - accuracy: 0.9409 - val_loss: 0.2742 - val_accuracy: 0.8929\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1988 - accuracy: 0.9409 - val_loss: 0.2660 - val_accuracy: 0.8929\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1968 - accuracy: 0.9409 - val_loss: 0.2634 - val_accuracy: 0.8929\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1946 - accuracy: 0.9409 - val_loss: 0.2635 - val_accuracy: 0.8929\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1927 - accuracy: 0.9455 - val_loss: 0.2669 - val_accuracy: 0.8929\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1907 - accuracy: 0.9455 - val_loss: 0.2620 - val_accuracy: 0.8929\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1884 - accuracy: 0.9455 - val_loss: 0.2606 - val_accuracy: 0.8929\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1865 - accuracy: 0.9455 - val_loss: 0.2576 - val_accuracy: 0.8929\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1848 - accuracy: 0.9455 - val_loss: 0.2568 - val_accuracy: 0.8929\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1826 - accuracy: 0.9500 - val_loss: 0.2542 - val_accuracy: 0.8929\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1805 - accuracy: 0.9500 - val_loss: 0.2487 - val_accuracy: 0.9107\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1783 - accuracy: 0.9500 - val_loss: 0.2483 - val_accuracy: 0.9107\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1769 - accuracy: 0.9500 - val_loss: 0.2466 - val_accuracy: 0.9286\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1748 - accuracy: 0.9500 - val_loss: 0.2406 - val_accuracy: 0.9286\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1728 - accuracy: 0.9545 - val_loss: 0.2402 - val_accuracy: 0.9286\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1717 - accuracy: 0.9545 - val_loss: 0.2431 - val_accuracy: 0.9107\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1697 - accuracy: 0.9545 - val_loss: 0.2393 - val_accuracy: 0.9107\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1679 - accuracy: 0.9545 - val_loss: 0.2334 - val_accuracy: 0.9464\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1675 - accuracy: 0.9545 - val_loss: 0.2297 - val_accuracy: 0.9464\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1656 - accuracy: 0.9545 - val_loss: 0.2357 - val_accuracy: 0.9286\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1634 - accuracy: 0.9545 - val_loss: 0.2360 - val_accuracy: 0.9286\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1621 - accuracy: 0.9545 - val_loss: 0.2306 - val_accuracy: 0.9286\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1601 - accuracy: 0.9545 - val_loss: 0.2288 - val_accuracy: 0.9286\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1593 - accuracy: 0.9545 - val_loss: 0.2255 - val_accuracy: 0.9286\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1578 - accuracy: 0.9545 - val_loss: 0.2259 - val_accuracy: 0.9286\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1562 - accuracy: 0.9545 - val_loss: 0.2284 - val_accuracy: 0.9286\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1561 - accuracy: 0.9545 - val_loss: 0.2234 - val_accuracy: 0.9286\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1536 - accuracy: 0.9545 - val_loss: 0.2237 - val_accuracy: 0.9286\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1526 - accuracy: 0.9545 - val_loss: 0.2274 - val_accuracy: 0.9286\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1508 - accuracy: 0.9545 - val_loss: 0.2252 - val_accuracy: 0.9286\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1503 - accuracy: 0.9545 - val_loss: 0.2172 - val_accuracy: 0.9286\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1482 - accuracy: 0.9591 - val_loss: 0.2208 - val_accuracy: 0.9286\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1469 - accuracy: 0.9591 - val_loss: 0.2195 - val_accuracy: 0.9286\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9591 - val_loss: 0.2189 - val_accuracy: 0.9286\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1448 - accuracy: 0.9591 - val_loss: 0.2201 - val_accuracy: 0.9286\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1429 - accuracy: 0.9591 - val_loss: 0.2170 - val_accuracy: 0.9286\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1420 - accuracy: 0.9545 - val_loss: 0.2190 - val_accuracy: 0.9286\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1404 - accuracy: 0.9591 - val_loss: 0.2152 - val_accuracy: 0.9286\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1401 - accuracy: 0.9591 - val_loss: 0.2155 - val_accuracy: 0.9286\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1384 - accuracy: 0.9591 - val_loss: 0.2164 - val_accuracy: 0.9286\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1376 - accuracy: 0.9591 - val_loss: 0.2132 - val_accuracy: 0.9286\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1364 - accuracy: 0.9591 - val_loss: 0.2115 - val_accuracy: 0.9286\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1353 - accuracy: 0.9591 - val_loss: 0.2157 - val_accuracy: 0.9286\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1345 - accuracy: 0.9591 - val_loss: 0.2163 - val_accuracy: 0.9286\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1337 - accuracy: 0.9591 - val_loss: 0.2132 - val_accuracy: 0.9286\n",
      "Epoch 137/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1321 - accuracy: 0.9591 - val_loss: 0.2141 - val_accuracy: 0.9286\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1309 - accuracy: 0.9636 - val_loss: 0.2138 - val_accuracy: 0.9286\n",
      "Epoch 139/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1300 - accuracy: 0.9636 - val_loss: 0.2147 - val_accuracy: 0.9286\n",
      "Epoch 140/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1295 - accuracy: 0.9636 - val_loss: 0.2120 - val_accuracy: 0.9286\n",
      "Epoch 141/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1283 - accuracy: 0.9636 - val_loss: 0.2103 - val_accuracy: 0.9286\n",
      "Epoch 142/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1274 - accuracy: 0.9636 - val_loss: 0.2151 - val_accuracy: 0.9286\n",
      "Epoch 143/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1271 - accuracy: 0.9636 - val_loss: 0.2144 - val_accuracy: 0.9286\n",
      "Epoch 144/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1262 - accuracy: 0.9636 - val_loss: 0.2119 - val_accuracy: 0.9286\n",
      "Epoch 145/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1253 - accuracy: 0.9636 - val_loss: 0.2132 - val_accuracy: 0.9286\n",
      "Epoch 146/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1262 - accuracy: 0.9636 - val_loss: 0.2085 - val_accuracy: 0.9286\n",
      "Epoch 147/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1230 - accuracy: 0.9636 - val_loss: 0.2115 - val_accuracy: 0.9286\n",
      "Epoch 148/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1246 - accuracy: 0.9636 - val_loss: 0.2226 - val_accuracy: 0.9286\n",
      "Epoch 149/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1228 - accuracy: 0.9636 - val_loss: 0.2120 - val_accuracy: 0.9286\n",
      "Epoch 150/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1211 - accuracy: 0.9636 - val_loss: 0.2130 - val_accuracy: 0.9286\n",
      "Epoch 151/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1207 - accuracy: 0.9636 - val_loss: 0.2180 - val_accuracy: 0.9286\n",
      "Epoch 152/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1201 - accuracy: 0.9636 - val_loss: 0.2140 - val_accuracy: 0.9286\n",
      "Epoch 153/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1188 - accuracy: 0.9636 - val_loss: 0.2126 - val_accuracy: 0.9286\n",
      "Epoch 154/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1183 - accuracy: 0.9636 - val_loss: 0.2171 - val_accuracy: 0.9286\n",
      "Epoch 155/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1173 - accuracy: 0.9636 - val_loss: 0.2185 - val_accuracy: 0.9286\n",
      "Epoch 156/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9636 - val_loss: 0.2147 - val_accuracy: 0.9286\n",
      "Epoch 157/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1168 - accuracy: 0.9636 - val_loss: 0.2138 - val_accuracy: 0.9286\n",
      "Epoch 158/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1158 - accuracy: 0.9636 - val_loss: 0.2168 - val_accuracy: 0.9286\n",
      "Epoch 159/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1150 - accuracy: 0.9636 - val_loss: 0.2185 - val_accuracy: 0.9286\n",
      "Epoch 160/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1141 - accuracy: 0.9636 - val_loss: 0.2148 - val_accuracy: 0.9286\n",
      "Epoch 161/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1140 - accuracy: 0.9636 - val_loss: 0.2133 - val_accuracy: 0.9286\n",
      "Epoch 162/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1151 - accuracy: 0.9636 - val_loss: 0.2241 - val_accuracy: 0.9286\n",
      "Epoch 163/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1126 - accuracy: 0.9636 - val_loss: 0.2198 - val_accuracy: 0.9286\n",
      "Epoch 164/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1120 - accuracy: 0.9636 - val_loss: 0.2170 - val_accuracy: 0.9286\n",
      "Epoch 165/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1116 - accuracy: 0.9636 - val_loss: 0.2154 - val_accuracy: 0.9286\n",
      "Epoch 166/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1107 - accuracy: 0.9636 - val_loss: 0.2188 - val_accuracy: 0.9286\n",
      "Epoch 167/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1102 - accuracy: 0.9636 - val_loss: 0.2202 - val_accuracy: 0.9286\n",
      "Epoch 168/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1097 - accuracy: 0.9591 - val_loss: 0.2213 - val_accuracy: 0.9286\n",
      "Epoch 169/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1097 - accuracy: 0.9591 - val_loss: 0.2202 - val_accuracy: 0.9286\n",
      "Epoch 170/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1094 - accuracy: 0.9591 - val_loss: 0.2163 - val_accuracy: 0.9286\n",
      "Epoch 171/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1082 - accuracy: 0.9591 - val_loss: 0.2200 - val_accuracy: 0.9286\n",
      "Epoch 172/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1084 - accuracy: 0.9591 - val_loss: 0.2222 - val_accuracy: 0.9286\n",
      "Epoch 173/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1077 - accuracy: 0.9591 - val_loss: 0.2167 - val_accuracy: 0.9286\n",
      "Epoch 174/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1067 - accuracy: 0.9591 - val_loss: 0.2203 - val_accuracy: 0.9286\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1076 - accuracy: 0.9591 - val_loss: 0.2302 - val_accuracy: 0.9286\n",
      "Epoch 176/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1085 - accuracy: 0.9591 - val_loss: 0.2214 - val_accuracy: 0.9286\n",
      "Epoch 177/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1058 - accuracy: 0.9591 - val_loss: 0.2212 - val_accuracy: 0.9286\n",
      "Epoch 178/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1053 - accuracy: 0.9591 - val_loss: 0.2218 - val_accuracy: 0.9286\n",
      "Epoch 179/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1058 - accuracy: 0.9591 - val_loss: 0.2263 - val_accuracy: 0.9286\n",
      "Epoch 180/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1047 - accuracy: 0.9591 - val_loss: 0.2233 - val_accuracy: 0.9286\n",
      "Epoch 181/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1044 - accuracy: 0.9591 - val_loss: 0.2183 - val_accuracy: 0.9286\n",
      "Epoch 182/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1039 - accuracy: 0.9636 - val_loss: 0.2223 - val_accuracy: 0.9286\n",
      "Epoch 183/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1035 - accuracy: 0.9591 - val_loss: 0.2287 - val_accuracy: 0.9286\n",
      "Epoch 184/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1027 - accuracy: 0.9591 - val_loss: 0.2240 - val_accuracy: 0.9286\n",
      "Epoch 185/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1022 - accuracy: 0.9636 - val_loss: 0.2242 - val_accuracy: 0.9286\n",
      "Epoch 186/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1023 - accuracy: 0.9591 - val_loss: 0.2225 - val_accuracy: 0.9286\n",
      "Epoch 187/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1016 - accuracy: 0.9591 - val_loss: 0.2286 - val_accuracy: 0.9286\n",
      "Epoch 188/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1020 - accuracy: 0.9636 - val_loss: 0.2235 - val_accuracy: 0.9286\n",
      "Epoch 189/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1016 - accuracy: 0.9591 - val_loss: 0.2282 - val_accuracy: 0.9286\n",
      "Epoch 190/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1014 - accuracy: 0.9591 - val_loss: 0.2258 - val_accuracy: 0.9286\n",
      "Epoch 191/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1007 - accuracy: 0.9591 - val_loss: 0.2250 - val_accuracy: 0.9286\n",
      "Epoch 192/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0998 - accuracy: 0.9591 - val_loss: 0.2310 - val_accuracy: 0.9286\n",
      "Epoch 193/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1001 - accuracy: 0.9636 - val_loss: 0.2289 - val_accuracy: 0.9286\n",
      "Epoch 194/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0992 - accuracy: 0.9636 - val_loss: 0.2300 - val_accuracy: 0.9286\n",
      "Epoch 195/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0990 - accuracy: 0.9591 - val_loss: 0.2315 - val_accuracy: 0.9286\n",
      "Epoch 196/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0995 - accuracy: 0.9591 - val_loss: 0.2319 - val_accuracy: 0.9286\n",
      "Epoch 197/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0987 - accuracy: 0.9636 - val_loss: 0.2238 - val_accuracy: 0.9286\n",
      "Epoch 198/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0986 - accuracy: 0.9636 - val_loss: 0.2335 - val_accuracy: 0.9286\n",
      "Epoch 199/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0979 - accuracy: 0.9636 - val_loss: 0.2330 - val_accuracy: 0.9286\n",
      "Epoch 200/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0978 - accuracy: 0.9636 - val_loss: 0.2353 - val_accuracy: 0.9286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cb479f7700>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_recovered.fit(x_train,y_train.iloc[:,-1],epochs=200,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_recovered = lstm_recovered.predict(x_test) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_recovered.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label: Deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               1200      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               50500     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 501       \n",
      "=================================================================\n",
      "Total params: 52,201\n",
      "Trainable params: 52,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "lstm_deaths = tf.keras.Sequential([\n",
    "                                tf.keras.Input(shape=(11,)),\n",
    "                                tf.keras.layers.Dense(100,activation = 'tanh'),\n",
    "                                tf.keras.layers.Dense(500,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(1,activation = 'sigmoid')])\n",
    "lstm_deaths.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_deaths.compile(optimizer='adam',\n",
    "              loss='BinaryCrossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5197 - accuracy: 0.8682 - val_loss: 0.3832 - val_accuracy: 0.9107\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3496 - accuracy: 0.9000 - val_loss: 0.3139 - val_accuracy: 0.9107\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3083 - accuracy: 0.9000 - val_loss: 0.3039 - val_accuracy: 0.9107\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2909 - accuracy: 0.9000 - val_loss: 0.3048 - val_accuracy: 0.9107\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2766 - accuracy: 0.9000 - val_loss: 0.3054 - val_accuracy: 0.9107\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2631 - accuracy: 0.9000 - val_loss: 0.3078 - val_accuracy: 0.9107\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2566 - accuracy: 0.8909 - val_loss: 0.3101 - val_accuracy: 0.9107\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2456 - accuracy: 0.9000 - val_loss: 0.3131 - val_accuracy: 0.9107\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2401 - accuracy: 0.9000 - val_loss: 0.3187 - val_accuracy: 0.9107\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2324 - accuracy: 0.9000 - val_loss: 0.3267 - val_accuracy: 0.9107\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2282 - accuracy: 0.9000 - val_loss: 0.3317 - val_accuracy: 0.9107\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2242 - accuracy: 0.8909 - val_loss: 0.3329 - val_accuracy: 0.8929\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2222 - accuracy: 0.8864 - val_loss: 0.3397 - val_accuracy: 0.9107\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2172 - accuracy: 0.9045 - val_loss: 0.3461 - val_accuracy: 0.9107\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2111 - accuracy: 0.9045 - val_loss: 0.3539 - val_accuracy: 0.9107\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2100 - accuracy: 0.9136 - val_loss: 0.3585 - val_accuracy: 0.8929\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2081 - accuracy: 0.9136 - val_loss: 0.3644 - val_accuracy: 0.9107\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2027 - accuracy: 0.9136 - val_loss: 0.3680 - val_accuracy: 0.8929\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2024 - accuracy: 0.9091 - val_loss: 0.3733 - val_accuracy: 0.9107\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2046 - accuracy: 0.8955 - val_loss: 0.3798 - val_accuracy: 0.9107\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2011 - accuracy: 0.9136 - val_loss: 0.3857 - val_accuracy: 0.9107\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2004 - accuracy: 0.9000 - val_loss: 0.3874 - val_accuracy: 0.8929\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1960 - accuracy: 0.9045 - val_loss: 0.3902 - val_accuracy: 0.8929\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1942 - accuracy: 0.9136 - val_loss: 0.4030 - val_accuracy: 0.9107\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1907 - accuracy: 0.9136 - val_loss: 0.4028 - val_accuracy: 0.9107\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1893 - accuracy: 0.9182 - val_loss: 0.4036 - val_accuracy: 0.8929\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1923 - accuracy: 0.9045 - val_loss: 0.4155 - val_accuracy: 0.8929\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1920 - accuracy: 0.9091 - val_loss: 0.4213 - val_accuracy: 0.8929\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1838 - accuracy: 0.9136 - val_loss: 0.4222 - val_accuracy: 0.9107\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1893 - accuracy: 0.9136 - val_loss: 0.4323 - val_accuracy: 0.9107\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1865 - accuracy: 0.9045 - val_loss: 0.4300 - val_accuracy: 0.9107\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1858 - accuracy: 0.9091 - val_loss: 0.4344 - val_accuracy: 0.8929\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1845 - accuracy: 0.9091 - val_loss: 0.4397 - val_accuracy: 0.8929\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1872 - accuracy: 0.9000 - val_loss: 0.4424 - val_accuracy: 0.8929\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1837 - accuracy: 0.9091 - val_loss: 0.4485 - val_accuracy: 0.9107\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1817 - accuracy: 0.9136 - val_loss: 0.4570 - val_accuracy: 0.9107\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1770 - accuracy: 0.9182 - val_loss: 0.4547 - val_accuracy: 0.9107\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1759 - accuracy: 0.9182 - val_loss: 0.4621 - val_accuracy: 0.8929\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1814 - accuracy: 0.9136 - val_loss: 0.4633 - val_accuracy: 0.8929\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1751 - accuracy: 0.9136 - val_loss: 0.4781 - val_accuracy: 0.8929\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1776 - accuracy: 0.9136 - val_loss: 0.4758 - val_accuracy: 0.9107\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1724 - accuracy: 0.9227 - val_loss: 0.4775 - val_accuracy: 0.8750\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1710 - accuracy: 0.9136 - val_loss: 0.4819 - val_accuracy: 0.8929\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1732 - accuracy: 0.9182 - val_loss: 0.4811 - val_accuracy: 0.8750\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1700 - accuracy: 0.9182 - val_loss: 0.4925 - val_accuracy: 0.8929\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1712 - accuracy: 0.9227 - val_loss: 0.4950 - val_accuracy: 0.9107\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1747 - accuracy: 0.9091 - val_loss: 0.4933 - val_accuracy: 0.8929\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1883 - accuracy: 0.9136 - val_loss: 0.5038 - val_accuracy: 0.9107\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1972 - accuracy: 0.9000 - val_loss: 0.5209 - val_accuracy: 0.9107\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1711 - accuracy: 0.9182 - val_loss: 0.5010 - val_accuracy: 0.9107\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1762 - accuracy: 0.9182 - val_loss: 0.5030 - val_accuracy: 0.8750\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1714 - accuracy: 0.9091 - val_loss: 0.5120 - val_accuracy: 0.9107\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1688 - accuracy: 0.9227 - val_loss: 0.5193 - val_accuracy: 0.9107\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1766 - accuracy: 0.9182 - val_loss: 0.5233 - val_accuracy: 0.9107\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1736 - accuracy: 0.9227 - val_loss: 0.5140 - val_accuracy: 0.8929\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1670 - accuracy: 0.9136 - val_loss: 0.5261 - val_accuracy: 0.9107\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1683 - accuracy: 0.9182 - val_loss: 0.5258 - val_accuracy: 0.8929\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1656 - accuracy: 0.9182 - val_loss: 0.5276 - val_accuracy: 0.8929\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1650 - accuracy: 0.9227 - val_loss: 0.5378 - val_accuracy: 0.8750\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1704 - accuracy: 0.9136 - val_loss: 0.5338 - val_accuracy: 0.9107\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1599 - accuracy: 0.9227 - val_loss: 0.5339 - val_accuracy: 0.9107\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1681 - accuracy: 0.9227 - val_loss: 0.5416 - val_accuracy: 0.9107\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1640 - accuracy: 0.9182 - val_loss: 0.5526 - val_accuracy: 0.9107\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1644 - accuracy: 0.9182 - val_loss: 0.5465 - val_accuracy: 0.8929\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1623 - accuracy: 0.9227 - val_loss: 0.5497 - val_accuracy: 0.9107\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1662 - accuracy: 0.9182 - val_loss: 0.5624 - val_accuracy: 0.9107\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1818 - accuracy: 0.9227 - val_loss: 0.5786 - val_accuracy: 0.8929\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1858 - accuracy: 0.8955 - val_loss: 0.5710 - val_accuracy: 0.8571\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1695 - accuracy: 0.9091 - val_loss: 0.5593 - val_accuracy: 0.9107\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1771 - accuracy: 0.9182 - val_loss: 0.5523 - val_accuracy: 0.8929\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1729 - accuracy: 0.9136 - val_loss: 0.5713 - val_accuracy: 0.8929\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1579 - accuracy: 0.9227 - val_loss: 0.5716 - val_accuracy: 0.9107\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1691 - accuracy: 0.9273 - val_loss: 0.5771 - val_accuracy: 0.9107\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1652 - accuracy: 0.9227 - val_loss: 0.5675 - val_accuracy: 0.8929\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1646 - accuracy: 0.9136 - val_loss: 0.5752 - val_accuracy: 0.8929\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1557 - accuracy: 0.9273 - val_loss: 0.5728 - val_accuracy: 0.8750\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1595 - accuracy: 0.9227 - val_loss: 0.5712 - val_accuracy: 0.8929\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1649 - accuracy: 0.9091 - val_loss: 0.5827 - val_accuracy: 0.9107\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1567 - accuracy: 0.9227 - val_loss: 0.5862 - val_accuracy: 0.8929\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1582 - accuracy: 0.9227 - val_loss: 0.5831 - val_accuracy: 0.8750\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1595 - accuracy: 0.9182 - val_loss: 0.5777 - val_accuracy: 0.9107\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1650 - accuracy: 0.9136 - val_loss: 0.5765 - val_accuracy: 0.8929\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1608 - accuracy: 0.9182 - val_loss: 0.6007 - val_accuracy: 0.8929\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1592 - accuracy: 0.9273 - val_loss: 0.6016 - val_accuracy: 0.8929\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1621 - accuracy: 0.9227 - val_loss: 0.5836 - val_accuracy: 0.9107\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1618 - accuracy: 0.9182 - val_loss: 0.5919 - val_accuracy: 0.9107\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1610 - accuracy: 0.9091 - val_loss: 0.5961 - val_accuracy: 0.8929\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1616 - accuracy: 0.9091 - val_loss: 0.5999 - val_accuracy: 0.8929\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1591 - accuracy: 0.9227 - val_loss: 0.6078 - val_accuracy: 0.8929\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1622 - accuracy: 0.9136 - val_loss: 0.6054 - val_accuracy: 0.8750\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1560 - accuracy: 0.9227 - val_loss: 0.6001 - val_accuracy: 0.9107\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1587 - accuracy: 0.9227 - val_loss: 0.6026 - val_accuracy: 0.9107\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1528 - accuracy: 0.9273 - val_loss: 0.6105 - val_accuracy: 0.9107\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1617 - accuracy: 0.9227 - val_loss: 0.6087 - val_accuracy: 0.8929\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1621 - accuracy: 0.9227 - val_loss: 0.6070 - val_accuracy: 0.8929\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1532 - accuracy: 0.9227 - val_loss: 0.6126 - val_accuracy: 0.9107\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1525 - accuracy: 0.9273 - val_loss: 0.6155 - val_accuracy: 0.8750\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1523 - accuracy: 0.9318 - val_loss: 0.6197 - val_accuracy: 0.8750\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1573 - accuracy: 0.9136 - val_loss: 0.6205 - val_accuracy: 0.9107\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1516 - accuracy: 0.9182 - val_loss: 0.6177 - val_accuracy: 0.8929\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1520 - accuracy: 0.9227 - val_loss: 0.6235 - val_accuracy: 0.8929\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1524 - accuracy: 0.9227 - val_loss: 0.6244 - val_accuracy: 0.8750\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1488 - accuracy: 0.9273 - val_loss: 0.6373 - val_accuracy: 0.8929\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1488 - accuracy: 0.9318 - val_loss: 0.6202 - val_accuracy: 0.8929\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1491 - accuracy: 0.9227 - val_loss: 0.6211 - val_accuracy: 0.8929\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1284 - accuracy: 0.93 - 0s 5ms/step - loss: 0.1516 - accuracy: 0.9227 - val_loss: 0.6334 - val_accuracy: 0.8750\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1538 - accuracy: 0.9182 - val_loss: 0.6368 - val_accuracy: 0.8750\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1486 - accuracy: 0.9227 - val_loss: 0.6367 - val_accuracy: 0.8929\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1485 - accuracy: 0.9227 - val_loss: 0.6452 - val_accuracy: 0.8929\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1515 - accuracy: 0.9273 - val_loss: 0.6407 - val_accuracy: 0.8750\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1497 - accuracy: 0.9182 - val_loss: 0.6379 - val_accuracy: 0.8929\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1494 - accuracy: 0.9273 - val_loss: 0.6440 - val_accuracy: 0.8929\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1517 - accuracy: 0.9136 - val_loss: 0.6557 - val_accuracy: 0.8929\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9364 - val_loss: 0.6475 - val_accuracy: 0.8929\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.1501 - accuracy: 0.9273 - val_loss: 0.6469 - val_accuracy: 0.8929\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1471 - accuracy: 0.9182 - val_loss: 0.6614 - val_accuracy: 0.8929\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1482 - accuracy: 0.9318 - val_loss: 0.6540 - val_accuracy: 0.8750\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1531 - accuracy: 0.9136 - val_loss: 0.6499 - val_accuracy: 0.9107\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1465 - accuracy: 0.9273 - val_loss: 0.6573 - val_accuracy: 0.8929\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1513 - accuracy: 0.9227 - val_loss: 0.6620 - val_accuracy: 0.8750\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1484 - accuracy: 0.9227 - val_loss: 0.6592 - val_accuracy: 0.8750\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1470 - accuracy: 0.9364 - val_loss: 0.6639 - val_accuracy: 0.9107\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1506 - accuracy: 0.9182 - val_loss: 0.6657 - val_accuracy: 0.8750\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1415 - accuracy: 0.9273 - val_loss: 0.6759 - val_accuracy: 0.9107\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1508 - accuracy: 0.9273 - val_loss: 0.6691 - val_accuracy: 0.8750\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1480 - accuracy: 0.9182 - val_loss: 0.6774 - val_accuracy: 0.8929\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1506 - accuracy: 0.9273 - val_loss: 0.6728 - val_accuracy: 0.8929\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1446 - accuracy: 0.9227 - val_loss: 0.6873 - val_accuracy: 0.8929\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1482 - accuracy: 0.9318 - val_loss: 0.6716 - val_accuracy: 0.8929\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1514 - accuracy: 0.9318 - val_loss: 0.6757 - val_accuracy: 0.9107\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1427 - accuracy: 0.9227 - val_loss: 0.6890 - val_accuracy: 0.9107\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1517 - accuracy: 0.9273 - val_loss: 0.6901 - val_accuracy: 0.8750\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1607 - accuracy: 0.9136 - val_loss: 0.6869 - val_accuracy: 0.8571\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1502 - accuracy: 0.9318 - val_loss: 0.7096 - val_accuracy: 0.8929\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1532 - accuracy: 0.9318 - val_loss: 0.6817 - val_accuracy: 0.8750\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1558 - accuracy: 0.9273 - val_loss: 0.6836 - val_accuracy: 0.8929\n",
      "Epoch 137/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1491 - accuracy: 0.9227 - val_loss: 0.7032 - val_accuracy: 0.8929\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1442 - accuracy: 0.9227 - val_loss: 0.6977 - val_accuracy: 0.8571\n",
      "Epoch 139/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1470 - accuracy: 0.9273 - val_loss: 0.6904 - val_accuracy: 0.8750\n",
      "Epoch 140/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1441 - accuracy: 0.9318 - val_loss: 0.6945 - val_accuracy: 0.8750\n",
      "Epoch 141/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1444 - accuracy: 0.9273 - val_loss: 0.7085 - val_accuracy: 0.8929\n",
      "Epoch 142/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1502 - accuracy: 0.9318 - val_loss: 0.7068 - val_accuracy: 0.8750\n",
      "Epoch 143/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1535 - accuracy: 0.9273 - val_loss: 0.6974 - val_accuracy: 0.8929\n",
      "Epoch 144/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1475 - accuracy: 0.9364 - val_loss: 0.7045 - val_accuracy: 0.8571\n",
      "Epoch 145/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1436 - accuracy: 0.9227 - val_loss: 0.7054 - val_accuracy: 0.8571\n",
      "Epoch 146/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1555 - accuracy: 0.9318 - val_loss: 0.7211 - val_accuracy: 0.8750\n",
      "Epoch 147/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1412 - accuracy: 0.9273 - val_loss: 0.7101 - val_accuracy: 0.8571\n",
      "Epoch 148/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1421 - accuracy: 0.9182 - val_loss: 0.7098 - val_accuracy: 0.8750\n",
      "Epoch 149/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1382 - accuracy: 0.9318 - val_loss: 0.7186 - val_accuracy: 0.8929\n",
      "Epoch 150/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1376 - accuracy: 0.9364 - val_loss: 0.7156 - val_accuracy: 0.8750\n",
      "Epoch 151/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1410 - accuracy: 0.9273 - val_loss: 0.7165 - val_accuracy: 0.8571\n",
      "Epoch 152/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1451 - accuracy: 0.9273 - val_loss: 0.7177 - val_accuracy: 0.8750\n",
      "Epoch 153/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1447 - accuracy: 0.9136 - val_loss: 0.7222 - val_accuracy: 0.8571\n",
      "Epoch 154/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1376 - accuracy: 0.9364 - val_loss: 0.7281 - val_accuracy: 0.8929\n",
      "Epoch 155/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1523 - accuracy: 0.9273 - val_loss: 0.7335 - val_accuracy: 0.8750\n",
      "Epoch 156/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1469 - accuracy: 0.9318 - val_loss: 0.7272 - val_accuracy: 0.8750\n",
      "Epoch 157/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1443 - accuracy: 0.9318 - val_loss: 0.7256 - val_accuracy: 0.8750\n",
      "Epoch 158/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0602 - accuracy: 0.96 - 0s 4ms/step - loss: 0.1400 - accuracy: 0.9318 - val_loss: 0.7294 - val_accuracy: 0.8750\n",
      "Epoch 159/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1367 - accuracy: 0.9318 - val_loss: 0.7365 - val_accuracy: 0.8571\n",
      "Epoch 160/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1404 - accuracy: 0.9364 - val_loss: 0.7356 - val_accuracy: 0.8571\n",
      "Epoch 161/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1400 - accuracy: 0.9273 - val_loss: 0.7278 - val_accuracy: 0.8750\n",
      "Epoch 162/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1371 - accuracy: 0.9227 - val_loss: 0.7327 - val_accuracy: 0.8750\n",
      "Epoch 163/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1360 - accuracy: 0.9364 - val_loss: 0.7370 - val_accuracy: 0.8571\n",
      "Epoch 164/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1355 - accuracy: 0.9318 - val_loss: 0.7343 - val_accuracy: 0.8750\n",
      "Epoch 165/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1446 - accuracy: 0.9318 - val_loss: 0.7492 - val_accuracy: 0.8571\n",
      "Epoch 166/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1393 - accuracy: 0.9455 - val_loss: 0.7463 - val_accuracy: 0.8571\n",
      "Epoch 167/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1380 - accuracy: 0.9409 - val_loss: 0.7400 - val_accuracy: 0.8571\n",
      "Epoch 168/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1382 - accuracy: 0.9364 - val_loss: 0.7392 - val_accuracy: 0.8571\n",
      "Epoch 169/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1366 - accuracy: 0.9227 - val_loss: 0.7444 - val_accuracy: 0.8750\n",
      "Epoch 170/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1356 - accuracy: 0.9318 - val_loss: 0.7523 - val_accuracy: 0.8750\n",
      "Epoch 171/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9364 - val_loss: 0.7495 - val_accuracy: 0.8571\n",
      "Epoch 172/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1699 - accuracy: 0.9136 - val_loss: 0.7472 - val_accuracy: 0.8393\n",
      "Epoch 173/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1483 - accuracy: 0.9227 - val_loss: 0.7849 - val_accuracy: 0.8929\n",
      "Epoch 174/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1544 - accuracy: 0.9364 - val_loss: 0.7523 - val_accuracy: 0.8571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1511 - accuracy: 0.9227 - val_loss: 0.7515 - val_accuracy: 0.8750\n",
      "Epoch 176/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1334 - accuracy: 0.9227 - val_loss: 0.7584 - val_accuracy: 0.8929\n",
      "Epoch 177/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1478 - accuracy: 0.9409 - val_loss: 0.7745 - val_accuracy: 0.8750\n",
      "Epoch 178/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1339 - accuracy: 0.9318 - val_loss: 0.7590 - val_accuracy: 0.8571\n",
      "Epoch 179/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1363 - accuracy: 0.9409 - val_loss: 0.7527 - val_accuracy: 0.8571\n",
      "Epoch 180/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1518 - accuracy: 0.9318 - val_loss: 0.7652 - val_accuracy: 0.9107\n",
      "Epoch 181/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1468 - accuracy: 0.9318 - val_loss: 0.7711 - val_accuracy: 0.8393\n",
      "Epoch 182/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1408 - accuracy: 0.9182 - val_loss: 0.7669 - val_accuracy: 0.8750\n",
      "Epoch 183/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1528 - accuracy: 0.9227 - val_loss: 0.7708 - val_accuracy: 0.8929\n",
      "Epoch 184/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1348 - accuracy: 0.9318 - val_loss: 0.7640 - val_accuracy: 0.8571\n",
      "Epoch 185/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1329 - accuracy: 0.9273 - val_loss: 0.7710 - val_accuracy: 0.8393\n",
      "Epoch 186/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1321 - accuracy: 0.9364 - val_loss: 0.7739 - val_accuracy: 0.8571\n",
      "Epoch 187/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1343 - accuracy: 0.9318 - val_loss: 0.7737 - val_accuracy: 0.8571\n",
      "Epoch 188/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1379 - accuracy: 0.9227 - val_loss: 0.7717 - val_accuracy: 0.8750\n",
      "Epoch 189/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1332 - accuracy: 0.9273 - val_loss: 0.7739 - val_accuracy: 0.8571\n",
      "Epoch 190/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1318 - accuracy: 0.9318 - val_loss: 0.7792 - val_accuracy: 0.8571\n",
      "Epoch 191/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1360 - accuracy: 0.9455 - val_loss: 0.7875 - val_accuracy: 0.8750\n",
      "Epoch 192/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1356 - accuracy: 0.9227 - val_loss: 0.7796 - val_accuracy: 0.8393\n",
      "Epoch 193/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1474 - accuracy: 0.9227 - val_loss: 0.7780 - val_accuracy: 0.8571\n",
      "Epoch 194/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1495 - accuracy: 0.9273 - val_loss: 0.7967 - val_accuracy: 0.8393\n",
      "Epoch 195/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1398 - accuracy: 0.9318 - val_loss: 0.7910 - val_accuracy: 0.8750\n",
      "Epoch 196/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1473 - accuracy: 0.9227 - val_loss: 0.7760 - val_accuracy: 0.8750\n",
      "Epoch 197/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1360 - accuracy: 0.9318 - val_loss: 0.7906 - val_accuracy: 0.8571\n",
      "Epoch 198/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1390 - accuracy: 0.9455 - val_loss: 0.8053 - val_accuracy: 0.8750\n",
      "Epoch 199/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1380 - accuracy: 0.9364 - val_loss: 0.7838 - val_accuracy: 0.8571\n",
      "Epoch 200/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1359 - accuracy: 0.9318 - val_loss: 0.7834 - val_accuracy: 0.8571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cb48e05f70>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_deaths.fit(x_train,y_train.iloc[:,-2],epochs=200,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_deaths = (lstm_deaths.predict(x_test) > 0.50).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_deaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label : Confirmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 50)                10400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                3264      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 22,113\n",
      "Trainable params: 22,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "lstm_confirmed = tf.keras.Sequential([\n",
    "                                tf.keras.layers.LSTM(50,dropout=0.2,recurrent_dropout=0.2,input_shape=(11,1)),\n",
    "                                tf.keras.layers.Dense(64,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(128,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(1,activation = 'sigmoid')])\n",
    "lstm_confirmed.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_confirmed.compile(optimizer='adam',\n",
    "              loss='BinaryCrossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7/7 [==============================] - 2s 41ms/step - loss: 0.6636 - accuracy: 0.9364 - val_loss: 0.6188 - val_accuracy: 0.9821\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.5789 - accuracy: 0.9818 - val_loss: 0.5087 - val_accuracy: 0.9821\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4363 - accuracy: 0.9818 - val_loss: 0.3245 - val_accuracy: 0.9821\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2384 - accuracy: 0.9818 - val_loss: 0.1163 - val_accuracy: 0.9821\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1089 - accuracy: 0.9818 - val_loss: 0.0690 - val_accuracy: 0.9821\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1142 - accuracy: 0.9818 - val_loss: 0.0811 - val_accuracy: 0.9821\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1125 - accuracy: 0.9818 - val_loss: 0.0844 - val_accuracy: 0.9821\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0892 - accuracy: 0.9818 - val_loss: 0.0909 - val_accuracy: 0.9821\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0923 - accuracy: 0.9818 - val_loss: 0.0925 - val_accuracy: 0.9821\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0912 - accuracy: 0.9818 - val_loss: 0.0919 - val_accuracy: 0.9821\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0886 - accuracy: 0.9818 - val_loss: 0.0851 - val_accuracy: 0.9821\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0866 - accuracy: 0.9818 - val_loss: 0.0823 - val_accuracy: 0.9821\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0877 - accuracy: 0.9818 - val_loss: 0.0816 - val_accuracy: 0.9821\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0904 - accuracy: 0.9818 - val_loss: 0.0846 - val_accuracy: 0.9821\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0855 - accuracy: 0.9818 - val_loss: 0.0826 - val_accuracy: 0.9821\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0850 - accuracy: 0.9818 - val_loss: 0.0819 - val_accuracy: 0.9821\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0872 - accuracy: 0.9818 - val_loss: 0.0809 - val_accuracy: 0.9821\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0860 - accuracy: 0.9818 - val_loss: 0.0802 - val_accuracy: 0.9821\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0898 - accuracy: 0.9818 - val_loss: 0.0802 - val_accuracy: 0.9821\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0860 - accuracy: 0.9818 - val_loss: 0.0819 - val_accuracy: 0.9821\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0853 - accuracy: 0.9818 - val_loss: 0.0821 - val_accuracy: 0.9821\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0820 - accuracy: 0.9818 - val_loss: 0.0818 - val_accuracy: 0.9821\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0876 - accuracy: 0.9818 - val_loss: 0.0788 - val_accuracy: 0.9821\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0849 - accuracy: 0.9818 - val_loss: 0.0803 - val_accuracy: 0.9821\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0834 - accuracy: 0.9818 - val_loss: 0.0805 - val_accuracy: 0.9821\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0866 - accuracy: 0.9818 - val_loss: 0.0774 - val_accuracy: 0.9821\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0855 - accuracy: 0.9818 - val_loss: 0.0733 - val_accuracy: 0.9821\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0841 - accuracy: 0.9818 - val_loss: 0.0756 - val_accuracy: 0.9821\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0839 - accuracy: 0.9818 - val_loss: 0.0759 - val_accuracy: 0.9821\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0840 - accuracy: 0.9818 - val_loss: 0.0741 - val_accuracy: 0.9821\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0812 - accuracy: 0.9818 - val_loss: 0.0756 - val_accuracy: 0.9821\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0823 - accuracy: 0.9818 - val_loss: 0.0759 - val_accuracy: 0.9821\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 1.00 - 0s 8ms/step - loss: 0.0815 - accuracy: 0.9818 - val_loss: 0.0743 - val_accuracy: 0.9821\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0844 - accuracy: 0.9818 - val_loss: 0.0731 - val_accuracy: 0.9821\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0813 - accuracy: 0.9818 - val_loss: 0.0689 - val_accuracy: 0.9821\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0863 - accuracy: 0.9818 - val_loss: 0.0686 - val_accuracy: 0.9821\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0802 - accuracy: 0.9818 - val_loss: 0.0686 - val_accuracy: 0.9821\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0814 - accuracy: 0.9818 - val_loss: 0.0723 - val_accuracy: 0.9821\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0825 - accuracy: 0.9818 - val_loss: 0.0711 - val_accuracy: 0.9821\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0863 - accuracy: 0.9818 - val_loss: 0.0737 - val_accuracy: 0.9821\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0808 - accuracy: 0.9818 - val_loss: 0.0742 - val_accuracy: 0.9821\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0827 - accuracy: 0.9818 - val_loss: 0.0750 - val_accuracy: 0.9821\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0833 - accuracy: 0.9818 - val_loss: 0.0810 - val_accuracy: 0.9821\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0879 - accuracy: 0.9818 - val_loss: 0.0868 - val_accuracy: 0.9821\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0796 - accuracy: 0.9818 - val_loss: 0.0913 - val_accuracy: 0.9821\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.9818 - val_loss: 0.0874 - val_accuracy: 0.9821\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0774 - accuracy: 0.9818 - val_loss: 0.0770 - val_accuracy: 0.9821\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0867 - accuracy: 0.9818 - val_loss: 0.0755 - val_accuracy: 0.9821\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0768 - accuracy: 0.9818 - val_loss: 0.0736 - val_accuracy: 0.9821\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0795 - accuracy: 0.9818 - val_loss: 0.0706 - val_accuracy: 0.9821\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0815 - accuracy: 0.9818 - val_loss: 0.0725 - val_accuracy: 0.9821\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0854 - accuracy: 0.9818 - val_loss: 0.0711 - val_accuracy: 0.9821\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0848 - accuracy: 0.9818 - val_loss: 0.0683 - val_accuracy: 0.9821\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0792 - accuracy: 0.9818 - val_loss: 0.0662 - val_accuracy: 0.9821\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0783 - accuracy: 0.9818 - val_loss: 0.0681 - val_accuracy: 0.9821\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0862 - accuracy: 0.9818 - val_loss: 0.0748 - val_accuracy: 0.9821\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0776 - accuracy: 0.9818 - val_loss: 0.0815 - val_accuracy: 0.9821\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0811 - accuracy: 0.9818 - val_loss: 0.0830 - val_accuracy: 0.9821\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0799 - accuracy: 0.9818 - val_loss: 0.0827 - val_accuracy: 0.9821\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0886 - accuracy: 0.9818 - val_loss: 0.0877 - val_accuracy: 0.9821\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0778 - accuracy: 0.9818 - val_loss: 0.0797 - val_accuracy: 0.9821\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0794 - accuracy: 0.9818 - val_loss: 0.0763 - val_accuracy: 0.9821\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0768 - accuracy: 0.9818 - val_loss: 0.0672 - val_accuracy: 0.9821\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0781 - accuracy: 0.9818 - val_loss: 0.0602 - val_accuracy: 0.9821\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0687 - accuracy: 0.9818 - val_loss: 0.0599 - val_accuracy: 0.9821\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0773 - accuracy: 0.9818 - val_loss: 0.0652 - val_accuracy: 0.9821\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0837 - accuracy: 0.9818 - val_loss: 0.0645 - val_accuracy: 0.9821\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0861 - accuracy: 0.9818 - val_loss: 0.0654 - val_accuracy: 0.9821\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0702 - accuracy: 0.9818 - val_loss: 0.0652 - val_accuracy: 0.9821\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0749 - accuracy: 0.9818 - val_loss: 0.0649 - val_accuracy: 0.9821\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0814 - accuracy: 0.9818 - val_loss: 0.0654 - val_accuracy: 0.9821\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0768 - accuracy: 0.9818 - val_loss: 0.0729 - val_accuracy: 0.9821\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0726 - accuracy: 0.9818 - val_loss: 0.0807 - val_accuracy: 0.9821\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0830 - accuracy: 0.9818 - val_loss: 0.0812 - val_accuracy: 0.9821\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0741 - accuracy: 0.9818 - val_loss: 0.0682 - val_accuracy: 0.9821\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0903 - accuracy: 0.9818 - val_loss: 0.0627 - val_accuracy: 0.9821\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0760 - accuracy: 0.9818 - val_loss: 0.0652 - val_accuracy: 0.9821\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0794 - accuracy: 0.9818 - val_loss: 0.0673 - val_accuracy: 0.9821\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0882 - accuracy: 0.9818 - val_loss: 0.0615 - val_accuracy: 0.9821\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0812 - accuracy: 0.9818 - val_loss: 0.0600 - val_accuracy: 0.9821\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0775 - accuracy: 0.9818 - val_loss: 0.0599 - val_accuracy: 0.9821\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0766 - accuracy: 0.9818 - val_loss: 0.0690 - val_accuracy: 0.9821\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0788 - accuracy: 0.9818 - val_loss: 0.0804 - val_accuracy: 0.9821\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0802 - accuracy: 0.9818 - val_loss: 0.0974 - val_accuracy: 0.9821\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0882 - accuracy: 0.9818 - val_loss: 0.0772 - val_accuracy: 0.9821\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0784 - accuracy: 0.9818 - val_loss: 0.0603 - val_accuracy: 0.9821\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0797 - accuracy: 0.9818 - val_loss: 0.0678 - val_accuracy: 0.9821\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0719 - accuracy: 0.9818 - val_loss: 0.0664 - val_accuracy: 0.9821\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0820 - accuracy: 0.9818 - val_loss: 0.0638 - val_accuracy: 0.9821\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0741 - accuracy: 0.9818 - val_loss: 0.0652 - val_accuracy: 0.9821\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0746 - accuracy: 0.9818 - val_loss: 0.0652 - val_accuracy: 0.9821\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0848 - accuracy: 0.9818 - val_loss: 0.0693 - val_accuracy: 0.9821\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0695 - accuracy: 0.9818 - val_loss: 0.0797 - val_accuracy: 0.9821\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0820 - accuracy: 0.9818 - val_loss: 0.0675 - val_accuracy: 0.9821\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0847 - accuracy: 0.9818 - val_loss: 0.0743 - val_accuracy: 0.9821\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0710 - accuracy: 0.9818 - val_loss: 0.0768 - val_accuracy: 0.9821\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0728 - accuracy: 0.9818 - val_loss: 0.0809 - val_accuracy: 0.9821\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0713 - accuracy: 0.9818 - val_loss: 0.0799 - val_accuracy: 0.9821\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0740 - accuracy: 0.9818 - val_loss: 0.0845 - val_accuracy: 0.9821\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0723 - accuracy: 0.9818 - val_loss: 0.0984 - val_accuracy: 0.9821\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0745 - accuracy: 0.9818 - val_loss: 0.1139 - val_accuracy: 0.9821\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0846 - accuracy: 0.9818 - val_loss: 0.0783 - val_accuracy: 0.9821\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0688 - accuracy: 0.9818 - val_loss: 0.0645 - val_accuracy: 0.9821\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0694 - accuracy: 0.9818 - val_loss: 0.0623 - val_accuracy: 0.9821\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0775 - accuracy: 0.9818 - val_loss: 0.0615 - val_accuracy: 0.9821\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0705 - accuracy: 0.9818 - val_loss: 0.0605 - val_accuracy: 0.9821\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0694 - accuracy: 0.9818 - val_loss: 0.0588 - val_accuracy: 0.9821\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0950 - accuracy: 0.9818 - val_loss: 0.0610 - val_accuracy: 0.9821\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0707 - accuracy: 0.9818 - val_loss: 0.0686 - val_accuracy: 0.9821\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0770 - accuracy: 0.9818 - val_loss: 0.0782 - val_accuracy: 0.9821\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0662 - accuracy: 0.9818 - val_loss: 0.0896 - val_accuracy: 0.9821\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0673 - accuracy: 0.9818 - val_loss: 0.0947 - val_accuracy: 0.9821\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0703 - accuracy: 0.9818 - val_loss: 0.0667 - val_accuracy: 0.9821\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0796 - accuracy: 0.9818 - val_loss: 0.0687 - val_accuracy: 0.9821\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0840 - accuracy: 0.9818 - val_loss: 0.0760 - val_accuracy: 0.9821\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0903 - accuracy: 0.9818 - val_loss: 0.0964 - val_accuracy: 0.9821\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0731 - accuracy: 0.9818 - val_loss: 0.0979 - val_accuracy: 0.9821\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0689 - accuracy: 0.9818 - val_loss: 0.0724 - val_accuracy: 0.9821\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0734 - accuracy: 0.9818 - val_loss: 0.0649 - val_accuracy: 0.9821\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0722 - accuracy: 0.9818 - val_loss: 0.0718 - val_accuracy: 0.9821\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0689 - accuracy: 0.9818 - val_loss: 0.0938 - val_accuracy: 0.9821\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0912 - accuracy: 0.9818 - val_loss: 0.1161 - val_accuracy: 0.9821\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0722 - accuracy: 0.9818 - val_loss: 0.0978 - val_accuracy: 0.9821\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0853 - accuracy: 0.9818 - val_loss: 0.0752 - val_accuracy: 0.9821\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0742 - accuracy: 0.9818 - val_loss: 0.0669 - val_accuracy: 0.9821\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0716 - accuracy: 0.9818 - val_loss: 0.0591 - val_accuracy: 0.9821\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0626 - accuracy: 0.9818 - val_loss: 0.0538 - val_accuracy: 0.9821\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0722 - accuracy: 0.9818 - val_loss: 0.0564 - val_accuracy: 0.9821\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0703 - accuracy: 0.9818 - val_loss: 0.0645 - val_accuracy: 0.9821\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0618 - accuracy: 0.9818 - val_loss: 0.0686 - val_accuracy: 0.9821\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0647 - accuracy: 0.9818 - val_loss: 0.0539 - val_accuracy: 0.9821\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0818 - accuracy: 0.9818 - val_loss: 0.0530 - val_accuracy: 0.9821\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0801 - accuracy: 0.9818 - val_loss: 0.0621 - val_accuracy: 0.9821\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0782 - accuracy: 0.9818 - val_loss: 0.0626 - val_accuracy: 0.9821\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0632 - accuracy: 0.9818 - val_loss: 0.0715 - val_accuracy: 0.9821\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0746 - accuracy: 0.9818 - val_loss: 0.0867 - val_accuracy: 0.9821\n",
      "Epoch 137/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0617 - accuracy: 0.9818 - val_loss: 0.0832 - val_accuracy: 0.9821\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0798 - accuracy: 0.9818 - val_loss: 0.0857 - val_accuracy: 0.9821\n",
      "Epoch 139/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0819 - accuracy: 0.9818 - val_loss: 0.0547 - val_accuracy: 0.9821\n",
      "Epoch 140/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1019 - accuracy: 0.9818 - val_loss: 0.0563 - val_accuracy: 0.9821\n",
      "Epoch 141/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0660 - accuracy: 0.9818 - val_loss: 0.0544 - val_accuracy: 0.9821\n",
      "Epoch 142/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0720 - accuracy: 0.9818 - val_loss: 0.0531 - val_accuracy: 0.9821\n",
      "Epoch 143/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0641 - accuracy: 0.9818 - val_loss: 0.0538 - val_accuracy: 0.9821\n",
      "Epoch 144/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0731 - accuracy: 0.9818 - val_loss: 0.0610 - val_accuracy: 0.9821\n",
      "Epoch 145/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0558 - accuracy: 0.9818 - val_loss: 0.0683 - val_accuracy: 0.9821\n",
      "Epoch 146/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0598 - accuracy: 0.9818 - val_loss: 0.0626 - val_accuracy: 0.9821\n",
      "Epoch 147/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0860 - accuracy: 0.9818 - val_loss: 0.0465 - val_accuracy: 0.9821\n",
      "Epoch 148/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0828 - accuracy: 0.9818 - val_loss: 0.0581 - val_accuracy: 0.9821\n",
      "Epoch 149/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0696 - accuracy: 0.9818 - val_loss: 0.0696 - val_accuracy: 0.9821\n",
      "Epoch 150/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0737 - accuracy: 0.9818 - val_loss: 0.0636 - val_accuracy: 0.9821\n",
      "Epoch 151/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0730 - accuracy: 0.9818 - val_loss: 0.0622 - val_accuracy: 0.9821\n",
      "Epoch 152/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0677 - accuracy: 0.9818 - val_loss: 0.0608 - val_accuracy: 0.9821\n",
      "Epoch 153/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0619 - accuracy: 0.9818 - val_loss: 0.0666 - val_accuracy: 0.9821\n",
      "Epoch 154/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0652 - accuracy: 0.9818 - val_loss: 0.0754 - val_accuracy: 0.9821\n",
      "Epoch 155/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0614 - accuracy: 0.9818 - val_loss: 0.0727 - val_accuracy: 0.9821\n",
      "Epoch 156/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0583 - accuracy: 0.9818 - val_loss: 0.0681 - val_accuracy: 0.9821\n",
      "Epoch 157/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0604 - accuracy: 0.9818 - val_loss: 0.0657 - val_accuracy: 0.9821\n",
      "Epoch 158/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0738 - accuracy: 0.9818 - val_loss: 0.0671 - val_accuracy: 0.9821\n",
      "Epoch 159/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0774 - accuracy: 0.9818 - val_loss: 0.0752 - val_accuracy: 0.9821\n",
      "Epoch 160/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0722 - accuracy: 0.9818 - val_loss: 0.0886 - val_accuracy: 0.9821\n",
      "Epoch 161/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0698 - accuracy: 0.9818 - val_loss: 0.0888 - val_accuracy: 0.9821\n",
      "Epoch 162/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0858 - accuracy: 0.9818 - val_loss: 0.0956 - val_accuracy: 0.9821\n",
      "Epoch 163/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0636 - accuracy: 0.9818 - val_loss: 0.0882 - val_accuracy: 0.9821\n",
      "Epoch 164/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0715 - accuracy: 0.9818 - val_loss: 0.0876 - val_accuracy: 0.9821\n",
      "Epoch 165/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0812 - accuracy: 0.9818 - val_loss: 0.0822 - val_accuracy: 0.9821\n",
      "Epoch 166/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0725 - accuracy: 0.9818 - val_loss: 0.0725 - val_accuracy: 0.9821\n",
      "Epoch 167/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0571 - accuracy: 0.9818 - val_loss: 0.0650 - val_accuracy: 0.9821\n",
      "Epoch 168/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0544 - accuracy: 0.9818 - val_loss: 0.0607 - val_accuracy: 0.9821\n",
      "Epoch 169/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0732 - accuracy: 0.9818 - val_loss: 0.0674 - val_accuracy: 0.9821\n",
      "Epoch 170/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0595 - accuracy: 0.9818 - val_loss: 0.0751 - val_accuracy: 0.9821\n",
      "Epoch 171/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0806 - accuracy: 0.9818 - val_loss: 0.0923 - val_accuracy: 0.9821\n",
      "Epoch 172/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0730 - accuracy: 0.9818 - val_loss: 0.0776 - val_accuracy: 0.9821\n",
      "Epoch 173/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0574 - accuracy: 0.9818 - val_loss: 0.0636 - val_accuracy: 0.9821\n",
      "Epoch 174/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0923 - accuracy: 0.9818 - val_loss: 0.0640 - val_accuracy: 0.9821\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0818 - accuracy: 0.9818 - val_loss: 0.0786 - val_accuracy: 0.9821\n",
      "Epoch 176/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0827 - accuracy: 0.9818 - val_loss: 0.0840 - val_accuracy: 0.9821\n",
      "Epoch 177/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0750 - accuracy: 0.9818 - val_loss: 0.0828 - val_accuracy: 0.9821\n",
      "Epoch 178/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0743 - accuracy: 0.9818 - val_loss: 0.0818 - val_accuracy: 0.9821\n",
      "Epoch 179/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0593 - accuracy: 0.9818 - val_loss: 0.0875 - val_accuracy: 0.9821\n",
      "Epoch 180/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0826 - accuracy: 0.9818 - val_loss: 0.0995 - val_accuracy: 0.9821\n",
      "Epoch 181/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0641 - accuracy: 0.9818 - val_loss: 0.0982 - val_accuracy: 0.9821\n",
      "Epoch 182/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0731 - accuracy: 0.9818 - val_loss: 0.0636 - val_accuracy: 0.9821\n",
      "Epoch 183/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0819 - accuracy: 0.9818 - val_loss: 0.0518 - val_accuracy: 0.9821\n",
      "Epoch 184/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0658 - accuracy: 0.9818 - val_loss: 0.0501 - val_accuracy: 0.9821\n",
      "Epoch 185/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0726 - accuracy: 0.9818 - val_loss: 0.0657 - val_accuracy: 0.9821\n",
      "Epoch 186/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0743 - accuracy: 0.9818 - val_loss: 0.0608 - val_accuracy: 0.9821\n",
      "Epoch 187/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0686 - accuracy: 0.9818 - val_loss: 0.0595 - val_accuracy: 0.9821\n",
      "Epoch 188/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0669 - accuracy: 0.9818 - val_loss: 0.0641 - val_accuracy: 0.9821\n",
      "Epoch 189/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0750 - accuracy: 0.9818 - val_loss: 0.0705 - val_accuracy: 0.9821\n",
      "Epoch 190/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0741 - accuracy: 0.9818 - val_loss: 0.0647 - val_accuracy: 0.9821\n",
      "Epoch 191/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0735 - accuracy: 0.9818 - val_loss: 0.0677 - val_accuracy: 0.9821\n",
      "Epoch 192/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0757 - accuracy: 0.9818 - val_loss: 0.0811 - val_accuracy: 0.9821\n",
      "Epoch 193/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0605 - accuracy: 0.9818 - val_loss: 0.0756 - val_accuracy: 0.9821\n",
      "Epoch 194/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0621 - accuracy: 0.9818 - val_loss: 0.0627 - val_accuracy: 0.9821\n",
      "Epoch 195/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0747 - accuracy: 0.9818 - val_loss: 0.0716 - val_accuracy: 0.9821\n",
      "Epoch 196/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0713 - accuracy: 0.9818 - val_loss: 0.0784 - val_accuracy: 0.9821\n",
      "Epoch 197/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0668 - accuracy: 0.9818 - val_loss: 0.0827 - val_accuracy: 0.9821\n",
      "Epoch 198/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0694 - accuracy: 0.9818 - val_loss: 0.0813 - val_accuracy: 0.9821\n",
      "Epoch 199/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0696 - accuracy: 0.9818 - val_loss: 0.0774 - val_accuracy: 0.9821\n",
      "Epoch 200/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0732 - accuracy: 0.9818 - val_loss: 0.0681 - val_accuracy: 0.9821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cb49fb0910>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_confirmed.fit(x_train1,y_train.iloc[:,-3],epochs=200,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_confirmed = (lstm_confirmed.predict(x_test1) > 0.50).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['Id'] = df.loc[:,'Id']\n",
    "new_df['Confirmed'] = predicted_confirmed\n",
    "new_df['Deaths'] = predicted_deaths\n",
    "new_df['Recovered'] = predicted_recovered.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"Kagglepred_assgn3.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
