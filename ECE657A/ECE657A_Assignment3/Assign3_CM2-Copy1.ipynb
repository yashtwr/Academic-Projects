{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading cleaned and normalized dataset\n",
    "load_dataset = pd.read_csv(\"cleaned_normalized_coviddata.csv\")\n",
    "df = load_dataset.iloc[:,3:]\n",
    "# Splitting the data into input and output values\n",
    "x=df.iloc[:,:-3]\n",
    "y=df.iloc[:,-3:].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data in training and testing dataset\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1104, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP on input dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label: Recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                240       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 681\n",
      "Trainable params: 681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "mlp_recovered = tf.keras.Sequential([     tf.keras.Input(shape=(11,)),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(1,activation = 'sigmoid')])\n",
    "mlp_recovered.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_recovered.compile(optimizer='adam',\n",
    "              loss='BinaryCrossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28/28 [==============================] - 2s 18ms/step - loss: 0.6816 - accuracy: 0.6149 - val_loss: 0.6476 - val_accuracy: 0.6516\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.6772 - val_loss: 0.5804 - val_accuracy: 0.6787\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.5479 - accuracy: 0.7089 - val_loss: 0.5459 - val_accuracy: 0.6968\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.5131 - accuracy: 0.7452 - val_loss: 0.5138 - val_accuracy: 0.7421\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4790 - accuracy: 0.7633 - val_loss: 0.4870 - val_accuracy: 0.7602\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.4510 - accuracy: 0.7916 - val_loss: 0.4618 - val_accuracy: 0.7919\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.8154 - val_loss: 0.4391 - val_accuracy: 0.8100\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4009 - accuracy: 0.8335 - val_loss: 0.4211 - val_accuracy: 0.8190\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3820 - accuracy: 0.8392 - val_loss: 0.4061 - val_accuracy: 0.8145\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3656 - accuracy: 0.8437 - val_loss: 0.3918 - val_accuracy: 0.8100\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3522 - accuracy: 0.8482 - val_loss: 0.3845 - val_accuracy: 0.8009\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3388 - accuracy: 0.8584 - val_loss: 0.3681 - val_accuracy: 0.8326\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3287 - accuracy: 0.8618 - val_loss: 0.3580 - val_accuracy: 0.8371\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3198 - accuracy: 0.8652 - val_loss: 0.3505 - val_accuracy: 0.8552\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3102 - accuracy: 0.8856 - val_loss: 0.3382 - val_accuracy: 0.8643\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3022 - accuracy: 0.9003 - val_loss: 0.3326 - val_accuracy: 0.8778\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2951 - accuracy: 0.8992 - val_loss: 0.3241 - val_accuracy: 0.8824\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2888 - accuracy: 0.9071 - val_loss: 0.3192 - val_accuracy: 0.8869\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2828 - accuracy: 0.9083 - val_loss: 0.3113 - val_accuracy: 0.8914\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2772 - accuracy: 0.9094 - val_loss: 0.3047 - val_accuracy: 0.8914\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2733 - accuracy: 0.9151 - val_loss: 0.2993 - val_accuracy: 0.9050\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2669 - accuracy: 0.9139 - val_loss: 0.2927 - val_accuracy: 0.9140\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2616 - accuracy: 0.9207 - val_loss: 0.2884 - val_accuracy: 0.9050\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2579 - accuracy: 0.9230 - val_loss: 0.2842 - val_accuracy: 0.9095\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2528 - accuracy: 0.9230 - val_loss: 0.2799 - val_accuracy: 0.9140\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2521 - accuracy: 0.9253 - val_loss: 0.2784 - val_accuracy: 0.9050\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2465 - accuracy: 0.9264 - val_loss: 0.2720 - val_accuracy: 0.9140\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2418 - accuracy: 0.9253 - val_loss: 0.2685 - val_accuracy: 0.9095\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2410 - accuracy: 0.9230 - val_loss: 0.2621 - val_accuracy: 0.9276\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2370 - accuracy: 0.9332 - val_loss: 0.2621 - val_accuracy: 0.9321\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2343 - accuracy: 0.9320 - val_loss: 0.2573 - val_accuracy: 0.9367\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2300 - accuracy: 0.9320 - val_loss: 0.2566 - val_accuracy: 0.9231\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2319 - accuracy: 0.9298 - val_loss: 0.2527 - val_accuracy: 0.9367\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2239 - accuracy: 0.9332 - val_loss: 0.2512 - val_accuracy: 0.9276\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.2196 - accuracy: 0.93 - 0s 4ms/step - loss: 0.2216 - accuracy: 0.9332 - val_loss: 0.2439 - val_accuracy: 0.9367\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2194 - accuracy: 0.9332 - val_loss: 0.2448 - val_accuracy: 0.9321\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2168 - accuracy: 0.9343 - val_loss: 0.2424 - val_accuracy: 0.9321\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2165 - accuracy: 0.9343 - val_loss: 0.2395 - val_accuracy: 0.9367\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2135 - accuracy: 0.9343 - val_loss: 0.2381 - val_accuracy: 0.9321\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2115 - accuracy: 0.9354 - val_loss: 0.2340 - val_accuracy: 0.9367\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2091 - accuracy: 0.9366 - val_loss: 0.2359 - val_accuracy: 0.9231\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2071 - accuracy: 0.9366 - val_loss: 0.2314 - val_accuracy: 0.9367\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2065 - accuracy: 0.9354 - val_loss: 0.2302 - val_accuracy: 0.9321\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2050 - accuracy: 0.9366 - val_loss: 0.2284 - val_accuracy: 0.9367\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2018 - accuracy: 0.9366 - val_loss: 0.2275 - val_accuracy: 0.9367\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2007 - accuracy: 0.9366 - val_loss: 0.2252 - val_accuracy: 0.9321\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1978 - accuracy: 0.9366 - val_loss: 0.2235 - val_accuracy: 0.9321\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1997 - accuracy: 0.9366 - val_loss: 0.2199 - val_accuracy: 0.9367\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1971 - accuracy: 0.9354 - val_loss: 0.2215 - val_accuracy: 0.9367\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1951 - accuracy: 0.9366 - val_loss: 0.2220 - val_accuracy: 0.9321\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1950 - accuracy: 0.9366 - val_loss: 0.2206 - val_accuracy: 0.9321\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1929 - accuracy: 0.9366 - val_loss: 0.2183 - val_accuracy: 0.9321\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1908 - accuracy: 0.9366 - val_loss: 0.2185 - val_accuracy: 0.9367\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1891 - accuracy: 0.9354 - val_loss: 0.2163 - val_accuracy: 0.9367\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1877 - accuracy: 0.9366 - val_loss: 0.2160 - val_accuracy: 0.9412\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1862 - accuracy: 0.9366 - val_loss: 0.2151 - val_accuracy: 0.9412\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1861 - accuracy: 0.9354 - val_loss: 0.2132 - val_accuracy: 0.9412\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.1834 - accuracy: 0.93 - 0s 4ms/step - loss: 0.1845 - accuracy: 0.9366 - val_loss: 0.2134 - val_accuracy: 0.9412\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1851 - accuracy: 0.9366 - val_loss: 0.2144 - val_accuracy: 0.9367\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1840 - accuracy: 0.9366 - val_loss: 0.2115 - val_accuracy: 0.9412\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1820 - accuracy: 0.9366 - val_loss: 0.2155 - val_accuracy: 0.9367\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1819 - accuracy: 0.9366 - val_loss: 0.2116 - val_accuracy: 0.9367\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1809 - accuracy: 0.9377 - val_loss: 0.2101 - val_accuracy: 0.9412\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1803 - accuracy: 0.9366 - val_loss: 0.2103 - val_accuracy: 0.9412\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1792 - accuracy: 0.9366 - val_loss: 0.2106 - val_accuracy: 0.9321\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1785 - accuracy: 0.9377 - val_loss: 0.2089 - val_accuracy: 0.9412\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1788 - accuracy: 0.9377 - val_loss: 0.2091 - val_accuracy: 0.9276\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1771 - accuracy: 0.9366 - val_loss: 0.2121 - val_accuracy: 0.9367\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1758 - accuracy: 0.9366 - val_loss: 0.2106 - val_accuracy: 0.9321\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1746 - accuracy: 0.9388 - val_loss: 0.2093 - val_accuracy: 0.9412\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1750 - accuracy: 0.9400 - val_loss: 0.2057 - val_accuracy: 0.9367\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1734 - accuracy: 0.9388 - val_loss: 0.2093 - val_accuracy: 0.9367\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1724 - accuracy: 0.9366 - val_loss: 0.2081 - val_accuracy: 0.9412\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1724 - accuracy: 0.9400 - val_loss: 0.2090 - val_accuracy: 0.9412\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1716 - accuracy: 0.9388 - val_loss: 0.2092 - val_accuracy: 0.9367\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1729 - accuracy: 0.9422 - val_loss: 0.2073 - val_accuracy: 0.9412\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1716 - accuracy: 0.9354 - val_loss: 0.2104 - val_accuracy: 0.9412\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1699 - accuracy: 0.9377 - val_loss: 0.2081 - val_accuracy: 0.9367\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1752 - accuracy: 0.9411 - val_loss: 0.2063 - val_accuracy: 0.9321\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1708 - accuracy: 0.9411 - val_loss: 0.2056 - val_accuracy: 0.9412\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1687 - accuracy: 0.9377 - val_loss: 0.2092 - val_accuracy: 0.9412\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1676 - accuracy: 0.9377 - val_loss: 0.2074 - val_accuracy: 0.9412\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1694 - accuracy: 0.9411 - val_loss: 0.2075 - val_accuracy: 0.9321\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1738 - accuracy: 0.9377 - val_loss: 0.2148 - val_accuracy: 0.9412\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1678 - accuracy: 0.9400 - val_loss: 0.2064 - val_accuracy: 0.9412\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1693 - accuracy: 0.9388 - val_loss: 0.2105 - val_accuracy: 0.9412\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1685 - accuracy: 0.9400 - val_loss: 0.2081 - val_accuracy: 0.9412\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1673 - accuracy: 0.9400 - val_loss: 0.2085 - val_accuracy: 0.9367\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1674 - accuracy: 0.9377 - val_loss: 0.2098 - val_accuracy: 0.9321\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1683 - accuracy: 0.9400 - val_loss: 0.2138 - val_accuracy: 0.9367\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1644 - accuracy: 0.9422 - val_loss: 0.2068 - val_accuracy: 0.9321\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1663 - accuracy: 0.9366 - val_loss: 0.2093 - val_accuracy: 0.9412\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1657 - accuracy: 0.9388 - val_loss: 0.2077 - val_accuracy: 0.9367\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1666 - accuracy: 0.9388 - val_loss: 0.2088 - val_accuracy: 0.9367\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1669 - accuracy: 0.9377 - val_loss: 0.2089 - val_accuracy: 0.9367\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1641 - accuracy: 0.9400 - val_loss: 0.2089 - val_accuracy: 0.9412\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1656 - accuracy: 0.9388 - val_loss: 0.2087 - val_accuracy: 0.9367\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1653 - accuracy: 0.9400 - val_loss: 0.2118 - val_accuracy: 0.9412\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1651 - accuracy: 0.9400 - val_loss: 0.2091 - val_accuracy: 0.9367\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1653 - accuracy: 0.9400 - val_loss: 0.2113 - val_accuracy: 0.9367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1caa03a98e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_recovered.fit(x_train,y_train.iloc[:,-1],epochs = 100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1574 - accuracy: 0.9457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15743856132030487, 0.945652186870575]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_recovered.evaluate(x_test,y_test.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mlp_recovered.predict(x_test)>0.5).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label: Deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_deaths = pd.read_csv('cleaned_deaths_coviddata.csv')\n",
    "x_dtrain,x_dtest,y_dtrain,y_dtest = train_test_split(pd_deaths.iloc[:,:-1],pd_deaths.iloc[:,-1],test_size = 0.2,random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                480       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,321\n",
      "Trainable params: 1,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "mlp_deaths = tf.keras.Sequential([     tf.keras.Input(shape=(11,)),\n",
    "                                tf.keras.layers.Dense(40,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(1,activation = 'sigmoid')])\n",
    "mlp_deaths.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_deaths.compile(optimizer='adam',\n",
    "              loss='BinaryCrossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.6031 - accuracy: 0.6828 - val_loss: 0.5473 - val_accuracy: 0.7387\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5269 - accuracy: 0.7155 - val_loss: 0.5083 - val_accuracy: 0.6985\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.7663 - val_loss: 0.4748 - val_accuracy: 0.7714\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7795 - val_loss: 0.4616 - val_accuracy: 0.7764\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7883 - val_loss: 0.4440 - val_accuracy: 0.8015\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7852 - val_loss: 0.4409 - val_accuracy: 0.7764\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7952 - val_loss: 0.4366 - val_accuracy: 0.7990\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.8034 - val_loss: 0.4330 - val_accuracy: 0.7965\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.8040 - val_loss: 0.4254 - val_accuracy: 0.8065\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.8172 - val_loss: 0.4201 - val_accuracy: 0.8065\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.8317 - val_loss: 0.4154 - val_accuracy: 0.8191\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8342 - val_loss: 0.4087 - val_accuracy: 0.8367\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.4019 - accuracy: 0.8361 - val_loss: 0.4028 - val_accuracy: 0.8518\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.3986 - accuracy: 0.8386 - val_loss: 0.4015 - val_accuracy: 0.8543\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3932 - accuracy: 0.8411 - val_loss: 0.3983 - val_accuracy: 0.8518\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3887 - accuracy: 0.8405 - val_loss: 0.4114 - val_accuracy: 0.8241\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3890 - accuracy: 0.8411 - val_loss: 0.3970 - val_accuracy: 0.8442\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3854 - accuracy: 0.8455 - val_loss: 0.3943 - val_accuracy: 0.8543\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3844 - accuracy: 0.8430 - val_loss: 0.3862 - val_accuracy: 0.8543\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3822 - accuracy: 0.8436 - val_loss: 0.3879 - val_accuracy: 0.8543\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3765 - accuracy: 0.8499 - val_loss: 0.3869 - val_accuracy: 0.8543\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3802 - accuracy: 0.8461 - val_loss: 0.3841 - val_accuracy: 0.8568\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3754 - accuracy: 0.8492 - val_loss: 0.3890 - val_accuracy: 0.8518\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3760 - accuracy: 0.8455 - val_loss: 0.3851 - val_accuracy: 0.8568\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3716 - accuracy: 0.8436 - val_loss: 0.3816 - val_accuracy: 0.8593\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3724 - accuracy: 0.8455 - val_loss: 0.3912 - val_accuracy: 0.8467\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3728 - accuracy: 0.8411 - val_loss: 0.3846 - val_accuracy: 0.8568\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3679 - accuracy: 0.8492 - val_loss: 0.3765 - val_accuracy: 0.8568\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3682 - accuracy: 0.8480 - val_loss: 0.3813 - val_accuracy: 0.8543\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3657 - accuracy: 0.8474 - val_loss: 0.3815 - val_accuracy: 0.8593\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3659 - accuracy: 0.8430 - val_loss: 0.3868 - val_accuracy: 0.8568\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3629 - accuracy: 0.8511 - val_loss: 0.3967 - val_accuracy: 0.8291\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3640 - accuracy: 0.8461 - val_loss: 0.3756 - val_accuracy: 0.8568\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3611 - accuracy: 0.8474 - val_loss: 0.3739 - val_accuracy: 0.8593\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3595 - accuracy: 0.8467 - val_loss: 0.3721 - val_accuracy: 0.8568\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.3599 - accuracy: 0.8448 - val_loss: 0.3749 - val_accuracy: 0.8593\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3588 - accuracy: 0.8518 - val_loss: 0.3688 - val_accuracy: 0.8593\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3560 - accuracy: 0.8499 - val_loss: 0.3725 - val_accuracy: 0.8593\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3565 - accuracy: 0.8518 - val_loss: 0.3752 - val_accuracy: 0.8593\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3576 - accuracy: 0.8480 - val_loss: 0.3685 - val_accuracy: 0.8568\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3559 - accuracy: 0.8486 - val_loss: 0.3718 - val_accuracy: 0.8618\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3537 - accuracy: 0.8499 - val_loss: 0.3682 - val_accuracy: 0.8618\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3512 - accuracy: 0.8530 - val_loss: 0.3743 - val_accuracy: 0.8593\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3538 - accuracy: 0.8543 - val_loss: 0.3737 - val_accuracy: 0.8618\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3534 - accuracy: 0.8530 - val_loss: 0.3655 - val_accuracy: 0.8568\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3496 - accuracy: 0.8467 - val_loss: 0.3657 - val_accuracy: 0.8568\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3520 - accuracy: 0.8480 - val_loss: 0.3626 - val_accuracy: 0.8618\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3495 - accuracy: 0.8518 - val_loss: 0.3642 - val_accuracy: 0.8518\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3469 - accuracy: 0.8492 - val_loss: 0.3681 - val_accuracy: 0.8568\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3469 - accuracy: 0.8524 - val_loss: 0.3688 - val_accuracy: 0.8568\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.3473 - accuracy: 0.8549 - val_loss: 0.3570 - val_accuracy: 0.8618\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3463 - accuracy: 0.8524 - val_loss: 0.3655 - val_accuracy: 0.8543\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3445 - accuracy: 0.8499 - val_loss: 0.3626 - val_accuracy: 0.8593\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3439 - accuracy: 0.8511 - val_loss: 0.3596 - val_accuracy: 0.8618\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3433 - accuracy: 0.8555 - val_loss: 0.3861 - val_accuracy: 0.8392\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3443 - accuracy: 0.8536 - val_loss: 0.3744 - val_accuracy: 0.8618\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3448 - accuracy: 0.8549 - val_loss: 0.3803 - val_accuracy: 0.8492\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3458 - accuracy: 0.8555 - val_loss: 0.3617 - val_accuracy: 0.8593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3500 - accuracy: 0.8492 - val_loss: 0.3588 - val_accuracy: 0.8442\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3427 - accuracy: 0.8511 - val_loss: 0.3634 - val_accuracy: 0.8568\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3430 - accuracy: 0.8543 - val_loss: 0.3681 - val_accuracy: 0.8593\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3395 - accuracy: 0.8530 - val_loss: 0.3612 - val_accuracy: 0.8593\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3389 - accuracy: 0.8562 - val_loss: 0.3644 - val_accuracy: 0.8543\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3381 - accuracy: 0.8530 - val_loss: 0.3538 - val_accuracy: 0.8568\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3413 - accuracy: 0.8524 - val_loss: 0.3574 - val_accuracy: 0.8593\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3404 - accuracy: 0.8555 - val_loss: 0.3561 - val_accuracy: 0.8593\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3389 - accuracy: 0.8543 - val_loss: 0.3615 - val_accuracy: 0.8568\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3378 - accuracy: 0.8524 - val_loss: 0.3603 - val_accuracy: 0.8618\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3373 - accuracy: 0.8505 - val_loss: 0.3601 - val_accuracy: 0.8593\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3358 - accuracy: 0.8543 - val_loss: 0.3600 - val_accuracy: 0.8543\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3393 - accuracy: 0.8562 - val_loss: 0.3582 - val_accuracy: 0.8593\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3397 - accuracy: 0.8461 - val_loss: 0.3567 - val_accuracy: 0.8543\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3352 - accuracy: 0.8555 - val_loss: 0.3559 - val_accuracy: 0.8593\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3352 - accuracy: 0.8530 - val_loss: 0.3624 - val_accuracy: 0.8618\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3339 - accuracy: 0.8549 - val_loss: 0.3511 - val_accuracy: 0.8593\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3339 - accuracy: 0.8574 - val_loss: 0.3554 - val_accuracy: 0.8568\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.3349 - accuracy: 0.8562 - val_loss: 0.3583 - val_accuracy: 0.8568\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3327 - accuracy: 0.8562 - val_loss: 0.3545 - val_accuracy: 0.8568\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3324 - accuracy: 0.8555 - val_loss: 0.3521 - val_accuracy: 0.8618\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3300 - accuracy: 0.8568 - val_loss: 0.3625 - val_accuracy: 0.8618\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.3327 - accuracy: 0.8562 - val_loss: 0.3553 - val_accuracy: 0.8492\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3364 - accuracy: 0.8536 - val_loss: 0.3529 - val_accuracy: 0.8568\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3326 - accuracy: 0.8574 - val_loss: 0.3470 - val_accuracy: 0.8593\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3301 - accuracy: 0.8593 - val_loss: 0.3511 - val_accuracy: 0.8593\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3310 - accuracy: 0.8562 - val_loss: 0.3548 - val_accuracy: 0.8593\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3288 - accuracy: 0.8555 - val_loss: 0.3503 - val_accuracy: 0.8568\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3273 - accuracy: 0.8606 - val_loss: 0.3492 - val_accuracy: 0.8568\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3309 - accuracy: 0.8606 - val_loss: 0.3504 - val_accuracy: 0.8568\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3309 - accuracy: 0.8555 - val_loss: 0.3474 - val_accuracy: 0.8618\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3278 - accuracy: 0.8568 - val_loss: 0.3476 - val_accuracy: 0.8593\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3286 - accuracy: 0.8524 - val_loss: 0.3462 - val_accuracy: 0.8593\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3273 - accuracy: 0.8606 - val_loss: 0.3545 - val_accuracy: 0.8593\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3308 - accuracy: 0.8568 - val_loss: 0.3608 - val_accuracy: 0.8618\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3265 - accuracy: 0.8643 - val_loss: 0.3476 - val_accuracy: 0.8593\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.3270 - accuracy: 0.8593 - val_loss: 0.3427 - val_accuracy: 0.8618\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3345 - accuracy: 0.85 - 0s 4ms/step - loss: 0.3292 - accuracy: 0.8536 - val_loss: 0.3530 - val_accuracy: 0.8618\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3255 - accuracy: 0.8637 - val_loss: 0.3438 - val_accuracy: 0.8593\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3261 - accuracy: 0.8587 - val_loss: 0.3464 - val_accuracy: 0.8593\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3332 - accuracy: 0.8555 - val_loss: 0.3503 - val_accuracy: 0.8518\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3294 - accuracy: 0.8599 - val_loss: 0.3472 - val_accuracy: 0.8618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1caabbf5550>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_deaths.fit(x_dtrain,y_dtrain,epochs = 100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3365 - accuracy: 0.8614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33653268218040466, 0.8614457845687866]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_deaths.evaluate(x_dtest,y_dtests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mlp_deaths.predict(x_test) > 0.5).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label: Confirmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_confirmed = pd.read_csv('cleaned_confirmed_coviddata.csv')\n",
    "x_ctrain,x_ctest,y_ctrain,y_ctest = train_test_split(pd_confirmed.iloc[:,:-1],pd_confirmed.iloc[:,-1],test_size = 0.2,random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                240       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 681\n",
      "Trainable params: 681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "mlp_confirmed = tf.keras.Sequential([     tf.keras.Input(shape=(11,)),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(1,activation = 'sigmoid')])\n",
    "mlp_confirmed.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_confirmed.compile(optimizer='adam',\n",
    "              loss='BinaryCrossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 1s 12ms/step - loss: 0.7067 - accuracy: 0.4561 - val_loss: 0.6806 - val_accuracy: 0.4838\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.6499 - accuracy: 0.5557 - val_loss: 0.6356 - val_accuracy: 0.6534\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.6105 - accuracy: 0.7059 - val_loss: 0.5976 - val_accuracy: 0.7401\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.5737 - accuracy: 0.7629 - val_loss: 0.5628 - val_accuracy: 0.7834\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.7873 - val_loss: 0.5249 - val_accuracy: 0.7870\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.8063 - val_loss: 0.4902 - val_accuracy: 0.7978\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.8154 - val_loss: 0.4587 - val_accuracy: 0.8195\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.8163 - val_loss: 0.4284 - val_accuracy: 0.8231\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8344 - val_loss: 0.4062 - val_accuracy: 0.8339\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3874 - accuracy: 0.8380 - val_loss: 0.3880 - val_accuracy: 0.8339\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3696 - accuracy: 0.8407 - val_loss: 0.3719 - val_accuracy: 0.8123\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3536 - accuracy: 0.8389 - val_loss: 0.3560 - val_accuracy: 0.8484\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3400 - accuracy: 0.8552 - val_loss: 0.3486 - val_accuracy: 0.8339\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3280 - accuracy: 0.8606 - val_loss: 0.3320 - val_accuracy: 0.8664\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3168 - accuracy: 0.8796 - val_loss: 0.3201 - val_accuracy: 0.8917\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3081 - accuracy: 0.8914 - val_loss: 0.3106 - val_accuracy: 0.8953\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3004 - accuracy: 0.8905 - val_loss: 0.3009 - val_accuracy: 0.9025\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2900 - accuracy: 0.8950 - val_loss: 0.2911 - val_accuracy: 0.8989\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2821 - accuracy: 0.9014 - val_loss: 0.2803 - val_accuracy: 0.8989\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2753 - accuracy: 0.9059 - val_loss: 0.2724 - val_accuracy: 0.9025\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2700 - accuracy: 0.9032 - val_loss: 0.2714 - val_accuracy: 0.9206\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2636 - accuracy: 0.9113 - val_loss: 0.2572 - val_accuracy: 0.9025\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2542 - accuracy: 0.9222 - val_loss: 0.2521 - val_accuracy: 0.9170\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2488 - accuracy: 0.9213 - val_loss: 0.2427 - val_accuracy: 0.9134\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2428 - accuracy: 0.9231 - val_loss: 0.2356 - val_accuracy: 0.9206\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2403 - accuracy: 0.9258 - val_loss: 0.2317 - val_accuracy: 0.9206\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2321 - accuracy: 0.9258 - val_loss: 0.2249 - val_accuracy: 0.9242\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2292 - accuracy: 0.9258 - val_loss: 0.2193 - val_accuracy: 0.9242\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2249 - accuracy: 0.9258 - val_loss: 0.2157 - val_accuracy: 0.9242\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2195 - accuracy: 0.9267 - val_loss: 0.2117 - val_accuracy: 0.9206\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2173 - accuracy: 0.9240 - val_loss: 0.2067 - val_accuracy: 0.9278\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2126 - accuracy: 0.9285 - val_loss: 0.2054 - val_accuracy: 0.9242\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2108 - accuracy: 0.9258 - val_loss: 0.1984 - val_accuracy: 0.9242\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2066 - accuracy: 0.9267 - val_loss: 0.1987 - val_accuracy: 0.9206\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2062 - accuracy: 0.9285 - val_loss: 0.1973 - val_accuracy: 0.9278\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2036 - accuracy: 0.9285 - val_loss: 0.1931 - val_accuracy: 0.9350\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2036 - accuracy: 0.9267 - val_loss: 0.1929 - val_accuracy: 0.9206\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1991 - accuracy: 0.9321 - val_loss: 0.1885 - val_accuracy: 0.9314\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2007 - accuracy: 0.9267 - val_loss: 0.1866 - val_accuracy: 0.9386\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1952 - accuracy: 0.9339 - val_loss: 0.1878 - val_accuracy: 0.9350\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1951 - accuracy: 0.9312 - val_loss: 0.1835 - val_accuracy: 0.9350\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1961 - accuracy: 0.9330 - val_loss: 0.1837 - val_accuracy: 0.9350\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1917 - accuracy: 0.9348 - val_loss: 0.1813 - val_accuracy: 0.9386\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1903 - accuracy: 0.9339 - val_loss: 0.1822 - val_accuracy: 0.9386\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1894 - accuracy: 0.9348 - val_loss: 0.1827 - val_accuracy: 0.9350\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1897 - accuracy: 0.9294 - val_loss: 0.1780 - val_accuracy: 0.9458\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1879 - accuracy: 0.9357 - val_loss: 0.1798 - val_accuracy: 0.9422\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1870 - accuracy: 0.9357 - val_loss: 0.1785 - val_accuracy: 0.9458\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1854 - accuracy: 0.9357 - val_loss: 0.1772 - val_accuracy: 0.9458\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1861 - accuracy: 0.9357 - val_loss: 0.1761 - val_accuracy: 0.9495\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1851 - accuracy: 0.9367 - val_loss: 0.1763 - val_accuracy: 0.9495\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1842 - accuracy: 0.9339 - val_loss: 0.1766 - val_accuracy: 0.9495\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1854 - accuracy: 0.9321 - val_loss: 0.1745 - val_accuracy: 0.9495\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1827 - accuracy: 0.9367 - val_loss: 0.1765 - val_accuracy: 0.9495\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1805 - accuracy: 0.9367 - val_loss: 0.1735 - val_accuracy: 0.9495\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1804 - accuracy: 0.9367 - val_loss: 0.1756 - val_accuracy: 0.9458\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1803 - accuracy: 0.9367 - val_loss: 0.1713 - val_accuracy: 0.9495\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1839 - accuracy: 0.9330 - val_loss: 0.1732 - val_accuracy: 0.9495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1812 - accuracy: 0.9339 - val_loss: 0.1736 - val_accuracy: 0.9495\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1787 - accuracy: 0.9385 - val_loss: 0.1708 - val_accuracy: 0.9495\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1800 - accuracy: 0.9339 - val_loss: 0.1718 - val_accuracy: 0.9458\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1781 - accuracy: 0.9357 - val_loss: 0.1701 - val_accuracy: 0.9495\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1773 - accuracy: 0.9357 - val_loss: 0.1693 - val_accuracy: 0.9495\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1771 - accuracy: 0.9357 - val_loss: 0.1703 - val_accuracy: 0.9495\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1788 - accuracy: 0.9376 - val_loss: 0.1712 - val_accuracy: 0.9458\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1773 - accuracy: 0.9357 - val_loss: 0.1691 - val_accuracy: 0.9603\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1780 - accuracy: 0.9348 - val_loss: 0.1696 - val_accuracy: 0.9458\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1757 - accuracy: 0.9376 - val_loss: 0.1676 - val_accuracy: 0.9495\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1766 - accuracy: 0.9376 - val_loss: 0.1691 - val_accuracy: 0.9458\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1758 - accuracy: 0.9357 - val_loss: 0.1705 - val_accuracy: 0.9495\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1782 - accuracy: 0.9321 - val_loss: 0.1712 - val_accuracy: 0.9458\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1761 - accuracy: 0.9348 - val_loss: 0.1667 - val_accuracy: 0.9458\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1752 - accuracy: 0.9357 - val_loss: 0.1676 - val_accuracy: 0.9495\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1743 - accuracy: 0.9376 - val_loss: 0.1667 - val_accuracy: 0.9495\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1736 - accuracy: 0.9367 - val_loss: 0.1695 - val_accuracy: 0.9458\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1758 - accuracy: 0.9330 - val_loss: 0.1704 - val_accuracy: 0.9495\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1742 - accuracy: 0.9367 - val_loss: 0.1657 - val_accuracy: 0.9495\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1762 - accuracy: 0.9357 - val_loss: 0.1694 - val_accuracy: 0.9603\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1750 - accuracy: 0.9294 - val_loss: 0.1659 - val_accuracy: 0.9495\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1726 - accuracy: 0.9385 - val_loss: 0.1647 - val_accuracy: 0.9458\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1725 - accuracy: 0.9348 - val_loss: 0.1669 - val_accuracy: 0.9603\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1736 - accuracy: 0.9348 - val_loss: 0.1667 - val_accuracy: 0.9495\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1717 - accuracy: 0.9357 - val_loss: 0.1678 - val_accuracy: 0.9458\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1715 - accuracy: 0.9385 - val_loss: 0.1640 - val_accuracy: 0.9603\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1717 - accuracy: 0.9376 - val_loss: 0.1672 - val_accuracy: 0.9458\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1707 - accuracy: 0.9357 - val_loss: 0.1673 - val_accuracy: 0.9495\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1734 - accuracy: 0.9376 - val_loss: 0.1641 - val_accuracy: 0.9603\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1722 - accuracy: 0.9357 - val_loss: 0.1645 - val_accuracy: 0.9495\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1721 - accuracy: 0.9376 - val_loss: 0.1645 - val_accuracy: 0.9495\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1705 - accuracy: 0.9376 - val_loss: 0.1698 - val_accuracy: 0.9495\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1735 - accuracy: 0.9376 - val_loss: 0.1668 - val_accuracy: 0.9495\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1707 - accuracy: 0.9367 - val_loss: 0.1640 - val_accuracy: 0.9458\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1694 - accuracy: 0.9357 - val_loss: 0.1686 - val_accuracy: 0.9495\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1696 - accuracy: 0.9376 - val_loss: 0.1647 - val_accuracy: 0.9567\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1690 - accuracy: 0.9376 - val_loss: 0.1646 - val_accuracy: 0.9495\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1699 - accuracy: 0.9367 - val_loss: 0.1658 - val_accuracy: 0.9495\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1690 - accuracy: 0.9367 - val_loss: 0.1664 - val_accuracy: 0.9495\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1693 - accuracy: 0.9348 - val_loss: 0.1630 - val_accuracy: 0.9531\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1707 - accuracy: 0.9367 - val_loss: 0.1678 - val_accuracy: 0.9458\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1683 - accuracy: 0.9330 - val_loss: 0.1670 - val_accuracy: 0.9458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1caa76686a0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_confirmed.fit(x_ctrain,y_ctrain,epochs = 100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1654 - accuracy: 0.9480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16544917225837708, 0.9479768872261047]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_confirmed.evaluate(x_ctest,y_ctest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mlp_confirmed.predict(x_test) > 0.5).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP on PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r pca_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ptrain,x_ptest,y_ptrain,y_ptest=train_test_split(pca_features[:,0:4],y,test_size = 0.2,random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                100       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 63        \n",
      "=================================================================\n",
      "Total params: 583\n",
      "Trainable params: 583\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "mlp_pca = tf.keras.Sequential([ tf.keras.Input(shape=(4,)),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(3,activation = 'softmax')])\n",
    "mlp_pca.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_pca.compile(optimizer='adam',\n",
    "              loss='BinaryCrossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.7081 - accuracy: 0.7350 - val_loss: 0.6439 - val_accuracy: 0.7376\n",
      "Epoch 2/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.6036 - accuracy: 0.6569 - val_loss: 0.5460 - val_accuracy: 0.6290\n",
      "Epoch 3/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.5798 - val_loss: 0.4620 - val_accuracy: 0.5882\n",
      "Epoch 4/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4389 - accuracy: 0.6353 - val_loss: 0.4008 - val_accuracy: 0.6244\n",
      "Epoch 5/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.6693 - val_loss: 0.3617 - val_accuracy: 0.6742\n",
      "Epoch 6/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.7123 - val_loss: 0.3387 - val_accuracy: 0.6923\n",
      "Epoch 7/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3490 - accuracy: 0.7293 - val_loss: 0.3207 - val_accuracy: 0.7059\n",
      "Epoch 8/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.7384 - val_loss: 0.3102 - val_accuracy: 0.7285\n",
      "Epoch 9/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8007 - val_loss: 0.3016 - val_accuracy: 0.7602\n",
      "Epoch 10/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.7905 - val_loss: 0.2959 - val_accuracy: 0.7602\n",
      "Epoch 11/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3196 - accuracy: 0.7780 - val_loss: 0.2926 - val_accuracy: 0.7466\n",
      "Epoch 12/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.7475 - val_loss: 0.2882 - val_accuracy: 0.6878\n",
      "Epoch 13/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.7418 - val_loss: 0.2841 - val_accuracy: 0.7149\n",
      "Epoch 14/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.7089 - val_loss: 0.2818 - val_accuracy: 0.6878\n",
      "Epoch 15/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3039 - accuracy: 0.6908 - val_loss: 0.2785 - val_accuracy: 0.6742\n",
      "Epoch 16/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3008 - accuracy: 0.6874 - val_loss: 0.2751 - val_accuracy: 0.6380\n",
      "Epoch 17/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2977 - accuracy: 0.6784 - val_loss: 0.2726 - val_accuracy: 0.6335\n",
      "Epoch 18/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2951 - accuracy: 0.6614 - val_loss: 0.2705 - val_accuracy: 0.6335\n",
      "Epoch 19/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2931 - accuracy: 0.6602 - val_loss: 0.2694 - val_accuracy: 0.6154\n",
      "Epoch 20/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2897 - accuracy: 0.6591 - val_loss: 0.2647 - val_accuracy: 0.6380\n",
      "Epoch 21/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2879 - accuracy: 0.6591 - val_loss: 0.2637 - val_accuracy: 0.6290\n",
      "Epoch 22/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2851 - accuracy: 0.6931 - val_loss: 0.2604 - val_accuracy: 0.6742\n",
      "Epoch 23/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2830 - accuracy: 0.6761 - val_loss: 0.2583 - val_accuracy: 0.6606\n",
      "Epoch 24/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2815 - accuracy: 0.7089 - val_loss: 0.2563 - val_accuracy: 0.6561\n",
      "Epoch 25/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2793 - accuracy: 0.6965 - val_loss: 0.2553 - val_accuracy: 0.6652\n",
      "Epoch 26/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2767 - accuracy: 0.6897 - val_loss: 0.2526 - val_accuracy: 0.6697\n",
      "Epoch 27/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2750 - accuracy: 0.7078 - val_loss: 0.2500 - val_accuracy: 0.6742\n",
      "Epoch 28/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2729 - accuracy: 0.6988 - val_loss: 0.2486 - val_accuracy: 0.6561\n",
      "Epoch 29/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2712 - accuracy: 0.7055 - val_loss: 0.2467 - val_accuracy: 0.6697\n",
      "Epoch 30/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2695 - accuracy: 0.6920 - val_loss: 0.2446 - val_accuracy: 0.6606\n",
      "Epoch 31/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.6874 - val_loss: 0.2431 - val_accuracy: 0.6697\n",
      "Epoch 32/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2664 - accuracy: 0.6954 - val_loss: 0.2419 - val_accuracy: 0.6923\n",
      "Epoch 33/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2650 - accuracy: 0.6942 - val_loss: 0.2408 - val_accuracy: 0.6742\n",
      "Epoch 34/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2642 - accuracy: 0.7044 - val_loss: 0.2403 - val_accuracy: 0.6652\n",
      "Epoch 35/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2632 - accuracy: 0.6761 - val_loss: 0.2397 - val_accuracy: 0.6697\n",
      "Epoch 36/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2617 - accuracy: 0.6795 - val_loss: 0.2367 - val_accuracy: 0.6923\n",
      "Epoch 37/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2610 - accuracy: 0.6954 - val_loss: 0.2372 - val_accuracy: 0.6878\n",
      "Epoch 38/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2598 - accuracy: 0.6874 - val_loss: 0.2357 - val_accuracy: 0.6923\n",
      "Epoch 39/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2590 - accuracy: 0.6829 - val_loss: 0.2351 - val_accuracy: 0.6697\n",
      "Epoch 40/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2571 - accuracy: 0.6750 - val_loss: 0.2328 - val_accuracy: 0.6878\n",
      "Epoch 41/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2574 - accuracy: 0.6659 - val_loss: 0.2334 - val_accuracy: 0.6516\n",
      "Epoch 42/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2560 - accuracy: 0.6580 - val_loss: 0.2340 - val_accuracy: 0.6471\n",
      "Epoch 43/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2554 - accuracy: 0.6602 - val_loss: 0.2335 - val_accuracy: 0.6516\n",
      "Epoch 44/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2548 - accuracy: 0.6625 - val_loss: 0.2306 - val_accuracy: 0.6471\n",
      "Epoch 45/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2539 - accuracy: 0.6535 - val_loss: 0.2326 - val_accuracy: 0.6425\n",
      "Epoch 46/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2525 - accuracy: 0.6591 - val_loss: 0.2295 - val_accuracy: 0.6425\n",
      "Epoch 47/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2523 - accuracy: 0.6580 - val_loss: 0.2293 - val_accuracy: 0.6380\n",
      "Epoch 48/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.6501 - val_loss: 0.2280 - val_accuracy: 0.6471\n",
      "Epoch 49/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.6512 - val_loss: 0.2284 - val_accuracy: 0.6380\n",
      "Epoch 50/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.6489 - val_loss: 0.2277 - val_accuracy: 0.6380\n",
      "Epoch 51/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.6478 - val_loss: 0.2263 - val_accuracy: 0.6425\n",
      "Epoch 52/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.6512 - val_loss: 0.2273 - val_accuracy: 0.6380\n",
      "Epoch 53/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2480 - accuracy: 0.6467 - val_loss: 0.2259 - val_accuracy: 0.6425\n",
      "Epoch 54/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.6467 - val_loss: 0.2262 - val_accuracy: 0.6380\n",
      "Epoch 55/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.6433 - val_loss: 0.2247 - val_accuracy: 0.6380\n",
      "Epoch 56/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.6444 - val_loss: 0.2259 - val_accuracy: 0.6380\n",
      "Epoch 57/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.6410 - val_loss: 0.2245 - val_accuracy: 0.6380\n",
      "Epoch 58/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.6353 - val_loss: 0.2232 - val_accuracy: 0.6380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.6399 - val_loss: 0.2231 - val_accuracy: 0.6290\n",
      "Epoch 60/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.6376 - val_loss: 0.2229 - val_accuracy: 0.6290\n",
      "Epoch 61/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2434 - accuracy: 0.6421 - val_loss: 0.2226 - val_accuracy: 0.6290\n",
      "Epoch 62/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2423 - accuracy: 0.6399 - val_loss: 0.2216 - val_accuracy: 0.6380\n",
      "Epoch 63/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2423 - accuracy: 0.6376 - val_loss: 0.2212 - val_accuracy: 0.6290\n",
      "Epoch 64/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2422 - accuracy: 0.6319 - val_loss: 0.2216 - val_accuracy: 0.6335\n",
      "Epoch 65/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2414 - accuracy: 0.6376 - val_loss: 0.2225 - val_accuracy: 0.6244\n",
      "Epoch 66/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2409 - accuracy: 0.6376 - val_loss: 0.2208 - val_accuracy: 0.6290\n",
      "Epoch 67/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2398 - accuracy: 0.6478 - val_loss: 0.2196 - val_accuracy: 0.6425\n",
      "Epoch 68/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2395 - accuracy: 0.6433 - val_loss: 0.2209 - val_accuracy: 0.6335\n",
      "Epoch 69/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2390 - accuracy: 0.6455 - val_loss: 0.2193 - val_accuracy: 0.6471\n",
      "Epoch 70/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2381 - accuracy: 0.6455 - val_loss: 0.2188 - val_accuracy: 0.6561\n",
      "Epoch 71/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2379 - accuracy: 0.6501 - val_loss: 0.2188 - val_accuracy: 0.6516\n",
      "Epoch 72/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2376 - accuracy: 0.6410 - val_loss: 0.2178 - val_accuracy: 0.6290\n",
      "Epoch 73/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2368 - accuracy: 0.6455 - val_loss: 0.2173 - val_accuracy: 0.6516\n",
      "Epoch 74/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2365 - accuracy: 0.6546 - val_loss: 0.2164 - val_accuracy: 0.6606\n",
      "Epoch 75/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2362 - accuracy: 0.6523 - val_loss: 0.2182 - val_accuracy: 0.6561\n",
      "Epoch 76/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2358 - accuracy: 0.6478 - val_loss: 0.2149 - val_accuracy: 0.6471\n",
      "Epoch 77/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2353 - accuracy: 0.6467 - val_loss: 0.2180 - val_accuracy: 0.6516\n",
      "Epoch 78/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2351 - accuracy: 0.6387 - val_loss: 0.2149 - val_accuracy: 0.6471\n",
      "Epoch 79/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2344 - accuracy: 0.6523 - val_loss: 0.2150 - val_accuracy: 0.6471\n",
      "Epoch 80/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2335 - accuracy: 0.6501 - val_loss: 0.2159 - val_accuracy: 0.6335\n",
      "Epoch 81/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2330 - accuracy: 0.6489 - val_loss: 0.2145 - val_accuracy: 0.6335\n",
      "Epoch 82/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2328 - accuracy: 0.6489 - val_loss: 0.2147 - val_accuracy: 0.6425\n",
      "Epoch 83/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2321 - accuracy: 0.6535 - val_loss: 0.2139 - val_accuracy: 0.6425\n",
      "Epoch 84/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2316 - accuracy: 0.6410 - val_loss: 0.2123 - val_accuracy: 0.6425\n",
      "Epoch 85/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2314 - accuracy: 0.6535 - val_loss: 0.2130 - val_accuracy: 0.6652\n",
      "Epoch 86/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2309 - accuracy: 0.6433 - val_loss: 0.2122 - val_accuracy: 0.6335\n",
      "Epoch 87/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2308 - accuracy: 0.6331 - val_loss: 0.2128 - val_accuracy: 0.6380\n",
      "Epoch 88/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2303 - accuracy: 0.6444 - val_loss: 0.2123 - val_accuracy: 0.6335\n",
      "Epoch 89/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2295 - accuracy: 0.6489 - val_loss: 0.2119 - val_accuracy: 0.6335\n",
      "Epoch 90/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2291 - accuracy: 0.6591 - val_loss: 0.2115 - val_accuracy: 0.6697\n",
      "Epoch 91/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2288 - accuracy: 0.6501 - val_loss: 0.2106 - val_accuracy: 0.6425\n",
      "Epoch 92/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2283 - accuracy: 0.6535 - val_loss: 0.2105 - val_accuracy: 0.6516\n",
      "Epoch 93/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2279 - accuracy: 0.6636 - val_loss: 0.2107 - val_accuracy: 0.6652\n",
      "Epoch 94/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2280 - accuracy: 0.6625 - val_loss: 0.2116 - val_accuracy: 0.6380\n",
      "Epoch 95/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2280 - accuracy: 0.6512 - val_loss: 0.2105 - val_accuracy: 0.6697\n",
      "Epoch 96/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2267 - accuracy: 0.6557 - val_loss: 0.2076 - val_accuracy: 0.6742\n",
      "Epoch 97/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2262 - accuracy: 0.6501 - val_loss: 0.2101 - val_accuracy: 0.6697\n",
      "Epoch 98/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2261 - accuracy: 0.6512 - val_loss: 0.2094 - val_accuracy: 0.6652\n",
      "Epoch 99/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 0.6557 - val_loss: 0.2085 - val_accuracy: 0.6606\n",
      "Epoch 100/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2259 - accuracy: 0.6614 - val_loss: 0.2092 - val_accuracy: 0.6787\n",
      "Epoch 101/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2248 - accuracy: 0.6659 - val_loss: 0.2082 - val_accuracy: 0.6742\n",
      "Epoch 102/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2240 - accuracy: 0.6580 - val_loss: 0.2084 - val_accuracy: 0.6697\n",
      "Epoch 103/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2242 - accuracy: 0.6580 - val_loss: 0.2081 - val_accuracy: 0.6787\n",
      "Epoch 104/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2240 - accuracy: 0.6602 - val_loss: 0.2079 - val_accuracy: 0.6742\n",
      "Epoch 105/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2238 - accuracy: 0.6727 - val_loss: 0.2060 - val_accuracy: 0.6697\n",
      "Epoch 106/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2229 - accuracy: 0.6602 - val_loss: 0.2070 - val_accuracy: 0.6742\n",
      "Epoch 107/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2229 - accuracy: 0.6648 - val_loss: 0.2067 - val_accuracy: 0.6742\n",
      "Epoch 108/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2217 - accuracy: 0.6591 - val_loss: 0.2065 - val_accuracy: 0.6697\n",
      "Epoch 109/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2214 - accuracy: 0.6716 - val_loss: 0.2045 - val_accuracy: 0.6833\n",
      "Epoch 110/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2211 - accuracy: 0.6625 - val_loss: 0.2056 - val_accuracy: 0.6833\n",
      "Epoch 111/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.6682 - val_loss: 0.2058 - val_accuracy: 0.6833\n",
      "Epoch 112/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.6625 - val_loss: 0.2049 - val_accuracy: 0.6787\n",
      "Epoch 113/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2200 - accuracy: 0.6591 - val_loss: 0.2057 - val_accuracy: 0.6652\n",
      "Epoch 114/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2200 - accuracy: 0.6591 - val_loss: 0.2045 - val_accuracy: 0.6742\n",
      "Epoch 115/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2203 - accuracy: 0.6569 - val_loss: 0.2041 - val_accuracy: 0.6697\n",
      "Epoch 116/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2194 - accuracy: 0.6591 - val_loss: 0.2028 - val_accuracy: 0.6561\n",
      "Epoch 117/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2185 - accuracy: 0.6614 - val_loss: 0.2035 - val_accuracy: 0.6742\n",
      "Epoch 118/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2186 - accuracy: 0.6670 - val_loss: 0.2024 - val_accuracy: 0.6742\n",
      "Epoch 119/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2181 - accuracy: 0.6512 - val_loss: 0.2036 - val_accuracy: 0.6787\n",
      "Epoch 120/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2180 - accuracy: 0.6648 - val_loss: 0.2023 - val_accuracy: 0.6787\n",
      "Epoch 121/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2169 - accuracy: 0.6602 - val_loss: 0.2022 - val_accuracy: 0.6697\n",
      "Epoch 122/150\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.2311 - accuracy: 0.46 - 0s 1ms/step - loss: 0.2169 - accuracy: 0.6682 - val_loss: 0.2010 - val_accuracy: 0.6833\n",
      "Epoch 123/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.6580 - val_loss: 0.2012 - val_accuracy: 0.6787\n",
      "Epoch 124/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2164 - accuracy: 0.6569 - val_loss: 0.2014 - val_accuracy: 0.6154\n",
      "Epoch 125/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2163 - accuracy: 0.6331 - val_loss: 0.2026 - val_accuracy: 0.6606\n",
      "Epoch 126/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2155 - accuracy: 0.6478 - val_loss: 0.2009 - val_accuracy: 0.6290\n",
      "Epoch 127/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2156 - accuracy: 0.6535 - val_loss: 0.2014 - val_accuracy: 0.6425\n",
      "Epoch 128/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2158 - accuracy: 0.6467 - val_loss: 0.2006 - val_accuracy: 0.6652\n",
      "Epoch 129/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2146 - accuracy: 0.6557 - val_loss: 0.2022 - val_accuracy: 0.6652\n",
      "Epoch 130/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2153 - accuracy: 0.6319 - val_loss: 0.1995 - val_accuracy: 0.6244\n",
      "Epoch 131/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2143 - accuracy: 0.6240 - val_loss: 0.2006 - val_accuracy: 0.6697\n",
      "Epoch 132/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2146 - accuracy: 0.6297 - val_loss: 0.2007 - val_accuracy: 0.6290\n",
      "Epoch 133/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2145 - accuracy: 0.6149 - val_loss: 0.1994 - val_accuracy: 0.6697\n",
      "Epoch 134/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2142 - accuracy: 0.6625 - val_loss: 0.1998 - val_accuracy: 0.6154\n",
      "Epoch 135/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2131 - accuracy: 0.6229 - val_loss: 0.1997 - val_accuracy: 0.6471\n",
      "Epoch 136/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2135 - accuracy: 0.6229 - val_loss: 0.1993 - val_accuracy: 0.6335\n",
      "Epoch 137/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2133 - accuracy: 0.6206 - val_loss: 0.1977 - val_accuracy: 0.6109\n",
      "Epoch 138/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2130 - accuracy: 0.6082 - val_loss: 0.1998 - val_accuracy: 0.6471\n",
      "Epoch 139/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2125 - accuracy: 0.6048 - val_loss: 0.1987 - val_accuracy: 0.6154\n",
      "Epoch 140/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2121 - accuracy: 0.6070 - val_loss: 0.1995 - val_accuracy: 0.6199\n",
      "Epoch 141/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2123 - accuracy: 0.6274 - val_loss: 0.1960 - val_accuracy: 0.6199\n",
      "Epoch 142/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2122 - accuracy: 0.6217 - val_loss: 0.1978 - val_accuracy: 0.6109\n",
      "Epoch 143/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2112 - accuracy: 0.6127 - val_loss: 0.1970 - val_accuracy: 0.6154\n",
      "Epoch 144/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2102 - accuracy: 0.6059 - val_loss: 0.1988 - val_accuracy: 0.6290\n",
      "Epoch 145/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2102 - accuracy: 0.6206 - val_loss: 0.1963 - val_accuracy: 0.6199\n",
      "Epoch 146/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2095 - accuracy: 0.6070 - val_loss: 0.1964 - val_accuracy: 0.6199\n",
      "Epoch 147/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2104 - accuracy: 0.6161 - val_loss: 0.1970 - val_accuracy: 0.6290\n",
      "Epoch 148/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.6365 - val_loss: 0.1976 - val_accuracy: 0.6335\n",
      "Epoch 149/150\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2088 - accuracy: 0.6070 - val_loss: 0.1978 - val_accuracy: 0.6244\n",
      "Epoch 150/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2099 - accuracy: 0.6036 - val_loss: 0.1969 - val_accuracy: 0.6063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22f1974a400>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_pca.fit(x_ptrain,y_ptrain,epochs = 150,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label: Recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                100       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 541\n",
      "Trainable params: 541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "mlp_pca_recovered = tf.keras.Sequential([    tf.keras.Input(shape=(4,)),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(1,activation = 'softmax')])\n",
    "mlp_pca_recovered.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_pca_recovered.compile(optimizer='adam',\n",
    "              loss='BinaryCrossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.7099 - accuracy: 0.6195 - val_loss: 0.6771 - val_accuracy: 0.6516\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.6541 - accuracy: 0.6195 - val_loss: 0.6389 - val_accuracy: 0.6516\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.6154 - accuracy: 0.6195 - val_loss: 0.6101 - val_accuracy: 0.6516\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5832 - accuracy: 0.6195 - val_loss: 0.5830 - val_accuracy: 0.6516\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.6195 - val_loss: 0.5614 - val_accuracy: 0.6516\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5267 - accuracy: 0.6195 - val_loss: 0.5425 - val_accuracy: 0.6516\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4999 - accuracy: 0.6195 - val_loss: 0.5180 - val_accuracy: 0.6516\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.6195 - val_loss: 0.4962 - val_accuracy: 0.6516\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.6195 - val_loss: 0.4795 - val_accuracy: 0.6516\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.6195 - val_loss: 0.4649 - val_accuracy: 0.6516\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4209 - accuracy: 0.6195 - val_loss: 0.4508 - val_accuracy: 0.6516\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4097 - accuracy: 0.6195 - val_loss: 0.4411 - val_accuracy: 0.6516\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3990 - accuracy: 0.6195 - val_loss: 0.4292 - val_accuracy: 0.6516\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.6195 - val_loss: 0.4187 - val_accuracy: 0.6516\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3821 - accuracy: 0.6195 - val_loss: 0.4122 - val_accuracy: 0.6516\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3733 - accuracy: 0.6195 - val_loss: 0.4019 - val_accuracy: 0.6516\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3660 - accuracy: 0.6195 - val_loss: 0.3948 - val_accuracy: 0.6516\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3598 - accuracy: 0.6195 - val_loss: 0.3864 - val_accuracy: 0.6516\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.6195 - val_loss: 0.3801 - val_accuracy: 0.6516\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3484 - accuracy: 0.6195 - val_loss: 0.3750 - val_accuracy: 0.6516\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3438 - accuracy: 0.6195 - val_loss: 0.3688 - val_accuracy: 0.6516\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3401 - accuracy: 0.6195 - val_loss: 0.3659 - val_accuracy: 0.6516\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3356 - accuracy: 0.6195 - val_loss: 0.3610 - val_accuracy: 0.6516\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.6195 - val_loss: 0.3547 - val_accuracy: 0.6516\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.6195 - val_loss: 0.3514 - val_accuracy: 0.6516\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3261 - accuracy: 0.6195 - val_loss: 0.3499 - val_accuracy: 0.6516\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.6195 - val_loss: 0.3429 - val_accuracy: 0.6516\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.6195 - val_loss: 0.3434 - val_accuracy: 0.6516\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3201 - accuracy: 0.6195 - val_loss: 0.3363 - val_accuracy: 0.6516\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3161 - accuracy: 0.6195 - val_loss: 0.3362 - val_accuracy: 0.6516\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3132 - accuracy: 0.6195 - val_loss: 0.3317 - val_accuracy: 0.6516\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.6195 - val_loss: 0.3295 - val_accuracy: 0.6516\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.6195 - val_loss: 0.3259 - val_accuracy: 0.6516\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3073 - accuracy: 0.6195 - val_loss: 0.3291 - val_accuracy: 0.6516\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3041 - accuracy: 0.6195 - val_loss: 0.3217 - val_accuracy: 0.6516\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3020 - accuracy: 0.6195 - val_loss: 0.3170 - val_accuracy: 0.6516\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2998 - accuracy: 0.6195 - val_loss: 0.3174 - val_accuracy: 0.6516\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2980 - accuracy: 0.6195 - val_loss: 0.3152 - val_accuracy: 0.6516\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2961 - accuracy: 0.6195 - val_loss: 0.3134 - val_accuracy: 0.6516\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2948 - accuracy: 0.6195 - val_loss: 0.3111 - val_accuracy: 0.6516\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2920 - accuracy: 0.6195 - val_loss: 0.3094 - val_accuracy: 0.6516\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2916 - accuracy: 0.6195 - val_loss: 0.3084 - val_accuracy: 0.6516\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2889 - accuracy: 0.6195 - val_loss: 0.3067 - val_accuracy: 0.6516\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2877 - accuracy: 0.6195 - val_loss: 0.3019 - val_accuracy: 0.6516\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2856 - accuracy: 0.6195 - val_loss: 0.3024 - val_accuracy: 0.6516\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2829 - accuracy: 0.6195 - val_loss: 0.3002 - val_accuracy: 0.6516\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2829 - accuracy: 0.6195 - val_loss: 0.2997 - val_accuracy: 0.6516\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2808 - accuracy: 0.6195 - val_loss: 0.2955 - val_accuracy: 0.6516\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2800 - accuracy: 0.6195 - val_loss: 0.2953 - val_accuracy: 0.6516\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2783 - accuracy: 0.6195 - val_loss: 0.2936 - val_accuracy: 0.6516\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2762 - accuracy: 0.6195 - val_loss: 0.2943 - val_accuracy: 0.6516\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2763 - accuracy: 0.6195 - val_loss: 0.2916 - val_accuracy: 0.6516\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2769 - accuracy: 0.6195 - val_loss: 0.2924 - val_accuracy: 0.6516\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2719 - accuracy: 0.6195 - val_loss: 0.2900 - val_accuracy: 0.6516\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2718 - accuracy: 0.6195 - val_loss: 0.2886 - val_accuracy: 0.6516\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2705 - accuracy: 0.6195 - val_loss: 0.2869 - val_accuracy: 0.6516\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2706 - accuracy: 0.6195 - val_loss: 0.2852 - val_accuracy: 0.6516\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2676 - accuracy: 0.6195 - val_loss: 0.2886 - val_accuracy: 0.6516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2679 - accuracy: 0.6195 - val_loss: 0.2852 - val_accuracy: 0.6516\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2662 - accuracy: 0.6195 - val_loss: 0.2837 - val_accuracy: 0.6516\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2658 - accuracy: 0.6195 - val_loss: 0.2830 - val_accuracy: 0.6516\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2661 - accuracy: 0.6195 - val_loss: 0.2812 - val_accuracy: 0.6516\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2645 - accuracy: 0.6195 - val_loss: 0.2828 - val_accuracy: 0.6516\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2627 - accuracy: 0.6195 - val_loss: 0.2822 - val_accuracy: 0.6516\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2618 - accuracy: 0.6195 - val_loss: 0.2800 - val_accuracy: 0.6516\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2603 - accuracy: 0.6195 - val_loss: 0.2826 - val_accuracy: 0.6516\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2588 - accuracy: 0.6195 - val_loss: 0.2791 - val_accuracy: 0.6516\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.6195 - val_loss: 0.2794 - val_accuracy: 0.6516\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2574 - accuracy: 0.6195 - val_loss: 0.2770 - val_accuracy: 0.6516\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2556 - accuracy: 0.6195 - val_loss: 0.2761 - val_accuracy: 0.6516\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2547 - accuracy: 0.6195 - val_loss: 0.2760 - val_accuracy: 0.6516\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2581 - accuracy: 0.6195 - val_loss: 0.2801 - val_accuracy: 0.6516\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2547 - accuracy: 0.6195 - val_loss: 0.2729 - val_accuracy: 0.6516\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2536 - accuracy: 0.6195 - val_loss: 0.2730 - val_accuracy: 0.6516\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2536 - accuracy: 0.6195 - val_loss: 0.2731 - val_accuracy: 0.6516\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2510 - accuracy: 0.6195 - val_loss: 0.2714 - val_accuracy: 0.6516\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2500 - accuracy: 0.6195 - val_loss: 0.2712 - val_accuracy: 0.6516\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.6195 - val_loss: 0.2705 - val_accuracy: 0.6516\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.6195 - val_loss: 0.2711 - val_accuracy: 0.6516\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2484 - accuracy: 0.6195 - val_loss: 0.2693 - val_accuracy: 0.6516\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2477 - accuracy: 0.6195 - val_loss: 0.2674 - val_accuracy: 0.6516\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2489 - accuracy: 0.6195 - val_loss: 0.2697 - val_accuracy: 0.6516\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2474 - accuracy: 0.6195 - val_loss: 0.2689 - val_accuracy: 0.6516\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.6195 - val_loss: 0.2658 - val_accuracy: 0.6516\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2438 - accuracy: 0.6195 - val_loss: 0.2660 - val_accuracy: 0.6516\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2429 - accuracy: 0.6195 - val_loss: 0.2664 - val_accuracy: 0.6516\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2431 - accuracy: 0.6195 - val_loss: 0.2646 - val_accuracy: 0.6516\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2418 - accuracy: 0.6195 - val_loss: 0.2650 - val_accuracy: 0.6516\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2415 - accuracy: 0.6195 - val_loss: 0.2659 - val_accuracy: 0.6516\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2412 - accuracy: 0.6195 - val_loss: 0.2628 - val_accuracy: 0.6516\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2415 - accuracy: 0.6195 - val_loss: 0.2619 - val_accuracy: 0.6516\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2395 - accuracy: 0.6195 - val_loss: 0.2622 - val_accuracy: 0.6516\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2380 - accuracy: 0.6195 - val_loss: 0.2608 - val_accuracy: 0.6516\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2378 - accuracy: 0.6195 - val_loss: 0.2589 - val_accuracy: 0.6516\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2374 - accuracy: 0.6195 - val_loss: 0.2608 - val_accuracy: 0.6516\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2353 - accuracy: 0.6195 - val_loss: 0.2575 - val_accuracy: 0.6516\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2349 - accuracy: 0.6195 - val_loss: 0.2582 - val_accuracy: 0.6516\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2354 - accuracy: 0.6195 - val_loss: 0.2618 - val_accuracy: 0.6516\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 0.6195 - val_loss: 0.2577 - val_accuracy: 0.6516\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2332 - accuracy: 0.6195 - val_loss: 0.2555 - val_accuracy: 0.6516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22f1985e250>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_pca_recovered.fit(x_ptrain,y_ptrain.iloc[:,-1],epochs = 100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.6268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2453708052635193, 0.6268116235733032]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_pca_recovered.evaluate(x_ptest,y_ptest.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label: Deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                100       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 541\n",
      "Trainable params: 541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "mlp_pca_deaths = tf.keras.Sequential([     tf.keras.Input(shape=(4,)),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(1,activation = 'softmax')])\n",
    "mlp_pca_deaths.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_pca_deaths.compile(optimizer='adam',\n",
    "              loss='BinaryCrossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5367 - accuracy: 0.9094 - val_loss: 0.4971 - val_accuracy: 0.9005\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4508 - accuracy: 0.9094 - val_loss: 0.4307 - val_accuracy: 0.9005\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3920 - accuracy: 0.9094 - val_loss: 0.3725 - val_accuracy: 0.9005\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.9094 - val_loss: 0.3368 - val_accuracy: 0.9005\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 814us/step - loss: 0.3300 - accuracy: 0.9094 - val_loss: 0.3218 - val_accuracy: 0.9005\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.3190 - accuracy: 0.9094 - val_loss: 0.3091 - val_accuracy: 0.9005\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3106 - accuracy: 0.9094 - val_loss: 0.3035 - val_accuracy: 0.9005\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3055 - accuracy: 0.9094 - val_loss: 0.2975 - val_accuracy: 0.9005\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3011 - accuracy: 0.9094 - val_loss: 0.2941 - val_accuracy: 0.9005\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2963 - accuracy: 0.9094 - val_loss: 0.2886 - val_accuracy: 0.9005\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2929 - accuracy: 0.9094 - val_loss: 0.2861 - val_accuracy: 0.9005\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2900 - accuracy: 0.9094 - val_loss: 0.2824 - val_accuracy: 0.9005\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.2879 - accuracy: 0.9094 - val_loss: 0.2796 - val_accuracy: 0.9005\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2839 - accuracy: 0.9094 - val_loss: 0.2780 - val_accuracy: 0.9005\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2804 - accuracy: 0.9094 - val_loss: 0.2758 - val_accuracy: 0.9005\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2782 - accuracy: 0.9094 - val_loss: 0.2750 - val_accuracy: 0.9005\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 983us/step - loss: 0.2757 - accuracy: 0.9094 - val_loss: 0.2726 - val_accuracy: 0.9005\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2731 - accuracy: 0.9094 - val_loss: 0.2715 - val_accuracy: 0.9005\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2708 - accuracy: 0.9094 - val_loss: 0.2688 - val_accuracy: 0.9005\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2680 - accuracy: 0.9094 - val_loss: 0.2683 - val_accuracy: 0.9005\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2667 - accuracy: 0.9094 - val_loss: 0.2679 - val_accuracy: 0.9005\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.2188 - accuracy: 0.93 - 0s 1ms/step - loss: 0.2655 - accuracy: 0.9094 - val_loss: 0.2670 - val_accuracy: 0.9005\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 966us/step - loss: 0.2623 - accuracy: 0.9094 - val_loss: 0.2679 - val_accuracy: 0.9005\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.9094 - val_loss: 0.2641 - val_accuracy: 0.9005\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2575 - accuracy: 0.9094 - val_loss: 0.2636 - val_accuracy: 0.9005\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2561 - accuracy: 0.9094 - val_loss: 0.2618 - val_accuracy: 0.9005\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.2563 - accuracy: 0.9094 - val_loss: 0.2606 - val_accuracy: 0.9005\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 980us/step - loss: 0.2536 - accuracy: 0.9094 - val_loss: 0.2607 - val_accuracy: 0.9005\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 971us/step - loss: 0.2517 - accuracy: 0.9094 - val_loss: 0.2593 - val_accuracy: 0.9005\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.2502 - accuracy: 0.9094 - val_loss: 0.2612 - val_accuracy: 0.9005\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2486 - accuracy: 0.9094 - val_loss: 0.2592 - val_accuracy: 0.9005\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.9094 - val_loss: 0.2587 - val_accuracy: 0.9005\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.9094 - val_loss: 0.2575 - val_accuracy: 0.9005\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.9094 - val_loss: 0.2585 - val_accuracy: 0.9005\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2440 - accuracy: 0.9094 - val_loss: 0.2574 - val_accuracy: 0.9005\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2423 - accuracy: 0.9094 - val_loss: 0.2578 - val_accuracy: 0.9005\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2422 - accuracy: 0.9094 - val_loss: 0.2572 - val_accuracy: 0.9005\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2395 - accuracy: 0.9094 - val_loss: 0.2569 - val_accuracy: 0.9005\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2397 - accuracy: 0.9094 - val_loss: 0.2560 - val_accuracy: 0.9005\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2387 - accuracy: 0.9094 - val_loss: 0.2574 - val_accuracy: 0.9005\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2394 - accuracy: 0.9094 - val_loss: 0.2580 - val_accuracy: 0.9005\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2384 - accuracy: 0.9094 - val_loss: 0.2561 - val_accuracy: 0.9005\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2355 - accuracy: 0.9094 - val_loss: 0.2563 - val_accuracy: 0.9005\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2350 - accuracy: 0.9094 - val_loss: 0.2555 - val_accuracy: 0.9005\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 0.9094 - val_loss: 0.2565 - val_accuracy: 0.9005\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 0.9094 - val_loss: 0.2567 - val_accuracy: 0.9005\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2326 - accuracy: 0.9094 - val_loss: 0.2564 - val_accuracy: 0.9005\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2327 - accuracy: 0.9094 - val_loss: 0.2560 - val_accuracy: 0.9005\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2335 - accuracy: 0.9094 - val_loss: 0.2557 - val_accuracy: 0.9005\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2312 - accuracy: 0.9094 - val_loss: 0.2576 - val_accuracy: 0.9005\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2322 - accuracy: 0.9094 - val_loss: 0.2558 - val_accuracy: 0.9005\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2321 - accuracy: 0.9094 - val_loss: 0.2629 - val_accuracy: 0.9005\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2325 - accuracy: 0.9094 - val_loss: 0.2546 - val_accuracy: 0.9005\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2286 - accuracy: 0.9094 - val_loss: 0.2561 - val_accuracy: 0.9005\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2296 - accuracy: 0.9094 - val_loss: 0.2556 - val_accuracy: 0.9005\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2283 - accuracy: 0.9094 - val_loss: 0.2552 - val_accuracy: 0.9005\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2273 - accuracy: 0.9094 - val_loss: 0.2568 - val_accuracy: 0.9005\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2260 - accuracy: 0.9094 - val_loss: 0.2536 - val_accuracy: 0.9005\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2265 - accuracy: 0.9094 - val_loss: 0.2538 - val_accuracy: 0.9005\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2251 - accuracy: 0.9094 - val_loss: 0.2554 - val_accuracy: 0.9005\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2262 - accuracy: 0.9094 - val_loss: 0.2560 - val_accuracy: 0.9005\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2268 - accuracy: 0.9094 - val_loss: 0.2548 - val_accuracy: 0.9005\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2252 - accuracy: 0.9094 - val_loss: 0.2555 - val_accuracy: 0.9005\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2234 - accuracy: 0.9094 - val_loss: 0.2547 - val_accuracy: 0.9005\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2248 - accuracy: 0.9094 - val_loss: 0.2537 - val_accuracy: 0.9005\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2243 - accuracy: 0.9094 - val_loss: 0.2563 - val_accuracy: 0.9005\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2222 - accuracy: 0.9094 - val_loss: 0.2543 - val_accuracy: 0.9005\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2221 - accuracy: 0.9094 - val_loss: 0.2548 - val_accuracy: 0.9005\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2222 - accuracy: 0.9094 - val_loss: 0.2541 - val_accuracy: 0.9005\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2216 - accuracy: 0.9094 - val_loss: 0.2537 - val_accuracy: 0.9005\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2215 - accuracy: 0.9094 - val_loss: 0.2565 - val_accuracy: 0.9005\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2208 - accuracy: 0.9094 - val_loss: 0.2543 - val_accuracy: 0.9005\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2200 - accuracy: 0.9094 - val_loss: 0.2534 - val_accuracy: 0.9005\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2213 - accuracy: 0.9094 - val_loss: 0.2545 - val_accuracy: 0.9005\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2210 - accuracy: 0.9094 - val_loss: 0.2536 - val_accuracy: 0.9005\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2224 - accuracy: 0.9094 - val_loss: 0.2527 - val_accuracy: 0.9005\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2191 - accuracy: 0.9094 - val_loss: 0.2565 - val_accuracy: 0.9005\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2191 - accuracy: 0.9094 - val_loss: 0.2541 - val_accuracy: 0.9005\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2180 - accuracy: 0.9094 - val_loss: 0.2542 - val_accuracy: 0.9005\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2169 - accuracy: 0.9094 - val_loss: 0.2539 - val_accuracy: 0.9005\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2167 - accuracy: 0.9094 - val_loss: 0.2528 - val_accuracy: 0.9005\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2180 - accuracy: 0.9094 - val_loss: 0.2548 - val_accuracy: 0.9005\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2169 - accuracy: 0.9094 - val_loss: 0.2539 - val_accuracy: 0.9005\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.2170 - accuracy: 0.9094 - val_loss: 0.2552 - val_accuracy: 0.9005\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2168 - accuracy: 0.9094 - val_loss: 0.2537 - val_accuracy: 0.9005\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2152 - accuracy: 0.9094 - val_loss: 0.2561 - val_accuracy: 0.9005\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2165 - accuracy: 0.9094 - val_loss: 0.2561 - val_accuracy: 0.9005\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2183 - accuracy: 0.9094 - val_loss: 0.2541 - val_accuracy: 0.9005\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2144 - accuracy: 0.9094 - val_loss: 0.2535 - val_accuracy: 0.9005\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2151 - accuracy: 0.9094 - val_loss: 0.2531 - val_accuracy: 0.9005\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2140 - accuracy: 0.9094 - val_loss: 0.2539 - val_accuracy: 0.9005\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2143 - accuracy: 0.9094 - val_loss: 0.2536 - val_accuracy: 0.9005\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2161 - accuracy: 0.9094 - val_loss: 0.2535 - val_accuracy: 0.9005\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2138 - accuracy: 0.9094 - val_loss: 0.2531 - val_accuracy: 0.9005\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2130 - accuracy: 0.9094 - val_loss: 0.2547 - val_accuracy: 0.9005\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2147 - accuracy: 0.9094 - val_loss: 0.2549 - val_accuracy: 0.9005\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2132 - accuracy: 0.9094 - val_loss: 0.2544 - val_accuracy: 0.9005\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2140 - accuracy: 0.9094 - val_loss: 0.2553 - val_accuracy: 0.9005\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2124 - accuracy: 0.9094 - val_loss: 0.2561 - val_accuracy: 0.9005\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2130 - accuracy: 0.9094 - val_loss: 0.2524 - val_accuracy: 0.9005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22f1a9d9130>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_pca_deaths.fit(x_ptrain,y_ptrain.iloc[:,-2],epochs = 100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 667us/step - loss: 0.2718 - accuracy: 0.9493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.27184930443763733, 0.9492753744125366]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_pca_deaths.evaluate(x_ptest,y_ptest.iloc[:,:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label: Confirmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                100       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 541\n",
      "Trainable params: 541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "mlp_pca_confirmed = tf.keras.Sequential([     tf.keras.Input(shape=(4,)),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(1,activation = 'softmax')])\n",
    "mlp_pca_confirmed.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_pca_confirmed.compile(optimizer='adam',\n",
    "              loss='BinaryCrossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28/28 [==============================] - 1s 4ms/step - loss: 0.6044 - accuracy: 0.9604 - val_loss: 0.4472 - val_accuracy: 0.9910\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3918 - accuracy: 0.9604 - val_loss: 0.2627 - val_accuracy: 0.9910\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2622 - accuracy: 0.9604 - val_loss: 0.1543 - val_accuracy: 0.9910\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.9604 - val_loss: 0.1053 - val_accuracy: 0.9910\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1745 - accuracy: 0.9604 - val_loss: 0.0845 - val_accuracy: 0.9910\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1655 - accuracy: 0.9604 - val_loss: 0.0727 - val_accuracy: 0.9910\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1604 - accuracy: 0.9604 - val_loss: 0.0686 - val_accuracy: 0.9910\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1571 - accuracy: 0.9604 - val_loss: 0.0645 - val_accuracy: 0.9910\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1546 - accuracy: 0.9604 - val_loss: 0.0618 - val_accuracy: 0.9910\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1521 - accuracy: 0.9604 - val_loss: 0.0592 - val_accuracy: 0.9910\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1504 - accuracy: 0.9604 - val_loss: 0.0593 - val_accuracy: 0.9910\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1487 - accuracy: 0.9604 - val_loss: 0.0575 - val_accuracy: 0.9910\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1472 - accuracy: 0.9604 - val_loss: 0.0566 - val_accuracy: 0.9910\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1463 - accuracy: 0.9604 - val_loss: 0.0562 - val_accuracy: 0.9910\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1444 - accuracy: 0.9604 - val_loss: 0.0547 - val_accuracy: 0.9910\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1432 - accuracy: 0.9604 - val_loss: 0.0526 - val_accuracy: 0.9910\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1422 - accuracy: 0.9604 - val_loss: 0.0522 - val_accuracy: 0.9910\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1414 - accuracy: 0.9604 - val_loss: 0.0543 - val_accuracy: 0.9910\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1402 - accuracy: 0.9604 - val_loss: 0.0530 - val_accuracy: 0.9910\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1393 - accuracy: 0.9604 - val_loss: 0.0517 - val_accuracy: 0.9910\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1386 - accuracy: 0.9604 - val_loss: 0.0519 - val_accuracy: 0.9910\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1375 - accuracy: 0.9604 - val_loss: 0.0518 - val_accuracy: 0.9910\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1367 - accuracy: 0.9604 - val_loss: 0.0508 - val_accuracy: 0.9910\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1359 - accuracy: 0.9604 - val_loss: 0.0507 - val_accuracy: 0.9910\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1355 - accuracy: 0.9604 - val_loss: 0.0496 - val_accuracy: 0.9910\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1352 - accuracy: 0.9604 - val_loss: 0.0514 - val_accuracy: 0.9910\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1344 - accuracy: 0.9604 - val_loss: 0.0490 - val_accuracy: 0.9910\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1337 - accuracy: 0.9604 - val_loss: 0.0508 - val_accuracy: 0.9910\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1336 - accuracy: 0.9604 - val_loss: 0.0496 - val_accuracy: 0.9910\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1330 - accuracy: 0.9604 - val_loss: 0.0492 - val_accuracy: 0.9910\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1326 - accuracy: 0.9604 - val_loss: 0.0511 - val_accuracy: 0.9910\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1319 - accuracy: 0.9604 - val_loss: 0.0499 - val_accuracy: 0.9910\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1315 - accuracy: 0.9604 - val_loss: 0.0494 - val_accuracy: 0.9910\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1309 - accuracy: 0.9604 - val_loss: 0.0498 - val_accuracy: 0.9910\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1306 - accuracy: 0.9604 - val_loss: 0.0485 - val_accuracy: 0.9910\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1303 - accuracy: 0.9604 - val_loss: 0.0479 - val_accuracy: 0.9910\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1298 - accuracy: 0.9604 - val_loss: 0.0491 - val_accuracy: 0.9910\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1295 - accuracy: 0.9604 - val_loss: 0.0500 - val_accuracy: 0.9910\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1291 - accuracy: 0.9604 - val_loss: 0.0501 - val_accuracy: 0.9910\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1288 - accuracy: 0.9604 - val_loss: 0.0490 - val_accuracy: 0.9910\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1290 - accuracy: 0.9604 - val_loss: 0.0500 - val_accuracy: 0.9910\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1288 - accuracy: 0.9604 - val_loss: 0.0479 - val_accuracy: 0.9910\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1282 - accuracy: 0.9604 - val_loss: 0.0508 - val_accuracy: 0.9910\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1279 - accuracy: 0.9604 - val_loss: 0.0494 - val_accuracy: 0.9910\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1273 - accuracy: 0.9604 - val_loss: 0.0519 - val_accuracy: 0.9910\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1267 - accuracy: 0.9604 - val_loss: 0.0479 - val_accuracy: 0.9910\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1270 - accuracy: 0.9604 - val_loss: 0.0495 - val_accuracy: 0.9910\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1266 - accuracy: 0.9604 - val_loss: 0.0488 - val_accuracy: 0.9910\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1264 - accuracy: 0.9604 - val_loss: 0.0467 - val_accuracy: 0.9910\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1267 - accuracy: 0.9604 - val_loss: 0.0476 - val_accuracy: 0.9910\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1255 - accuracy: 0.9604 - val_loss: 0.0524 - val_accuracy: 0.9910\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1253 - accuracy: 0.9604 - val_loss: 0.0486 - val_accuracy: 0.9910\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1252 - accuracy: 0.9604 - val_loss: 0.0487 - val_accuracy: 0.9910\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1252 - accuracy: 0.9604 - val_loss: 0.0513 - val_accuracy: 0.9910\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1241 - accuracy: 0.9604 - val_loss: 0.0474 - val_accuracy: 0.9910\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1247 - accuracy: 0.9604 - val_loss: 0.0476 - val_accuracy: 0.9910\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1250 - accuracy: 0.9604 - val_loss: 0.0493 - val_accuracy: 0.9910\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1239 - accuracy: 0.9604 - val_loss: 0.0484 - val_accuracy: 0.9910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1233 - accuracy: 0.9604 - val_loss: 0.0500 - val_accuracy: 0.9910\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1230 - accuracy: 0.9604 - val_loss: 0.0494 - val_accuracy: 0.9910\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1229 - accuracy: 0.9604 - val_loss: 0.0501 - val_accuracy: 0.9910\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1229 - accuracy: 0.9604 - val_loss: 0.0502 - val_accuracy: 0.9910\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1229 - accuracy: 0.9604 - val_loss: 0.0482 - val_accuracy: 0.9910\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1222 - accuracy: 0.9604 - val_loss: 0.0492 - val_accuracy: 0.9910\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1221 - accuracy: 0.9604 - val_loss: 0.0501 - val_accuracy: 0.9910\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1221 - accuracy: 0.9604 - val_loss: 0.0467 - val_accuracy: 0.9910\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1221 - accuracy: 0.9604 - val_loss: 0.0499 - val_accuracy: 0.9910\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1213 - accuracy: 0.9604 - val_loss: 0.0473 - val_accuracy: 0.9910\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1225 - accuracy: 0.9604 - val_loss: 0.0478 - val_accuracy: 0.9910\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1225 - accuracy: 0.9604 - val_loss: 0.0513 - val_accuracy: 0.9910\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1210 - accuracy: 0.9604 - val_loss: 0.0473 - val_accuracy: 0.9910\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1206 - accuracy: 0.9604 - val_loss: 0.0490 - val_accuracy: 0.9910\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1211 - accuracy: 0.9604 - val_loss: 0.0460 - val_accuracy: 0.9910\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1207 - accuracy: 0.9604 - val_loss: 0.0490 - val_accuracy: 0.9910\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1201 - accuracy: 0.9604 - val_loss: 0.0498 - val_accuracy: 0.9910\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1204 - accuracy: 0.9604 - val_loss: 0.0500 - val_accuracy: 0.9910\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1204 - accuracy: 0.9604 - val_loss: 0.0489 - val_accuracy: 0.9910\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1199 - accuracy: 0.9604 - val_loss: 0.0504 - val_accuracy: 0.9910\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1200 - accuracy: 0.9604 - val_loss: 0.0491 - val_accuracy: 0.9910\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1199 - accuracy: 0.9604 - val_loss: 0.0494 - val_accuracy: 0.9910\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1200 - accuracy: 0.9604 - val_loss: 0.0480 - val_accuracy: 0.9910\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1192 - accuracy: 0.9604 - val_loss: 0.0497 - val_accuracy: 0.9910\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1189 - accuracy: 0.9604 - val_loss: 0.0478 - val_accuracy: 0.9910\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1194 - accuracy: 0.9604 - val_loss: 0.0482 - val_accuracy: 0.9910\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1190 - accuracy: 0.9604 - val_loss: 0.0520 - val_accuracy: 0.9910\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1184 - accuracy: 0.9604 - val_loss: 0.0471 - val_accuracy: 0.9910\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1188 - accuracy: 0.9604 - val_loss: 0.0490 - val_accuracy: 0.9910\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1185 - accuracy: 0.9604 - val_loss: 0.0488 - val_accuracy: 0.9910\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1185 - accuracy: 0.9604 - val_loss: 0.0495 - val_accuracy: 0.9910\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1185 - accuracy: 0.9604 - val_loss: 0.0495 - val_accuracy: 0.9910\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1178 - accuracy: 0.9604 - val_loss: 0.0499 - val_accuracy: 0.9910\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1184 - accuracy: 0.9604 - val_loss: 0.0473 - val_accuracy: 0.9910\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1177 - accuracy: 0.9604 - val_loss: 0.0501 - val_accuracy: 0.9910\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1177 - accuracy: 0.9604 - val_loss: 0.0498 - val_accuracy: 0.9910\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1180 - accuracy: 0.9604 - val_loss: 0.0492 - val_accuracy: 0.9910\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1185 - accuracy: 0.9604 - val_loss: 0.0499 - val_accuracy: 0.9910\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1176 - accuracy: 0.9604 - val_loss: 0.0478 - val_accuracy: 0.9910\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1172 - accuracy: 0.9604 - val_loss: 0.0493 - val_accuracy: 0.9910\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1168 - accuracy: 0.9604 - val_loss: 0.0490 - val_accuracy: 0.9910\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1172 - accuracy: 0.9604 - val_loss: 0.0472 - val_accuracy: 0.9910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22f1bb37e50>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_pca_confirmed.fit(x_ptrain,y_ptrain.iloc[:,-3],epochs = 100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1676 - accuracy: 0.9493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1676435023546219, 0.9492753744125366]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_pca_confirmed.evaluate(x_ptest,y_ptest.iloc[:,-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5)).suptitle(\"Default Architecture of DNN for combined labels \",fontsize=17)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history_mlp.epoch,history_mlp.history['accuracy'],'b--',label = 'Training Accuracy')\n",
    "plt.plot(history_mlp.epoch,history_mlp.history['val_accuracy'],'r',label = 'Validation Accuracy')\n",
    "plt.title(' Training and Validation Accuracy VS Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history_mlp.epoch,history_mlp.history['loss'],'b--',label = 'Training losses')\n",
    "plt.plot(history_mlp.epoch,history_mlp.history['val_loss'],'r',label = 'Validation losses')\n",
    "plt.title(' Training and Validation Losses VS Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Losses')\n",
    "plt.legend()\n",
    "plt.figure(figsize=(15,5)).suptitle(\"Default Architecture of DNN for Label: Recovered \",fontsize=17)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(his_recovered.epoch,his_recovered.history['accuracy'],'b--',label = 'Training Accuracy')\n",
    "plt.plot(his_recovered.epoch,his_recovered.history['val_accuracy'],'r',label = 'Validation Accuracy')\n",
    "plt.title(' Training and Validation Accuracy VS Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5,0.9])\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(his_recovered.epoch,his_recovered.history['loss'],'b--',label = 'Training losses')\n",
    "plt.plot(his_recovered.epoch,his_recovered.history['val_loss'],'r',label = 'Validation losses')\n",
    "plt.title(' Training and Validation Losses VS Epoch')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Losses')\n",
    "plt.figure(figsize=(15,5)).suptitle(\"Default Architecture of DNN for Label: Deaths \",fontsize=17)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(his_deaths.epoch,his_deaths.history['accuracy'],'b--',label = 'Training Accuracy')\n",
    "plt.plot(his_deaths.epoch,his_deaths.history['val_accuracy'],'r',label = 'Validation Accuracy')\n",
    "plt.title(' Training and Validation Accuracy VS Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(his_deaths.epoch,his_deaths.history['loss'],'b--',label = 'Training losses')\n",
    "plt.plot(his_deaths.epoch,his_deaths.history['val_loss'],'r',label = 'Validation losses')\n",
    "plt.title(' Training and Validation Losses VS Epoch')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Losses')\n",
    "plt.figure(figsize=(15,5)).suptitle(\"Modified Architecture of DNN for Label: Confirmed \",fontsize=17)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(his_confirmed.epoch,his_confirmed.history['accuracy'],'b--',label = 'Training Accuracy')\n",
    "plt.plot(his_confirmed.epoch,his_confirmed.history['val_accuracy'],'r',label = 'Validation Accuracy')\n",
    "plt.title(' Training and Validation Accuracy VS Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(his_confirmed.epoch,his_confirmed.history['loss'],'b--',label = 'Training losses')\n",
    "plt.plot(his_confirmed.epoch,his_confirmed.history['val_loss'],'r',label = 'Validation losses')\n",
    "plt.title(' Training and Validation Losses VS Epoch')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Losses')\n",
    "plt.figure(figsize=(15,5)).suptitle(\"Default Architecture of DNN using PCA features for combined Labels\",fontsize=17)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(his_pmlp.epoch,his_pmlp.history['accuracy'],'b--',label = 'Training Accuracy')\n",
    "plt.plot(his_pmlp.epoch,his_pmlp.history['val_accuracy'],'r',label = 'Validation Accuracy')\n",
    "plt.title(' Training and Validation Accuracy VS Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(his_pmlp.epoch,his_pmlp.history['loss'],'b--',label = 'Training losses')\n",
    "plt.plot(his_pmlp.epoch,his_pmlp.history['val_loss'],'r',label = 'Validation losses')\n",
    "plt.title(' Training and Validation Losses VS Epoch')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Losses')\n",
    "plt.figure(figsize=(15,5)).suptitle(\"Default Architecture of DNN using PCA features for Label: Recovered\",fontsize=17)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(his_precovered.epoch,his_precovered.history['accuracy'],'b--',label = 'Training Accuracy')\n",
    "plt.plot(his_precovered.epoch,his_precovered.history['val_accuracy'],'r',label = 'Validation Accuracy')\n",
    "plt.title(' Training and Validation Accuracy VS Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5,0.9])\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(his_precovered.epoch,his_precovered.history['loss'],'b--',label = 'Training losses')\n",
    "plt.plot(his_precovered.epoch,his_precovered.history['val_loss'],'r',label = 'Validation losses')\n",
    "plt.title(' Training and Validation Losses VS Epoch')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Losses')\n",
    "plt.figure(figsize=(15,5)).suptitle(\"Default Architecture of DNN using PCA features for Label: Deaths\",fontsize=17)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(his_pdeaths.epoch,his_pdeaths.history['accuracy'],'b--',label = 'Training Accuracy')\n",
    "plt.plot(his_pdeaths.epoch,his_pdeaths.history['val_accuracy'],'r',label = 'Validation Accuracy')\n",
    "plt.title(' Training and Validation Accuracy VS Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(his_pdeaths.epoch,his_pdeaths.history['loss'],'b--',label = 'Training losses')\n",
    "plt.plot(his_pdeaths.epoch,his_pdeaths.history['val_loss'],'r',label = 'Validation losses')\n",
    "plt.title(' Training and Validation Losses VS Epoch')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Losses')\n",
    "plt.figure(figsize=(15,5)).suptitle(\"Default Architecture of DNN using PCA features for Label: Confirmed\",fontsize=17)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(his_pconfirmed.epoch,his_pconfirmed.history['accuracy'],'b--',label = 'Training Accuracy')\n",
    "plt.plot(his_pconfirmed.epoch,his_pconfirmed.history['val_accuracy'],'r',label = 'Validation Accuracy')\n",
    "plt.title(' Training and Validation Accuracy VS Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(his_pconfirmed.epoch,his_pconfirmed.history['loss'],'b--',label = 'Training losses')\n",
    "plt.plot(his_pconfirmed.epoch,his_pconfirmed.history['val_loss'],'r',label = 'Validation losses')\n",
    "plt.title(' Training and Validation Losses VS Epoch')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Losses')\n",
    "plt.figure(figsize=(15,5)).suptitle(\"Modified Architecture of DNN for Label: Recovered \",fontsize=17)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(his_m_rec.epoch,his_m_rec.history['accuracy'],'b--',label = 'Training Accuracy')\n",
    "plt.plot(his_m_rec.epoch,his_m_rec.history['val_accuracy'],'r',label = 'Validation Accuracy')\n",
    "plt.title(' Training and Validation Accuracy VS Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(his_m_rec.epoch,his_m_rec.history['loss'],'b--',label = 'Training losses')\n",
    "plt.plot(his_m_rec.epoch,his_m_rec.history['val_loss'],'r',label = 'Validation losses')\n",
    "plt.title(' Training and Validation Losses VS Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Losses')\n",
    "plt.figure(figsize=(15,5)).suptitle(\"Modified Architecture of DNN for Label: Deaths \",fontsize=17)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(his_m_deaths.epoch,his_m_deaths.history['accuracy'],'b--',label = 'Training Accuracy')\n",
    "plt.plot(his_m_deaths.epoch,his_m_deaths.history['val_accuracy'],'r',label = 'Validation Accuracy')\n",
    "plt.title(' Training and Validation Accuracy VS Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(his_m_deaths.epoch,his_m_deaths.history['loss'],'b--',label = 'Training losses')\n",
    "plt.plot(his_m_deaths.epoch,his_m_deaths.history['val_loss'],'r',label = 'Validation losses')\n",
    "plt.title(' Training and Validation Losses VS Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Losses')\n",
    "plt.figure(figsize=(15,5)).suptitle(\"Modified Architecture of DNN for Label: Confirmed \",fontsize=17)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(his_m_confirmed.epoch,his_m_confirmed.history['accuracy'],'b--',label = 'Training Accuracy')\n",
    "plt.plot(his_m_confirmed.epoch,his_m_confirmed.history['val_accuracy'],'r',label = 'Validation Accuracy')\n",
    "plt.title(' Training and Validation Accuracy VS Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(his_m_confirmed.epoch,his_m_confirmed.history['loss'],'b--',label = 'Training losses')\n",
    "plt.plot(his_m_confirmed.epoch,his_m_confirmed.history['val_loss'],'r',label = 'Validation losses')\n",
    "plt.title(' Training and Validation Losses VS Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Losses')\n",
    "plt.figure(figsize=(15,5)).suptitle(\"Modified Architecture of LSTM for Label: Recovered \",fontsize=17)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(his_lstm_r.epoch,his_lstm_r.history['accuracy'],'b--',label = 'Training Accuracy')\n",
    "plt.plot(his_lstm_r.epoch,his_lstm_r.history['val_accuracy'],'r',label = 'Validation Accuracy')\n",
    "plt.title(' Training and Validation Accuracy VS Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(his_lstm_r.epoch,his_lstm_r.history['loss'],'b--',label = 'Training losses')\n",
    "plt.plot(his_lstm_r.epoch,his_lstm_r.history['val_loss'],'r',label = 'Validation losses')\n",
    "plt.title(' Training and Validation Losses VS Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Losses')\n",
    "plt.figure(figsize=(15,5)).suptitle(\"Modified Architecture of LSTM for Label: Deaths \",fontsize=17)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(his_lstm_d.epoch,his_lstm_d.history['accuracy'],'b--',label = 'Training Accuracy')\n",
    "plt.plot(his_lstm_d.epoch,his_lstm_d.history['val_accuracy'],'r',label = 'Validation Accuracy')\n",
    "plt.title(' Training and Validation Accuracy VS Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(his_lstm_d.epoch,his_lstm_d.history['loss'],'b--',label = 'Training losses')\n",
    "plt.plot(his_lstm_d.epoch,his_lstm_d.history['val_loss'],'r',label = 'Validation losses')\n",
    "plt.title(' Training and Validation Losses VS Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Losses')\n",
    "plt.figure(figsize=(15,5)).suptitle(\"Modified Architecture of LSTM for Label: Confirmed \",fontsize=17)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(his_lstm_c.epoch,his_lstm_c.history['accuracy'],'b--',label = 'Training Accuracy')\n",
    "plt.plot(his_lstm_c.epoch,his_lstm_c.history['val_accuracy'],'r',label = 'Validation Accuracy')\n",
    "plt.title(' Training and Validation Accuracy VS Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(his_lstm_c.epoch,his_lstm_c.history['loss'],'b--',label = 'Training losses')\n",
    "plt.plot(his_lstm_c.epoch,his_lstm_c.history['val_loss'],'r',label = 'Validation losses')\n",
    "plt.title(' Training and Validation Losses VS Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
