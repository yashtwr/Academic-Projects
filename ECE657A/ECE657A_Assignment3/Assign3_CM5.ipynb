{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CM[5] Kaggle Competition Group38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dkmacovid_kaggletest_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Day</th>\n",
       "      <th>State ID</th>\n",
       "      <th>State</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Active</th>\n",
       "      <th>Incident_Rate</th>\n",
       "      <th>Total_Test_Results</th>\n",
       "      <th>Case_Fatality_Ratio</th>\n",
       "      <th>Testing_Rate</th>\n",
       "      <th>Resident Population 2020 Census</th>\n",
       "      <th>Population Density 2020 Census</th>\n",
       "      <th>Density Rank 2020 Census</th>\n",
       "      <th>SexRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>40.3495</td>\n",
       "      <td>-88.9861</td>\n",
       "      <td>957138</td>\n",
       "      <td>7697.015291</td>\n",
       "      <td>13436652</td>\n",
       "      <td>1.867428</td>\n",
       "      <td>106035.6834</td>\n",
       "      <td>12,812,508</td>\n",
       "      <td>230.8</td>\n",
       "      <td>14</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>40.3495</td>\n",
       "      <td>-88.9861</td>\n",
       "      <td>961499</td>\n",
       "      <td>7732.282519</td>\n",
       "      <td>13482117</td>\n",
       "      <td>1.869933</td>\n",
       "      <td>106394.4716</td>\n",
       "      <td>12,812,508</td>\n",
       "      <td>230.8</td>\n",
       "      <td>14</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>40.3495</td>\n",
       "      <td>-88.9861</td>\n",
       "      <td>966468</td>\n",
       "      <td>7772.205747</td>\n",
       "      <td>13530371</td>\n",
       "      <td>1.869466</td>\n",
       "      <td>106775.2693</td>\n",
       "      <td>12,812,508</td>\n",
       "      <td>230.8</td>\n",
       "      <td>14</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>40.3495</td>\n",
       "      <td>-88.9861</td>\n",
       "      <td>973157</td>\n",
       "      <td>7826.175891</td>\n",
       "      <td>13617454</td>\n",
       "      <td>1.871700</td>\n",
       "      <td>107462.4870</td>\n",
       "      <td>12,812,508</td>\n",
       "      <td>230.8</td>\n",
       "      <td>14</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>40.3495</td>\n",
       "      <td>-88.9861</td>\n",
       "      <td>980553</td>\n",
       "      <td>7885.906848</td>\n",
       "      <td>13698428</td>\n",
       "      <td>1.874835</td>\n",
       "      <td>108101.4954</td>\n",
       "      <td>12,812,508</td>\n",
       "      <td>230.8</td>\n",
       "      <td>14</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Day  State ID     State      Lat    Long_  Active  Incident_Rate  \\\n",
       "0   0    2        14  Illinois  40.3495 -88.9861  957138    7697.015291   \n",
       "1   5    3        14  Illinois  40.3495 -88.9861  961499    7732.282519   \n",
       "2  10    4        14  Illinois  40.3495 -88.9861  966468    7772.205747   \n",
       "3  15    5        14  Illinois  40.3495 -88.9861  973157    7826.175891   \n",
       "4  20    6        14  Illinois  40.3495 -88.9861  980553    7885.906848   \n",
       "\n",
       "   Total_Test_Results  Case_Fatality_Ratio  Testing_Rate  \\\n",
       "0            13436652             1.867428   106035.6834   \n",
       "1            13482117             1.869933   106394.4716   \n",
       "2            13530371             1.869466   106775.2693   \n",
       "3            13617454             1.871700   107462.4870   \n",
       "4            13698428             1.874835   108101.4954   \n",
       "\n",
       "  Resident Population 2020 Census  Population Density 2020 Census  \\\n",
       "0                      12,812,508                           230.8   \n",
       "1                      12,812,508                           230.8   \n",
       "2                      12,812,508                           230.8   \n",
       "3                      12,812,508                           230.8   \n",
       "4                      12,812,508                           230.8   \n",
       "\n",
       "   Density Rank 2020 Census  SexRatio  \n",
       "0                        14        97  \n",
       "1                        14        97  \n",
       "2                        14        97  \n",
       "3                        14        97  \n",
       "4                        14        97  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Resident Population 2020 Census'] = df['Resident Population 2020 Census'].str.replace(',','').astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iowa Case_Fatality_Ratio 1\n",
      "Washington Case_Fatality_Ratio 2\n"
     ]
    }
   ],
   "source": [
    "df_gstate = df.groupby('State')\n",
    "for key,value in df_gstate:\n",
    "    groups = df_gstate.get_group(key)\n",
    "    temp = groups.iloc[:,4:]\n",
    "    for columns in temp:\n",
    "        Q1 = np.percentile(temp[columns],25)\n",
    "        Q3 = np.percentile(temp[columns],75)\n",
    "        IQR = Q3 - Q1\n",
    "        right_limit = Q3 + 1.5*IQR\n",
    "        left_limit = Q1 - 1.5*IQR\n",
    "        outlier_right_index = groups[groups[columns] > right_limit][columns].index\n",
    "        outlier_left_index = groups[groups[columns] < left_limit][columns].index\n",
    "        n_outliers = len(outlier_right_index) + len(outlier_left_index)\n",
    "        if(n_outliers > 0):\n",
    "            print(key,columns,n_outliers)\n",
    "            df.loc[outlier_right_index,columns] = right_limit\n",
    "            df.loc[outlier_left_index,columns] = left_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = (X_test - X_test.mean())/ X_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Active</th>\n",
       "      <th>Incident_Rate</th>\n",
       "      <th>Total_Test_Results</th>\n",
       "      <th>Case_Fatality_Ratio</th>\n",
       "      <th>Testing_Rate</th>\n",
       "      <th>Resident Population 2020 Census</th>\n",
       "      <th>Population Density 2020 Census</th>\n",
       "      <th>Density Rank 2020 Census</th>\n",
       "      <th>SexRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.185758</td>\n",
       "      <td>0.685045</td>\n",
       "      <td>1.624921</td>\n",
       "      <td>-0.034555</td>\n",
       "      <td>0.871610</td>\n",
       "      <td>1.714293</td>\n",
       "      <td>1.248503</td>\n",
       "      <td>0.093862</td>\n",
       "      <td>1.600344</td>\n",
       "      <td>-1.387770</td>\n",
       "      <td>-0.557150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.185758</td>\n",
       "      <td>0.685045</td>\n",
       "      <td>1.636807</td>\n",
       "      <td>-0.019067</td>\n",
       "      <td>0.879419</td>\n",
       "      <td>1.725587</td>\n",
       "      <td>1.261108</td>\n",
       "      <td>0.093862</td>\n",
       "      <td>1.600344</td>\n",
       "      <td>-1.387770</td>\n",
       "      <td>-0.557150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.185758</td>\n",
       "      <td>0.685045</td>\n",
       "      <td>1.650350</td>\n",
       "      <td>-0.001535</td>\n",
       "      <td>0.887708</td>\n",
       "      <td>1.723482</td>\n",
       "      <td>1.274487</td>\n",
       "      <td>0.093862</td>\n",
       "      <td>1.600344</td>\n",
       "      <td>-1.387770</td>\n",
       "      <td>-0.557150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.185758</td>\n",
       "      <td>0.685045</td>\n",
       "      <td>1.668580</td>\n",
       "      <td>0.022167</td>\n",
       "      <td>0.902667</td>\n",
       "      <td>1.733551</td>\n",
       "      <td>1.298632</td>\n",
       "      <td>0.093862</td>\n",
       "      <td>1.600344</td>\n",
       "      <td>-1.387770</td>\n",
       "      <td>-0.557150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.185758</td>\n",
       "      <td>0.685045</td>\n",
       "      <td>1.688737</td>\n",
       "      <td>0.048398</td>\n",
       "      <td>0.916576</td>\n",
       "      <td>1.747687</td>\n",
       "      <td>1.321083</td>\n",
       "      <td>0.093862</td>\n",
       "      <td>1.600344</td>\n",
       "      <td>-1.387770</td>\n",
       "      <td>-0.557150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1.449287</td>\n",
       "      <td>-1.903393</td>\n",
       "      <td>-0.163129</td>\n",
       "      <td>-1.654112</td>\n",
       "      <td>-0.672606</td>\n",
       "      <td>-0.486315</td>\n",
       "      <td>-0.425243</td>\n",
       "      <td>-0.463803</td>\n",
       "      <td>-0.351668</td>\n",
       "      <td>-0.102798</td>\n",
       "      <td>1.114301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>1.449287</td>\n",
       "      <td>-1.903393</td>\n",
       "      <td>-0.156348</td>\n",
       "      <td>-1.639579</td>\n",
       "      <td>-0.668592</td>\n",
       "      <td>-0.490357</td>\n",
       "      <td>-0.414460</td>\n",
       "      <td>-0.463803</td>\n",
       "      <td>-0.351668</td>\n",
       "      <td>-0.102798</td>\n",
       "      <td>1.114301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1.449287</td>\n",
       "      <td>-1.903393</td>\n",
       "      <td>-0.151034</td>\n",
       "      <td>-1.628091</td>\n",
       "      <td>-0.664255</td>\n",
       "      <td>-0.469195</td>\n",
       "      <td>-0.402811</td>\n",
       "      <td>-0.463803</td>\n",
       "      <td>-0.351668</td>\n",
       "      <td>-0.102798</td>\n",
       "      <td>1.114301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1.449287</td>\n",
       "      <td>-1.903393</td>\n",
       "      <td>-0.146139</td>\n",
       "      <td>-1.617734</td>\n",
       "      <td>-0.659315</td>\n",
       "      <td>-0.505139</td>\n",
       "      <td>-0.389542</td>\n",
       "      <td>-0.463803</td>\n",
       "      <td>-0.351668</td>\n",
       "      <td>-0.102798</td>\n",
       "      <td>1.114301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1.449287</td>\n",
       "      <td>-1.903393</td>\n",
       "      <td>-0.146139</td>\n",
       "      <td>-1.617734</td>\n",
       "      <td>-0.655189</td>\n",
       "      <td>-0.505139</td>\n",
       "      <td>-0.378461</td>\n",
       "      <td>-0.463803</td>\n",
       "      <td>-0.351668</td>\n",
       "      <td>-0.102798</td>\n",
       "      <td>1.114301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Lat     Long_    Active  Incident_Rate  Total_Test_Results  \\\n",
       "0    0.185758  0.685045  1.624921      -0.034555            0.871610   \n",
       "1    0.185758  0.685045  1.636807      -0.019067            0.879419   \n",
       "2    0.185758  0.685045  1.650350      -0.001535            0.887708   \n",
       "3    0.185758  0.685045  1.668580       0.022167            0.902667   \n",
       "4    0.185758  0.685045  1.688737       0.048398            0.916576   \n",
       "..        ...       ...       ...            ...                 ...   \n",
       "145  1.449287 -1.903393 -0.163129      -1.654112           -0.672606   \n",
       "146  1.449287 -1.903393 -0.156348      -1.639579           -0.668592   \n",
       "147  1.449287 -1.903393 -0.151034      -1.628091           -0.664255   \n",
       "148  1.449287 -1.903393 -0.146139      -1.617734           -0.659315   \n",
       "149  1.449287 -1.903393 -0.146139      -1.617734           -0.655189   \n",
       "\n",
       "     Case_Fatality_Ratio  Testing_Rate  Resident Population 2020 Census  \\\n",
       "0               1.714293      1.248503                         0.093862   \n",
       "1               1.725587      1.261108                         0.093862   \n",
       "2               1.723482      1.274487                         0.093862   \n",
       "3               1.733551      1.298632                         0.093862   \n",
       "4               1.747687      1.321083                         0.093862   \n",
       "..                   ...           ...                              ...   \n",
       "145            -0.486315     -0.425243                        -0.463803   \n",
       "146            -0.490357     -0.414460                        -0.463803   \n",
       "147            -0.469195     -0.402811                        -0.463803   \n",
       "148            -0.505139     -0.389542                        -0.463803   \n",
       "149            -0.505139     -0.378461                        -0.463803   \n",
       "\n",
       "     Population Density 2020 Census  Density Rank 2020 Census  SexRatio  \n",
       "0                          1.600344                 -1.387770 -0.557150  \n",
       "1                          1.600344                 -1.387770 -0.557150  \n",
       "2                          1.600344                 -1.387770 -0.557150  \n",
       "3                          1.600344                 -1.387770 -0.557150  \n",
       "4                          1.600344                 -1.387770 -0.557150  \n",
       "..                              ...                       ...       ...  \n",
       "145                       -0.351668                 -0.102798  1.114301  \n",
       "146                       -0.351668                 -0.102798  1.114301  \n",
       "147                       -0.351668                 -0.102798  1.114301  \n",
       "148                       -0.351668                 -0.102798  1.114301  \n",
       "149                       -0.351668                 -0.102798  1.114301  \n",
       "\n",
       "[150 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(X_test)\n",
    "x_test1 = np.reshape(x_test,(x_test.shape[0],x_test.shape[1],1))\n",
    "%store -r x_train1 y_train x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label: Recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                240       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 681\n",
      "Trainable params: 681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "lstm_recovered = tf.keras.Sequential([\n",
    "                                tf.keras.Input(shape=(11,)),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(1,activation = 'sigmoid')])\n",
    "lstm_recovered.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_recovered.compile(optimizer='adam',\n",
    "              loss='BinaryCrossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.7460 - accuracy: 0.4000 - val_loss: 0.6977 - val_accuracy: 0.4643\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7133 - accuracy: 0.4273 - val_loss: 0.6848 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6907 - accuracy: 0.4818 - val_loss: 0.6759 - val_accuracy: 0.5714\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6694 - accuracy: 0.5455 - val_loss: 0.6688 - val_accuracy: 0.5893\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6533 - accuracy: 0.6636 - val_loss: 0.6629 - val_accuracy: 0.6786\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6389 - accuracy: 0.7045 - val_loss: 0.6580 - val_accuracy: 0.6786\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6270 - accuracy: 0.7227 - val_loss: 0.6534 - val_accuracy: 0.6607\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6159 - accuracy: 0.7227 - val_loss: 0.6489 - val_accuracy: 0.6607\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6055 - accuracy: 0.7227 - val_loss: 0.6438 - val_accuracy: 0.6786\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5968 - accuracy: 0.7364 - val_loss: 0.6383 - val_accuracy: 0.6786\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5883 - accuracy: 0.7364 - val_loss: 0.6330 - val_accuracy: 0.6786\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.7318 - val_loss: 0.6285 - val_accuracy: 0.7143\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.7273 - val_loss: 0.6237 - val_accuracy: 0.6964\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5648 - accuracy: 0.7364 - val_loss: 0.6170 - val_accuracy: 0.6964\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5576 - accuracy: 0.7364 - val_loss: 0.6111 - val_accuracy: 0.6964\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5498 - accuracy: 0.7364 - val_loss: 0.6059 - val_accuracy: 0.6964\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5422 - accuracy: 0.7409 - val_loss: 0.5998 - val_accuracy: 0.7143\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.7409 - val_loss: 0.5941 - val_accuracy: 0.7143\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5261 - accuracy: 0.7409 - val_loss: 0.5857 - val_accuracy: 0.7143\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5188 - accuracy: 0.7455 - val_loss: 0.5762 - val_accuracy: 0.7143\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.7455 - val_loss: 0.5689 - val_accuracy: 0.7143\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5029 - accuracy: 0.7455 - val_loss: 0.5601 - val_accuracy: 0.7143\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.7409 - val_loss: 0.5552 - val_accuracy: 0.7143\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4872 - accuracy: 0.7455 - val_loss: 0.5471 - val_accuracy: 0.7321\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4799 - accuracy: 0.7636 - val_loss: 0.5368 - val_accuracy: 0.7679\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7818 - val_loss: 0.5294 - val_accuracy: 0.7679\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4645 - accuracy: 0.7818 - val_loss: 0.5211 - val_accuracy: 0.7857\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7909 - val_loss: 0.5149 - val_accuracy: 0.7857\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7909 - val_loss: 0.5059 - val_accuracy: 0.7679\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7864 - val_loss: 0.4961 - val_accuracy: 0.7679\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7864 - val_loss: 0.4919 - val_accuracy: 0.7679\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7909 - val_loss: 0.4831 - val_accuracy: 0.7857\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.7909 - val_loss: 0.4741 - val_accuracy: 0.7857\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4154 - accuracy: 0.8091 - val_loss: 0.4692 - val_accuracy: 0.8036\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8045 - val_loss: 0.4619 - val_accuracy: 0.8036\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4016 - accuracy: 0.8091 - val_loss: 0.4556 - val_accuracy: 0.8036\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3947 - accuracy: 0.8136 - val_loss: 0.4506 - val_accuracy: 0.8036\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3885 - accuracy: 0.8182 - val_loss: 0.4492 - val_accuracy: 0.8036\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3819 - accuracy: 0.8182 - val_loss: 0.4407 - val_accuracy: 0.8214\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3762 - accuracy: 0.8364 - val_loss: 0.4355 - val_accuracy: 0.8214\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3694 - accuracy: 0.8409 - val_loss: 0.4324 - val_accuracy: 0.8214\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3635 - accuracy: 0.8455 - val_loss: 0.4229 - val_accuracy: 0.8214\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3579 - accuracy: 0.8455 - val_loss: 0.4194 - val_accuracy: 0.8214\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3520 - accuracy: 0.8409 - val_loss: 0.4146 - val_accuracy: 0.8214\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3476 - accuracy: 0.8591 - val_loss: 0.4059 - val_accuracy: 0.8393\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3419 - accuracy: 0.8727 - val_loss: 0.4066 - val_accuracy: 0.8214\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3367 - accuracy: 0.8727 - val_loss: 0.4012 - val_accuracy: 0.8393\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3309 - accuracy: 0.8773 - val_loss: 0.3973 - val_accuracy: 0.8393\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3262 - accuracy: 0.8773 - val_loss: 0.3887 - val_accuracy: 0.8393\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3218 - accuracy: 0.8818 - val_loss: 0.3846 - val_accuracy: 0.8571\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3158 - accuracy: 0.9000 - val_loss: 0.3787 - val_accuracy: 0.8571\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3114 - accuracy: 0.9045 - val_loss: 0.3772 - val_accuracy: 0.8571\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3068 - accuracy: 0.9091 - val_loss: 0.3714 - val_accuracy: 0.8571\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3023 - accuracy: 0.9136 - val_loss: 0.3648 - val_accuracy: 0.8571\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2979 - accuracy: 0.9182 - val_loss: 0.3643 - val_accuracy: 0.8571\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2930 - accuracy: 0.9182 - val_loss: 0.3568 - val_accuracy: 0.8571\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2886 - accuracy: 0.9227 - val_loss: 0.3524 - val_accuracy: 0.8571\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2847 - accuracy: 0.9227 - val_loss: 0.3454 - val_accuracy: 0.8571\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2813 - accuracy: 0.9227 - val_loss: 0.3525 - val_accuracy: 0.8750\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2763 - accuracy: 0.9318 - val_loss: 0.3481 - val_accuracy: 0.8750\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2722 - accuracy: 0.9273 - val_loss: 0.3400 - val_accuracy: 0.8750\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2690 - accuracy: 0.9318 - val_loss: 0.3367 - val_accuracy: 0.8750\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2649 - accuracy: 0.9364 - val_loss: 0.3293 - val_accuracy: 0.8750\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2611 - accuracy: 0.9409 - val_loss: 0.3293 - val_accuracy: 0.8750\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2577 - accuracy: 0.9409 - val_loss: 0.3235 - val_accuracy: 0.8750\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2541 - accuracy: 0.9409 - val_loss: 0.3205 - val_accuracy: 0.8750\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2518 - accuracy: 0.9409 - val_loss: 0.3138 - val_accuracy: 0.8750\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2483 - accuracy: 0.9409 - val_loss: 0.3188 - val_accuracy: 0.8929\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2444 - accuracy: 0.9409 - val_loss: 0.3128 - val_accuracy: 0.8929\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2418 - accuracy: 0.9409 - val_loss: 0.3098 - val_accuracy: 0.8929\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2388 - accuracy: 0.9409 - val_loss: 0.3127 - val_accuracy: 0.8929\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2352 - accuracy: 0.9409 - val_loss: 0.3063 - val_accuracy: 0.8929\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2325 - accuracy: 0.9409 - val_loss: 0.3025 - val_accuracy: 0.8929\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2298 - accuracy: 0.9409 - val_loss: 0.3007 - val_accuracy: 0.8929\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2273 - accuracy: 0.9409 - val_loss: 0.2958 - val_accuracy: 0.8929\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2241 - accuracy: 0.9455 - val_loss: 0.2952 - val_accuracy: 0.8929\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2220 - accuracy: 0.9455 - val_loss: 0.2919 - val_accuracy: 0.8929\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2195 - accuracy: 0.9455 - val_loss: 0.2901 - val_accuracy: 0.8929\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2168 - accuracy: 0.9409 - val_loss: 0.2916 - val_accuracy: 0.8929\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2153 - accuracy: 0.9409 - val_loss: 0.2842 - val_accuracy: 0.8929\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2128 - accuracy: 0.9409 - val_loss: 0.2871 - val_accuracy: 0.8929\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2096 - accuracy: 0.9409 - val_loss: 0.2863 - val_accuracy: 0.8929\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2076 - accuracy: 0.9455 - val_loss: 0.2831 - val_accuracy: 0.8929\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2055 - accuracy: 0.9455 - val_loss: 0.2797 - val_accuracy: 0.8929\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2031 - accuracy: 0.9455 - val_loss: 0.2769 - val_accuracy: 0.8929\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2014 - accuracy: 0.9455 - val_loss: 0.2752 - val_accuracy: 0.8929\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1998 - accuracy: 0.9455 - val_loss: 0.2724 - val_accuracy: 0.8929\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1976 - accuracy: 0.9455 - val_loss: 0.2748 - val_accuracy: 0.8929\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1960 - accuracy: 0.9455 - val_loss: 0.2705 - val_accuracy: 0.8929\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1938 - accuracy: 0.9455 - val_loss: 0.2705 - val_accuracy: 0.8929\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1930 - accuracy: 0.9500 - val_loss: 0.2758 - val_accuracy: 0.8929\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1903 - accuracy: 0.9500 - val_loss: 0.2680 - val_accuracy: 0.8929\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1883 - accuracy: 0.9500 - val_loss: 0.2644 - val_accuracy: 0.9107\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1873 - accuracy: 0.9455 - val_loss: 0.2631 - val_accuracy: 0.8929\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1850 - accuracy: 0.9455 - val_loss: 0.2636 - val_accuracy: 0.9107\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.9545 - val_loss: 0.2590 - val_accuracy: 0.9107\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1828 - accuracy: 0.9500 - val_loss: 0.2650 - val_accuracy: 0.9107\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1806 - accuracy: 0.9545 - val_loss: 0.2610 - val_accuracy: 0.9107\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.9545 - val_loss: 0.2561 - val_accuracy: 0.9107\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1775 - accuracy: 0.9545 - val_loss: 0.2557 - val_accuracy: 0.9107\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1760 - accuracy: 0.9545 - val_loss: 0.2576 - val_accuracy: 0.8929\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1742 - accuracy: 0.9545 - val_loss: 0.2563 - val_accuracy: 0.8929\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1750 - accuracy: 0.9500 - val_loss: 0.2465 - val_accuracy: 0.9464\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1717 - accuracy: 0.9500 - val_loss: 0.2525 - val_accuracy: 0.9286\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1711 - accuracy: 0.9545 - val_loss: 0.2573 - val_accuracy: 0.9107\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1693 - accuracy: 0.9545 - val_loss: 0.2523 - val_accuracy: 0.9286\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1675 - accuracy: 0.9545 - val_loss: 0.2481 - val_accuracy: 0.9286\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1661 - accuracy: 0.9591 - val_loss: 0.2510 - val_accuracy: 0.9286\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1642 - accuracy: 0.9591 - val_loss: 0.2489 - val_accuracy: 0.9286\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1632 - accuracy: 0.9545 - val_loss: 0.2512 - val_accuracy: 0.9286\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.9591 - val_loss: 0.2467 - val_accuracy: 0.9286\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1603 - accuracy: 0.9591 - val_loss: 0.2478 - val_accuracy: 0.9286\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1592 - accuracy: 0.9591 - val_loss: 0.2466 - val_accuracy: 0.9286\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1584 - accuracy: 0.9591 - val_loss: 0.2490 - val_accuracy: 0.9286\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1567 - accuracy: 0.9591 - val_loss: 0.2454 - val_accuracy: 0.9286\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1559 - accuracy: 0.9591 - val_loss: 0.2468 - val_accuracy: 0.9286\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1546 - accuracy: 0.9591 - val_loss: 0.2426 - val_accuracy: 0.9286\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1536 - accuracy: 0.9591 - val_loss: 0.2465 - val_accuracy: 0.9286\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1534 - accuracy: 0.9591 - val_loss: 0.2415 - val_accuracy: 0.9286\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1528 - accuracy: 0.9591 - val_loss: 0.2495 - val_accuracy: 0.9286\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1511 - accuracy: 0.9591 - val_loss: 0.2404 - val_accuracy: 0.9107\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1492 - accuracy: 0.9591 - val_loss: 0.2402 - val_accuracy: 0.9107\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1484 - accuracy: 0.9591 - val_loss: 0.2429 - val_accuracy: 0.9107\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1470 - accuracy: 0.9591 - val_loss: 0.2432 - val_accuracy: 0.9107\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1466 - accuracy: 0.9591 - val_loss: 0.2419 - val_accuracy: 0.9107\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9591 - val_loss: 0.2424 - val_accuracy: 0.9107\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9591 - val_loss: 0.2386 - val_accuracy: 0.9107\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1435 - accuracy: 0.9591 - val_loss: 0.2374 - val_accuracy: 0.9107\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9591 - val_loss: 0.2394 - val_accuracy: 0.9107\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1421 - accuracy: 0.9591 - val_loss: 0.2421 - val_accuracy: 0.9107\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1410 - accuracy: 0.9591 - val_loss: 0.2435 - val_accuracy: 0.9107\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1403 - accuracy: 0.9591 - val_loss: 0.2383 - val_accuracy: 0.9107\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1398 - accuracy: 0.9591 - val_loss: 0.2437 - val_accuracy: 0.9107\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1381 - accuracy: 0.9591 - val_loss: 0.2392 - val_accuracy: 0.9107\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1379 - accuracy: 0.9591 - val_loss: 0.2413 - val_accuracy: 0.9107\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1367 - accuracy: 0.9591 - val_loss: 0.2392 - val_accuracy: 0.9107\n",
      "Epoch 137/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1359 - accuracy: 0.9591 - val_loss: 0.2390 - val_accuracy: 0.9107\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1357 - accuracy: 0.9591 - val_loss: 0.2404 - val_accuracy: 0.9107\n",
      "Epoch 139/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1350 - accuracy: 0.9591 - val_loss: 0.2381 - val_accuracy: 0.9107\n",
      "Epoch 140/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1343 - accuracy: 0.9591 - val_loss: 0.2351 - val_accuracy: 0.9107\n",
      "Epoch 141/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1330 - accuracy: 0.9591 - val_loss: 0.2355 - val_accuracy: 0.9107\n",
      "Epoch 142/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1322 - accuracy: 0.9591 - val_loss: 0.2414 - val_accuracy: 0.9107\n",
      "Epoch 143/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1317 - accuracy: 0.9591 - val_loss: 0.2420 - val_accuracy: 0.9107\n",
      "Epoch 144/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1314 - accuracy: 0.9591 - val_loss: 0.2424 - val_accuracy: 0.9107\n",
      "Epoch 145/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1307 - accuracy: 0.9636 - val_loss: 0.2365 - val_accuracy: 0.9107\n",
      "Epoch 146/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1296 - accuracy: 0.9636 - val_loss: 0.2384 - val_accuracy: 0.9107\n",
      "Epoch 147/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1288 - accuracy: 0.9636 - val_loss: 0.2363 - val_accuracy: 0.9107\n",
      "Epoch 148/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1283 - accuracy: 0.9636 - val_loss: 0.2367 - val_accuracy: 0.9107\n",
      "Epoch 149/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1283 - accuracy: 0.9636 - val_loss: 0.2404 - val_accuracy: 0.9107\n",
      "Epoch 150/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1277 - accuracy: 0.9636 - val_loss: 0.2391 - val_accuracy: 0.9107\n",
      "Epoch 151/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1268 - accuracy: 0.9636 - val_loss: 0.2429 - val_accuracy: 0.9107\n",
      "Epoch 152/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1255 - accuracy: 0.9636 - val_loss: 0.2414 - val_accuracy: 0.9107\n",
      "Epoch 153/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1249 - accuracy: 0.9636 - val_loss: 0.2369 - val_accuracy: 0.9107\n",
      "Epoch 154/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1248 - accuracy: 0.9636 - val_loss: 0.2363 - val_accuracy: 0.9107\n",
      "Epoch 155/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1245 - accuracy: 0.9636 - val_loss: 0.2371 - val_accuracy: 0.9107\n",
      "Epoch 156/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1239 - accuracy: 0.9636 - val_loss: 0.2397 - val_accuracy: 0.9107\n",
      "Epoch 157/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1237 - accuracy: 0.9636 - val_loss: 0.2357 - val_accuracy: 0.9107\n",
      "Epoch 158/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1228 - accuracy: 0.9636 - val_loss: 0.2396 - val_accuracy: 0.9107\n",
      "Epoch 159/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1218 - accuracy: 0.9636 - val_loss: 0.2405 - val_accuracy: 0.9107\n",
      "Epoch 160/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1220 - accuracy: 0.9636 - val_loss: 0.2410 - val_accuracy: 0.9107\n",
      "Epoch 161/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1219 - accuracy: 0.9636 - val_loss: 0.2404 - val_accuracy: 0.9107\n",
      "Epoch 162/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1206 - accuracy: 0.9636 - val_loss: 0.2425 - val_accuracy: 0.9107\n",
      "Epoch 163/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1200 - accuracy: 0.9636 - val_loss: 0.2418 - val_accuracy: 0.9107\n",
      "Epoch 164/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1199 - accuracy: 0.9636 - val_loss: 0.2395 - val_accuracy: 0.9107\n",
      "Epoch 165/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1191 - accuracy: 0.9636 - val_loss: 0.2406 - val_accuracy: 0.9107\n",
      "Epoch 166/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1187 - accuracy: 0.9636 - val_loss: 0.2395 - val_accuracy: 0.9107\n",
      "Epoch 167/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1189 - accuracy: 0.9636 - val_loss: 0.2370 - val_accuracy: 0.9107\n",
      "Epoch 168/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1181 - accuracy: 0.9636 - val_loss: 0.2427 - val_accuracy: 0.9107\n",
      "Epoch 169/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1181 - accuracy: 0.9636 - val_loss: 0.2462 - val_accuracy: 0.9107\n",
      "Epoch 170/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1178 - accuracy: 0.9636 - val_loss: 0.2443 - val_accuracy: 0.9107\n",
      "Epoch 171/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1168 - accuracy: 0.9636 - val_loss: 0.2389 - val_accuracy: 0.9107\n",
      "Epoch 172/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1157 - accuracy: 0.9636 - val_loss: 0.2431 - val_accuracy: 0.9107\n",
      "Epoch 173/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9636 - val_loss: 0.2485 - val_accuracy: 0.9107\n",
      "Epoch 174/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1175 - accuracy: 0.9636 - val_loss: 0.2370 - val_accuracy: 0.9107\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1152 - accuracy: 0.9636 - val_loss: 0.2432 - val_accuracy: 0.9107\n",
      "Epoch 176/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1146 - accuracy: 0.9636 - val_loss: 0.2443 - val_accuracy: 0.9107\n",
      "Epoch 177/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1146 - accuracy: 0.9636 - val_loss: 0.2468 - val_accuracy: 0.9107\n",
      "Epoch 178/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1138 - accuracy: 0.9636 - val_loss: 0.2445 - val_accuracy: 0.9107\n",
      "Epoch 179/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1149 - accuracy: 0.9636 - val_loss: 0.2354 - val_accuracy: 0.9107\n",
      "Epoch 180/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1134 - accuracy: 0.9636 - val_loss: 0.2385 - val_accuracy: 0.9107\n",
      "Epoch 181/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1128 - accuracy: 0.9636 - val_loss: 0.2461 - val_accuracy: 0.9107\n",
      "Epoch 182/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1125 - accuracy: 0.9636 - val_loss: 0.2477 - val_accuracy: 0.9107\n",
      "Epoch 183/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1122 - accuracy: 0.9636 - val_loss: 0.2496 - val_accuracy: 0.9107\n",
      "Epoch 184/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1118 - accuracy: 0.9636 - val_loss: 0.2476 - val_accuracy: 0.9107\n",
      "Epoch 185/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1118 - accuracy: 0.9636 - val_loss: 0.2506 - val_accuracy: 0.9107\n",
      "Epoch 186/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1104 - accuracy: 0.9636 - val_loss: 0.2449 - val_accuracy: 0.9107\n",
      "Epoch 187/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1104 - accuracy: 0.9636 - val_loss: 0.2444 - val_accuracy: 0.9107\n",
      "Epoch 188/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1105 - accuracy: 0.9591 - val_loss: 0.2422 - val_accuracy: 0.9107\n",
      "Epoch 189/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1110 - accuracy: 0.9636 - val_loss: 0.2499 - val_accuracy: 0.9107\n",
      "Epoch 190/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1098 - accuracy: 0.9636 - val_loss: 0.2520 - val_accuracy: 0.9107\n",
      "Epoch 191/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1096 - accuracy: 0.9636 - val_loss: 0.2447 - val_accuracy: 0.9107\n",
      "Epoch 192/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1095 - accuracy: 0.9591 - val_loss: 0.2440 - val_accuracy: 0.9107\n",
      "Epoch 193/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1088 - accuracy: 0.9591 - val_loss: 0.2492 - val_accuracy: 0.9107\n",
      "Epoch 194/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1081 - accuracy: 0.9636 - val_loss: 0.2531 - val_accuracy: 0.9107\n",
      "Epoch 195/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1081 - accuracy: 0.9636 - val_loss: 0.2545 - val_accuracy: 0.9107\n",
      "Epoch 196/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1078 - accuracy: 0.9636 - val_loss: 0.2448 - val_accuracy: 0.9107\n",
      "Epoch 197/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1071 - accuracy: 0.9636 - val_loss: 0.2465 - val_accuracy: 0.9107\n",
      "Epoch 198/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1068 - accuracy: 0.9591 - val_loss: 0.2475 - val_accuracy: 0.9107\n",
      "Epoch 199/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1061 - accuracy: 0.9591 - val_loss: 0.2534 - val_accuracy: 0.9107\n",
      "Epoch 200/200\n",
      "7/7 [==============================] - 0s 669us/step - loss: 0.1068 - accuracy: 0.9591 - val_loss: 0.2542 - val_accuracy: 0.9107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x242c0bbcd90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_recovered.fit(x_train,y_train.iloc[:,-1],epochs=200,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_recovered = lstm_recovered.predict(x_test) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_recovered.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label: Deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_deaths = pd.read_csv('cleaned_deaths_coviddata.csv')\n",
    "x_dtrain,y_dtrain = pd_deaths.iloc[:,:-1],pd_deaths.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                480       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,321\n",
      "Trainable params: 1,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "lstm_deaths = tf.keras.Sequential([\n",
    "                                 tf.keras.Input(shape=(11,)),\n",
    "                                tf.keras.layers.Dense(40,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(1,activation = 'sigmoid')])\n",
    "lstm_deaths.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_deaths.compile(optimizer='adam',\n",
    "              loss='BinaryCrossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/190\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6263 - accuracy: 0.6477 - val_loss: 0.7398 - val_accuracy: 0.4639\n",
      "Epoch 2/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5328 - accuracy: 0.7211 - val_loss: 0.6553 - val_accuracy: 0.6606\n",
      "Epoch 3/190\n",
      "63/63 [==============================] - 0s 996us/step - loss: 0.4919 - accuracy: 0.7497 - val_loss: 0.6328 - val_accuracy: 0.6466\n",
      "Epoch 4/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4645 - accuracy: 0.7693 - val_loss: 0.6313 - val_accuracy: 0.6145\n",
      "Epoch 5/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4481 - accuracy: 0.7749 - val_loss: 0.6309 - val_accuracy: 0.6325\n",
      "Epoch 6/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4356 - accuracy: 0.7844 - val_loss: 0.6891 - val_accuracy: 0.5843\n",
      "Epoch 7/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4255 - accuracy: 0.7925 - val_loss: 0.5873 - val_accuracy: 0.7430\n",
      "Epoch 8/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4162 - accuracy: 0.7990 - val_loss: 0.5987 - val_accuracy: 0.7048\n",
      "Epoch 9/190\n",
      "63/63 [==============================] - 0s 897us/step - loss: 0.4078 - accuracy: 0.8095 - val_loss: 0.6025 - val_accuracy: 0.7129\n",
      "Epoch 10/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4021 - accuracy: 0.8035 - val_loss: 0.6125 - val_accuracy: 0.6928\n",
      "Epoch 11/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3965 - accuracy: 0.8146 - val_loss: 0.5791 - val_accuracy: 0.7149\n",
      "Epoch 12/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3957 - accuracy: 0.8070 - val_loss: 0.5847 - val_accuracy: 0.7390\n",
      "Epoch 13/190\n",
      "63/63 [==============================] - 0s 860us/step - loss: 0.3906 - accuracy: 0.8121 - val_loss: 0.6197 - val_accuracy: 0.6867\n",
      "Epoch 14/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3849 - accuracy: 0.8176 - val_loss: 0.6316 - val_accuracy: 0.6707\n",
      "Epoch 15/190\n",
      "63/63 [==============================] - 0s 981us/step - loss: 0.3809 - accuracy: 0.8146 - val_loss: 0.5459 - val_accuracy: 0.7731\n",
      "Epoch 16/190\n",
      "63/63 [==============================] - 0s 969us/step - loss: 0.3809 - accuracy: 0.8111 - val_loss: 0.5132 - val_accuracy: 0.8333\n",
      "Epoch 17/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3765 - accuracy: 0.8166 - val_loss: 0.6117 - val_accuracy: 0.7289\n",
      "Epoch 18/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3763 - accuracy: 0.8196 - val_loss: 0.5675 - val_accuracy: 0.7490\n",
      "Epoch 19/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3723 - accuracy: 0.8296 - val_loss: 0.4909 - val_accuracy: 0.8635\n",
      "Epoch 20/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3698 - accuracy: 0.8246 - val_loss: 0.5032 - val_accuracy: 0.8494\n",
      "Epoch 21/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3683 - accuracy: 0.8266 - val_loss: 0.4750 - val_accuracy: 0.8614\n",
      "Epoch 22/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3671 - accuracy: 0.8196 - val_loss: 0.5063 - val_accuracy: 0.8414\n",
      "Epoch 23/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3672 - accuracy: 0.8226 - val_loss: 0.5078 - val_accuracy: 0.8534\n",
      "Epoch 24/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3676 - accuracy: 0.8281 - val_loss: 0.4108 - val_accuracy: 0.8876\n",
      "Epoch 25/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3658 - accuracy: 0.8291 - val_loss: 0.4437 - val_accuracy: 0.8635\n",
      "Epoch 26/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3639 - accuracy: 0.8251 - val_loss: 0.4524 - val_accuracy: 0.8815\n",
      "Epoch 27/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3645 - accuracy: 0.8251 - val_loss: 0.5140 - val_accuracy: 0.8353\n",
      "Epoch 28/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3600 - accuracy: 0.8296 - val_loss: 0.5227 - val_accuracy: 0.8173\n",
      "Epoch 29/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3637 - accuracy: 0.8196 - val_loss: 0.5093 - val_accuracy: 0.8614\n",
      "Epoch 30/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3598 - accuracy: 0.8261 - val_loss: 0.5031 - val_accuracy: 0.8614\n",
      "Epoch 31/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3594 - accuracy: 0.8276 - val_loss: 0.4666 - val_accuracy: 0.8735\n",
      "Epoch 32/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3566 - accuracy: 0.8317 - val_loss: 0.4755 - val_accuracy: 0.8675\n",
      "Epoch 33/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3560 - accuracy: 0.8327 - val_loss: 0.4872 - val_accuracy: 0.8454\n",
      "Epoch 34/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3540 - accuracy: 0.8261 - val_loss: 0.4262 - val_accuracy: 0.8835\n",
      "Epoch 35/190\n",
      "63/63 [==============================] - 0s 894us/step - loss: 0.3565 - accuracy: 0.8271 - val_loss: 0.5077 - val_accuracy: 0.8253\n",
      "Epoch 36/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3534 - accuracy: 0.8296 - val_loss: 0.4703 - val_accuracy: 0.8715\n",
      "Epoch 37/190\n",
      "63/63 [==============================] - 0s 885us/step - loss: 0.3533 - accuracy: 0.8266 - val_loss: 0.4281 - val_accuracy: 0.8835\n",
      "Epoch 38/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.8296 - val_loss: 0.4416 - val_accuracy: 0.8795\n",
      "Epoch 39/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3547 - accuracy: 0.8296 - val_loss: 0.5019 - val_accuracy: 0.8454\n",
      "Epoch 40/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.8296 - val_loss: 0.3902 - val_accuracy: 0.8855\n",
      "Epoch 41/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3539 - accuracy: 0.8317 - val_loss: 0.4728 - val_accuracy: 0.8233\n",
      "Epoch 42/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3510 - accuracy: 0.8291 - val_loss: 0.4167 - val_accuracy: 0.8815\n",
      "Epoch 43/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3522 - accuracy: 0.8377 - val_loss: 0.4089 - val_accuracy: 0.8835\n",
      "Epoch 44/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3486 - accuracy: 0.8312 - val_loss: 0.4528 - val_accuracy: 0.8554\n",
      "Epoch 45/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3481 - accuracy: 0.8307 - val_loss: 0.4944 - val_accuracy: 0.8353\n",
      "Epoch 46/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3499 - accuracy: 0.8312 - val_loss: 0.4675 - val_accuracy: 0.8534\n",
      "Epoch 47/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3474 - accuracy: 0.8291 - val_loss: 0.4819 - val_accuracy: 0.8534\n",
      "Epoch 48/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3468 - accuracy: 0.8357 - val_loss: 0.4246 - val_accuracy: 0.8775\n",
      "Epoch 49/190\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3476 - accuracy: 0.8317 - val_loss: 0.4050 - val_accuracy: 0.8896\n",
      "Epoch 50/190\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3451 - accuracy: 0.8317 - val_loss: 0.4984 - val_accuracy: 0.8273\n",
      "Epoch 51/190\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3453 - accuracy: 0.8322 - val_loss: 0.4455 - val_accuracy: 0.8815\n",
      "Epoch 52/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3477 - accuracy: 0.8332 - val_loss: 0.4752 - val_accuracy: 0.8554\n",
      "Epoch 53/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3433 - accuracy: 0.8352 - val_loss: 0.4416 - val_accuracy: 0.8635\n",
      "Epoch 54/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3463 - accuracy: 0.8347 - val_loss: 0.4394 - val_accuracy: 0.8715\n",
      "Epoch 55/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3424 - accuracy: 0.8347 - val_loss: 0.4515 - val_accuracy: 0.8675\n",
      "Epoch 56/190\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8327 - val_loss: 0.4261 - val_accuracy: 0.8755\n",
      "Epoch 57/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3443 - accuracy: 0.8367 - val_loss: 0.4554 - val_accuracy: 0.8795\n",
      "Epoch 58/190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3471 - accuracy: 0.8256 - val_loss: 0.4799 - val_accuracy: 0.8434\n",
      "Epoch 59/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3438 - accuracy: 0.8347 - val_loss: 0.4700 - val_accuracy: 0.8153\n",
      "Epoch 60/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3427 - accuracy: 0.8307 - val_loss: 0.3956 - val_accuracy: 0.8876\n",
      "Epoch 61/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3448 - accuracy: 0.8307 - val_loss: 0.5071 - val_accuracy: 0.8012\n",
      "Epoch 62/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3416 - accuracy: 0.8372 - val_loss: 0.4013 - val_accuracy: 0.8896\n",
      "Epoch 63/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3410 - accuracy: 0.8377 - val_loss: 0.5898 - val_accuracy: 0.7470\n",
      "Epoch 64/190\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3390 - accuracy: 0.8372 - val_loss: 0.4742 - val_accuracy: 0.8534\n",
      "Epoch 65/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3386 - accuracy: 0.8347 - val_loss: 0.3695 - val_accuracy: 0.8896\n",
      "Epoch 66/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3396 - accuracy: 0.8387 - val_loss: 0.4945 - val_accuracy: 0.8253\n",
      "Epoch 67/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3389 - accuracy: 0.8402 - val_loss: 0.4114 - val_accuracy: 0.8855\n",
      "Epoch 68/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3382 - accuracy: 0.8337 - val_loss: 0.4247 - val_accuracy: 0.8755\n",
      "Epoch 69/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3387 - accuracy: 0.8362 - val_loss: 0.4490 - val_accuracy: 0.8815\n",
      "Epoch 70/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3377 - accuracy: 0.8387 - val_loss: 0.4256 - val_accuracy: 0.8695\n",
      "Epoch 71/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3379 - accuracy: 0.8317 - val_loss: 0.3751 - val_accuracy: 0.8916\n",
      "Epoch 72/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.8352 - val_loss: 0.4895 - val_accuracy: 0.8273\n",
      "Epoch 73/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8387 - val_loss: 0.4069 - val_accuracy: 0.8795\n",
      "Epoch 74/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3347 - accuracy: 0.8412 - val_loss: 0.5235 - val_accuracy: 0.8092\n",
      "Epoch 75/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.8407 - val_loss: 0.4624 - val_accuracy: 0.8434\n",
      "Epoch 76/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8402 - val_loss: 0.4447 - val_accuracy: 0.8655\n",
      "Epoch 77/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8387 - val_loss: 0.4287 - val_accuracy: 0.8534\n",
      "Epoch 78/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3353 - accuracy: 0.8372 - val_loss: 0.3815 - val_accuracy: 0.8916\n",
      "Epoch 79/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3332 - accuracy: 0.8367 - val_loss: 0.3925 - val_accuracy: 0.8936\n",
      "Epoch 80/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3366 - accuracy: 0.8437 - val_loss: 0.4007 - val_accuracy: 0.8916\n",
      "Epoch 81/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8407 - val_loss: 0.4652 - val_accuracy: 0.8454\n",
      "Epoch 82/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8402 - val_loss: 0.4159 - val_accuracy: 0.8876\n",
      "Epoch 83/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8442 - val_loss: 0.3805 - val_accuracy: 0.8855\n",
      "Epoch 84/190\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8422 - val_loss: 0.4702 - val_accuracy: 0.8353\n",
      "Epoch 85/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8412 - val_loss: 0.3921 - val_accuracy: 0.8675\n",
      "Epoch 86/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.8362 - val_loss: 0.4905 - val_accuracy: 0.7972\n",
      "Epoch 87/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8412 - val_loss: 0.3780 - val_accuracy: 0.8916\n",
      "Epoch 88/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8407 - val_loss: 0.4882 - val_accuracy: 0.8173\n",
      "Epoch 89/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8372 - val_loss: 0.4409 - val_accuracy: 0.8675\n",
      "Epoch 90/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8427 - val_loss: 0.4070 - val_accuracy: 0.8755\n",
      "Epoch 91/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3304 - accuracy: 0.8447 - val_loss: 0.5092 - val_accuracy: 0.7671\n",
      "Epoch 92/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8417 - val_loss: 0.3756 - val_accuracy: 0.8976\n",
      "Epoch 93/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8432 - val_loss: 0.3172 - val_accuracy: 0.9157\n",
      "Epoch 94/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8437 - val_loss: 0.3791 - val_accuracy: 0.8996\n",
      "Epoch 95/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8387 - val_loss: 0.4378 - val_accuracy: 0.8474\n",
      "Epoch 96/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8412 - val_loss: 0.4034 - val_accuracy: 0.8715\n",
      "Epoch 97/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8387 - val_loss: 0.4982 - val_accuracy: 0.7691\n",
      "Epoch 98/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8477 - val_loss: 0.3947 - val_accuracy: 0.8936\n",
      "Epoch 99/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3257 - accuracy: 0.8477 - val_loss: 0.4103 - val_accuracy: 0.8534\n",
      "Epoch 100/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8447 - val_loss: 0.4382 - val_accuracy: 0.8574\n",
      "Epoch 101/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3268 - accuracy: 0.8472 - val_loss: 0.4224 - val_accuracy: 0.8514\n",
      "Epoch 102/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8422 - val_loss: 0.4181 - val_accuracy: 0.8755\n",
      "Epoch 103/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3273 - accuracy: 0.8472 - val_loss: 0.4154 - val_accuracy: 0.8514\n",
      "Epoch 104/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3256 - accuracy: 0.8472 - val_loss: 0.5183 - val_accuracy: 0.7329\n",
      "Epoch 105/190\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8397 - val_loss: 0.3764 - val_accuracy: 0.8996\n",
      "Epoch 106/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3248 - accuracy: 0.8518 - val_loss: 0.4468 - val_accuracy: 0.8594\n",
      "Epoch 107/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8447 - val_loss: 0.3200 - val_accuracy: 0.9197\n",
      "Epoch 108/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3258 - accuracy: 0.8392 - val_loss: 0.3775 - val_accuracy: 0.8896\n",
      "Epoch 109/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3246 - accuracy: 0.8432 - val_loss: 0.4516 - val_accuracy: 0.8353\n",
      "Epoch 110/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3247 - accuracy: 0.8482 - val_loss: 0.4314 - val_accuracy: 0.8855\n",
      "Epoch 111/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3256 - accuracy: 0.8482 - val_loss: 0.4797 - val_accuracy: 0.8514\n",
      "Epoch 112/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3259 - accuracy: 0.8422 - val_loss: 0.3884 - val_accuracy: 0.8896\n",
      "Epoch 113/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3245 - accuracy: 0.8462 - val_loss: 0.4056 - val_accuracy: 0.8755\n",
      "Epoch 114/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3225 - accuracy: 0.8492 - val_loss: 0.4085 - val_accuracy: 0.8775\n",
      "Epoch 115/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3238 - accuracy: 0.8462 - val_loss: 0.3871 - val_accuracy: 0.8855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3229 - accuracy: 0.8492 - val_loss: 0.4040 - val_accuracy: 0.8594\n",
      "Epoch 117/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3223 - accuracy: 0.8508 - val_loss: 0.4158 - val_accuracy: 0.8534\n",
      "Epoch 118/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3207 - accuracy: 0.8452 - val_loss: 0.4100 - val_accuracy: 0.8695\n",
      "Epoch 119/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3204 - accuracy: 0.8457 - val_loss: 0.4034 - val_accuracy: 0.8855\n",
      "Epoch 120/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3232 - accuracy: 0.8482 - val_loss: 0.4137 - val_accuracy: 0.8635\n",
      "Epoch 121/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3228 - accuracy: 0.8462 - val_loss: 0.3579 - val_accuracy: 0.9036\n",
      "Epoch 122/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3203 - accuracy: 0.8442 - val_loss: 0.4037 - val_accuracy: 0.8735\n",
      "Epoch 123/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3214 - accuracy: 0.8472 - val_loss: 0.4150 - val_accuracy: 0.8353\n",
      "Epoch 124/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3210 - accuracy: 0.8457 - val_loss: 0.3788 - val_accuracy: 0.8956\n",
      "Epoch 125/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3197 - accuracy: 0.8508 - val_loss: 0.4015 - val_accuracy: 0.8635\n",
      "Epoch 126/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3230 - accuracy: 0.8392 - val_loss: 0.3726 - val_accuracy: 0.9036\n",
      "Epoch 127/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3232 - accuracy: 0.8437 - val_loss: 0.3823 - val_accuracy: 0.8896\n",
      "Epoch 128/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3190 - accuracy: 0.8462 - val_loss: 0.3989 - val_accuracy: 0.8635\n",
      "Epoch 129/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3206 - accuracy: 0.8497 - val_loss: 0.4506 - val_accuracy: 0.8133\n",
      "Epoch 130/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3182 - accuracy: 0.8518 - val_loss: 0.4003 - val_accuracy: 0.8835\n",
      "Epoch 131/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3204 - accuracy: 0.8452 - val_loss: 0.4346 - val_accuracy: 0.8594\n",
      "Epoch 132/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3213 - accuracy: 0.8442 - val_loss: 0.4442 - val_accuracy: 0.8353\n",
      "Epoch 133/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3172 - accuracy: 0.8548 - val_loss: 0.3331 - val_accuracy: 0.9076\n",
      "Epoch 134/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3192 - accuracy: 0.8452 - val_loss: 0.4277 - val_accuracy: 0.8655\n",
      "Epoch 135/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3161 - accuracy: 0.8487 - val_loss: 0.3529 - val_accuracy: 0.9056\n",
      "Epoch 136/190\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3175 - accuracy: 0.8477 - val_loss: 0.4013 - val_accuracy: 0.8795\n",
      "Epoch 137/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3168 - accuracy: 0.8452 - val_loss: 0.3532 - val_accuracy: 0.9036\n",
      "Epoch 138/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3149 - accuracy: 0.8543 - val_loss: 0.4378 - val_accuracy: 0.8414\n",
      "Epoch 139/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3156 - accuracy: 0.8472 - val_loss: 0.3596 - val_accuracy: 0.8936\n",
      "Epoch 140/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3172 - accuracy: 0.8523 - val_loss: 0.4182 - val_accuracy: 0.8775\n",
      "Epoch 141/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3157 - accuracy: 0.8487 - val_loss: 0.3510 - val_accuracy: 0.9036\n",
      "Epoch 142/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3135 - accuracy: 0.8513 - val_loss: 0.3924 - val_accuracy: 0.8675\n",
      "Epoch 143/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3197 - accuracy: 0.8457 - val_loss: 0.3984 - val_accuracy: 0.8976\n",
      "Epoch 144/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3138 - accuracy: 0.8477 - val_loss: 0.4745 - val_accuracy: 0.8112\n",
      "Epoch 145/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3139 - accuracy: 0.8477 - val_loss: 0.3935 - val_accuracy: 0.8675\n",
      "Epoch 146/190\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3179 - accuracy: 0.8447 - val_loss: 0.4152 - val_accuracy: 0.8514\n",
      "Epoch 147/190\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8477 - val_loss: 0.3810 - val_accuracy: 0.8695\n",
      "Epoch 148/190\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.8447 - val_loss: 0.4363 - val_accuracy: 0.8253\n",
      "Epoch 149/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3164 - accuracy: 0.8487 - val_loss: 0.3635 - val_accuracy: 0.8976\n",
      "Epoch 150/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3097 - accuracy: 0.8553 - val_loss: 0.3223 - val_accuracy: 0.9076\n",
      "Epoch 151/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3174 - accuracy: 0.8427 - val_loss: 0.3720 - val_accuracy: 0.8956\n",
      "Epoch 152/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3150 - accuracy: 0.8503 - val_loss: 0.4005 - val_accuracy: 0.8835\n",
      "Epoch 153/190\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.8452 - val_loss: 0.3069 - val_accuracy: 0.9137\n",
      "Epoch 154/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3151 - accuracy: 0.8508 - val_loss: 0.4571 - val_accuracy: 0.8534\n",
      "Epoch 155/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3129 - accuracy: 0.8482 - val_loss: 0.4100 - val_accuracy: 0.8775\n",
      "Epoch 156/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3143 - accuracy: 0.8513 - val_loss: 0.3846 - val_accuracy: 0.8755\n",
      "Epoch 157/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3109 - accuracy: 0.8523 - val_loss: 0.3909 - val_accuracy: 0.8755\n",
      "Epoch 158/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3106 - accuracy: 0.8482 - val_loss: 0.3501 - val_accuracy: 0.8855\n",
      "Epoch 159/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3148 - accuracy: 0.8467 - val_loss: 0.3732 - val_accuracy: 0.8876\n",
      "Epoch 160/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3133 - accuracy: 0.8518 - val_loss: 0.2965 - val_accuracy: 0.9177\n",
      "Epoch 161/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3137 - accuracy: 0.8457 - val_loss: 0.3558 - val_accuracy: 0.9036\n",
      "Epoch 162/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3124 - accuracy: 0.8543 - val_loss: 0.4801 - val_accuracy: 0.7711\n",
      "Epoch 163/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3132 - accuracy: 0.8472 - val_loss: 0.3940 - val_accuracy: 0.8695\n",
      "Epoch 164/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.8573 - val_loss: 0.3194 - val_accuracy: 0.9096\n",
      "Epoch 165/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3129 - accuracy: 0.8558 - val_loss: 0.3292 - val_accuracy: 0.9076\n",
      "Epoch 166/190\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8467 - val_loss: 0.3843 - val_accuracy: 0.8896\n",
      "Epoch 167/190\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8472 - val_loss: 0.4420 - val_accuracy: 0.8092\n",
      "Epoch 168/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3097 - accuracy: 0.8548 - val_loss: 0.3851 - val_accuracy: 0.8655\n",
      "Epoch 169/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3102 - accuracy: 0.8553 - val_loss: 0.4420 - val_accuracy: 0.8333\n",
      "Epoch 170/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3132 - accuracy: 0.8518 - val_loss: 0.4443 - val_accuracy: 0.8534\n",
      "Epoch 171/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3122 - accuracy: 0.8482 - val_loss: 0.3807 - val_accuracy: 0.8936\n",
      "Epoch 172/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3108 - accuracy: 0.8518 - val_loss: 0.3873 - val_accuracy: 0.8835\n",
      "Epoch 173/190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.8467 - val_loss: 0.3996 - val_accuracy: 0.8855\n",
      "Epoch 174/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3077 - accuracy: 0.8528 - val_loss: 0.3919 - val_accuracy: 0.8795\n",
      "Epoch 175/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3087 - accuracy: 0.8452 - val_loss: 0.3929 - val_accuracy: 0.8574\n",
      "Epoch 176/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3118 - accuracy: 0.8518 - val_loss: 0.3828 - val_accuracy: 0.8655\n",
      "Epoch 177/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3098 - accuracy: 0.8472 - val_loss: 0.3293 - val_accuracy: 0.9116\n",
      "Epoch 178/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3065 - accuracy: 0.8497 - val_loss: 0.3446 - val_accuracy: 0.9116\n",
      "Epoch 179/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3077 - accuracy: 0.8508 - val_loss: 0.3798 - val_accuracy: 0.8655\n",
      "Epoch 180/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3062 - accuracy: 0.8563 - val_loss: 0.3406 - val_accuracy: 0.9116\n",
      "Epoch 181/190\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8583 - val_loss: 0.3644 - val_accuracy: 0.8916\n",
      "Epoch 182/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3076 - accuracy: 0.8518 - val_loss: 0.3929 - val_accuracy: 0.8494\n",
      "Epoch 183/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3120 - accuracy: 0.8452 - val_loss: 0.3731 - val_accuracy: 0.8695\n",
      "Epoch 184/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3058 - accuracy: 0.8518 - val_loss: 0.3780 - val_accuracy: 0.8795\n",
      "Epoch 185/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3059 - accuracy: 0.8583 - val_loss: 0.3583 - val_accuracy: 0.8956\n",
      "Epoch 186/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3070 - accuracy: 0.8548 - val_loss: 0.3317 - val_accuracy: 0.8956\n",
      "Epoch 187/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3050 - accuracy: 0.8558 - val_loss: 0.3857 - val_accuracy: 0.8695\n",
      "Epoch 188/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3087 - accuracy: 0.8432 - val_loss: 0.4435 - val_accuracy: 0.8293\n",
      "Epoch 189/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3062 - accuracy: 0.8497 - val_loss: 0.4564 - val_accuracy: 0.8253\n",
      "Epoch 190/190\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3105 - accuracy: 0.8558 - val_loss: 0.4520 - val_accuracy: 0.8394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x242c1f05670>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_deaths.fit(x_dtrain,y_dtrain,epochs=190,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_deaths = (lstm_deaths.predict(x_test) > 0.50).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_deaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label : Confirmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_confirmed = pd.read_csv('cleaned_confirmed_coviddata.csv')\n",
    "x_ctrain,y_ctrain = pd_confirmed.iloc[:,:-1],pd_confirmed.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                240       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 681\n",
      "Trainable params: 681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "lstm_confirmed = tf.keras.Sequential([\n",
    "                                tf.keras.Input(shape=(11,)),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "                                tf.keras.layers.Dense(1,activation = 'sigmoid')])\n",
    "lstm_confirmed.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_confirmed.compile(optimizer='adam',\n",
    "              loss='BinaryCrossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.6348 - accuracy: 0.6838 - val_loss: 0.7292 - val_accuracy: 0.3873\n",
      "Epoch 2/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.5552 - accuracy: 0.7192 - val_loss: 0.7232 - val_accuracy: 0.3526\n",
      "Epoch 3/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4983 - accuracy: 0.7525 - val_loss: 0.6920 - val_accuracy: 0.5058\n",
      "Epoch 4/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.7800 - val_loss: 0.6421 - val_accuracy: 0.5636\n",
      "Epoch 5/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4216 - accuracy: 0.8148 - val_loss: 0.5900 - val_accuracy: 0.6965\n",
      "Epoch 6/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8198 - val_loss: 0.5511 - val_accuracy: 0.7225\n",
      "Epoch 7/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3710 - accuracy: 0.8300 - val_loss: 0.5223 - val_accuracy: 0.7341\n",
      "Epoch 8/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3526 - accuracy: 0.8459 - val_loss: 0.4610 - val_accuracy: 0.8295\n",
      "Epoch 9/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3362 - accuracy: 0.8705 - val_loss: 0.4641 - val_accuracy: 0.8121\n",
      "Epoch 10/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3198 - accuracy: 0.8893 - val_loss: 0.4131 - val_accuracy: 0.8410\n",
      "Epoch 11/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3061 - accuracy: 0.8965 - val_loss: 0.4033 - val_accuracy: 0.8382\n",
      "Epoch 12/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2933 - accuracy: 0.8915 - val_loss: 0.3562 - val_accuracy: 0.8468\n",
      "Epoch 13/200\n",
      "44/44 [==============================] - 0s 938us/step - loss: 0.2826 - accuracy: 0.8951 - val_loss: 0.3564 - val_accuracy: 0.8410\n",
      "Epoch 14/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.2702 - accuracy: 0.8973 - val_loss: 0.3607 - val_accuracy: 0.8439\n",
      "Epoch 15/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.2603 - accuracy: 0.9001 - val_loss: 0.3266 - val_accuracy: 0.8468\n",
      "Epoch 16/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.2530 - accuracy: 0.9052 - val_loss: 0.3260 - val_accuracy: 0.8497\n",
      "Epoch 17/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.2446 - accuracy: 0.9103 - val_loss: 0.3053 - val_accuracy: 0.8497\n",
      "Epoch 18/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.2381 - accuracy: 0.9088 - val_loss: 0.2849 - val_accuracy: 0.8671\n",
      "Epoch 19/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2302 - accuracy: 0.9124 - val_loss: 0.3126 - val_accuracy: 0.8844\n",
      "Epoch 20/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.2255 - accuracy: 0.9197 - val_loss: 0.2846 - val_accuracy: 0.8988\n",
      "Epoch 21/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.2205 - accuracy: 0.9284 - val_loss: 0.2992 - val_accuracy: 0.8873\n",
      "Epoch 22/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2176 - accuracy: 0.9305 - val_loss: 0.3057 - val_accuracy: 0.8844\n",
      "Epoch 23/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.2120 - accuracy: 0.9342 - val_loss: 0.2516 - val_accuracy: 0.9422\n",
      "Epoch 24/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.2112 - accuracy: 0.9334 - val_loss: 0.2989 - val_accuracy: 0.9017\n",
      "Epoch 25/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.2058 - accuracy: 0.9392 - val_loss: 0.2546 - val_accuracy: 0.9393\n",
      "Epoch 26/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.2036 - accuracy: 0.9392 - val_loss: 0.2732 - val_accuracy: 0.9075\n",
      "Epoch 27/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.2035 - accuracy: 0.9378 - val_loss: 0.2640 - val_accuracy: 0.9335\n",
      "Epoch 28/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.2001 - accuracy: 0.9370 - val_loss: 0.2544 - val_accuracy: 0.9393\n",
      "Epoch 29/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.9407 - val_loss: 0.2370 - val_accuracy: 0.9393\n",
      "Epoch 30/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1966 - accuracy: 0.9385 - val_loss: 0.2458 - val_accuracy: 0.9422\n",
      "Epoch 31/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1926 - accuracy: 0.9385 - val_loss: 0.2500 - val_accuracy: 0.9393\n",
      "Epoch 32/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1912 - accuracy: 0.9399 - val_loss: 0.2274 - val_accuracy: 0.9422\n",
      "Epoch 33/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1906 - accuracy: 0.9392 - val_loss: 0.2493 - val_accuracy: 0.9393\n",
      "Epoch 34/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1893 - accuracy: 0.9378 - val_loss: 0.2186 - val_accuracy: 0.9393\n",
      "Epoch 35/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1891 - accuracy: 0.9399 - val_loss: 0.2217 - val_accuracy: 0.9393\n",
      "Epoch 36/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.9414 - val_loss: 0.2246 - val_accuracy: 0.9422\n",
      "Epoch 37/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.9370 - val_loss: 0.2348 - val_accuracy: 0.9364\n",
      "Epoch 38/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1849 - accuracy: 0.9407 - val_loss: 0.2260 - val_accuracy: 0.9393\n",
      "Epoch 39/200\n",
      "44/44 [==============================] - 0s 912us/step - loss: 0.1834 - accuracy: 0.9385 - val_loss: 0.2370 - val_accuracy: 0.9393\n",
      "Epoch 40/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1808 - accuracy: 0.9363 - val_loss: 0.1995 - val_accuracy: 0.9393\n",
      "Epoch 41/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.9385 - val_loss: 0.2260 - val_accuracy: 0.9393\n",
      "Epoch 42/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1800 - accuracy: 0.9392 - val_loss: 0.2359 - val_accuracy: 0.9364\n",
      "Epoch 43/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1810 - accuracy: 0.9421 - val_loss: 0.2227 - val_accuracy: 0.9364\n",
      "Epoch 44/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1785 - accuracy: 0.9407 - val_loss: 0.2255 - val_accuracy: 0.9364\n",
      "Epoch 45/200\n",
      "44/44 [==============================] - 0s 828us/step - loss: 0.1798 - accuracy: 0.9407 - val_loss: 0.2280 - val_accuracy: 0.9335\n",
      "Epoch 46/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1782 - accuracy: 0.9378 - val_loss: 0.1912 - val_accuracy: 0.9393\n",
      "Epoch 47/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.9399 - val_loss: 0.2348 - val_accuracy: 0.9191\n",
      "Epoch 48/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.9399 - val_loss: 0.1909 - val_accuracy: 0.9422\n",
      "Epoch 49/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.9414 - val_loss: 0.2061 - val_accuracy: 0.9393\n",
      "Epoch 50/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1752 - accuracy: 0.9392 - val_loss: 0.1709 - val_accuracy: 0.9480\n",
      "Epoch 51/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1740 - accuracy: 0.9414 - val_loss: 0.2163 - val_accuracy: 0.9335\n",
      "Epoch 52/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1728 - accuracy: 0.9385 - val_loss: 0.1917 - val_accuracy: 0.9422\n",
      "Epoch 53/200\n",
      "44/44 [==============================] - 0s 969us/step - loss: 0.1743 - accuracy: 0.9385 - val_loss: 0.1891 - val_accuracy: 0.9393\n",
      "Epoch 54/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1726 - accuracy: 0.9392 - val_loss: 0.1888 - val_accuracy: 0.9393\n",
      "Epoch 55/200\n",
      "44/44 [==============================] - 0s 864us/step - loss: 0.1707 - accuracy: 0.9407 - val_loss: 0.1668 - val_accuracy: 0.9422\n",
      "Epoch 56/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1727 - accuracy: 0.9385 - val_loss: 0.2069 - val_accuracy: 0.9364\n",
      "Epoch 57/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1728 - accuracy: 0.9414 - val_loss: 0.1673 - val_accuracy: 0.9422\n",
      "Epoch 58/200\n",
      "44/44 [==============================] - 0s 919us/step - loss: 0.1707 - accuracy: 0.9385 - val_loss: 0.2076 - val_accuracy: 0.9364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1692 - accuracy: 0.9414 - val_loss: 0.2076 - val_accuracy: 0.9335\n",
      "Epoch 60/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1687 - accuracy: 0.9414 - val_loss: 0.1916 - val_accuracy: 0.9393\n",
      "Epoch 61/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1694 - accuracy: 0.9407 - val_loss: 0.2131 - val_accuracy: 0.9335\n",
      "Epoch 62/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1684 - accuracy: 0.9392 - val_loss: 0.1864 - val_accuracy: 0.9393\n",
      "Epoch 63/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1673 - accuracy: 0.9399 - val_loss: 0.1950 - val_accuracy: 0.9393\n",
      "Epoch 64/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1663 - accuracy: 0.9407 - val_loss: 0.1851 - val_accuracy: 0.9422\n",
      "Epoch 65/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1692 - accuracy: 0.9392 - val_loss: 0.2093 - val_accuracy: 0.9249\n",
      "Epoch 66/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1734 - accuracy: 0.9363 - val_loss: 0.2130 - val_accuracy: 0.9335\n",
      "Epoch 67/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1673 - accuracy: 0.9414 - val_loss: 0.1768 - val_accuracy: 0.9393\n",
      "Epoch 68/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1646 - accuracy: 0.9414 - val_loss: 0.1755 - val_accuracy: 0.9393\n",
      "Epoch 69/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1659 - accuracy: 0.9407 - val_loss: 0.1749 - val_accuracy: 0.9393\n",
      "Epoch 70/200\n",
      "44/44 [==============================] - 0s 907us/step - loss: 0.1645 - accuracy: 0.9414 - val_loss: 0.2004 - val_accuracy: 0.9335\n",
      "Epoch 71/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1650 - accuracy: 0.9414 - val_loss: 0.1920 - val_accuracy: 0.9364\n",
      "Epoch 72/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1631 - accuracy: 0.9407 - val_loss: 0.1798 - val_accuracy: 0.9393\n",
      "Epoch 73/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1636 - accuracy: 0.9414 - val_loss: 0.1947 - val_accuracy: 0.9249\n",
      "Epoch 74/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1631 - accuracy: 0.9392 - val_loss: 0.1770 - val_accuracy: 0.9393\n",
      "Epoch 75/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1637 - accuracy: 0.9399 - val_loss: 0.1571 - val_accuracy: 0.9422\n",
      "Epoch 76/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1641 - accuracy: 0.9399 - val_loss: 0.1687 - val_accuracy: 0.9393\n",
      "Epoch 77/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1626 - accuracy: 0.9414 - val_loss: 0.1660 - val_accuracy: 0.9393\n",
      "Epoch 78/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1622 - accuracy: 0.9399 - val_loss: 0.1914 - val_accuracy: 0.9364\n",
      "Epoch 79/200\n",
      "44/44 [==============================] - 0s 855us/step - loss: 0.1624 - accuracy: 0.9407 - val_loss: 0.1840 - val_accuracy: 0.9364\n",
      "Epoch 80/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1629 - accuracy: 0.9399 - val_loss: 0.1743 - val_accuracy: 0.9364\n",
      "Epoch 81/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1612 - accuracy: 0.9407 - val_loss: 0.1618 - val_accuracy: 0.9422\n",
      "Epoch 82/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1633 - accuracy: 0.9399 - val_loss: 0.1878 - val_accuracy: 0.9277\n",
      "Epoch 83/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1623 - accuracy: 0.9407 - val_loss: 0.1888 - val_accuracy: 0.9364\n",
      "Epoch 84/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1612 - accuracy: 0.9414 - val_loss: 0.1706 - val_accuracy: 0.9393\n",
      "Epoch 85/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1610 - accuracy: 0.9392 - val_loss: 0.1913 - val_accuracy: 0.9277\n",
      "Epoch 86/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1613 - accuracy: 0.9414 - val_loss: 0.1610 - val_accuracy: 0.9393\n",
      "Epoch 87/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1617 - accuracy: 0.9363 - val_loss: 0.1703 - val_accuracy: 0.9364\n",
      "Epoch 88/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1606 - accuracy: 0.9385 - val_loss: 0.1798 - val_accuracy: 0.9364\n",
      "Epoch 89/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1606 - accuracy: 0.9414 - val_loss: 0.1835 - val_accuracy: 0.9364\n",
      "Epoch 90/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1611 - accuracy: 0.9407 - val_loss: 0.1696 - val_accuracy: 0.9393\n",
      "Epoch 91/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1597 - accuracy: 0.9428 - val_loss: 0.1689 - val_accuracy: 0.9393\n",
      "Epoch 92/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1607 - accuracy: 0.9392 - val_loss: 0.1709 - val_accuracy: 0.9364\n",
      "Epoch 93/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1595 - accuracy: 0.9414 - val_loss: 0.1853 - val_accuracy: 0.9249\n",
      "Epoch 94/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1588 - accuracy: 0.9392 - val_loss: 0.1687 - val_accuracy: 0.9393\n",
      "Epoch 95/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1599 - accuracy: 0.9392 - val_loss: 0.1550 - val_accuracy: 0.9393\n",
      "Epoch 96/200\n",
      "44/44 [==============================] - 0s 909us/step - loss: 0.1600 - accuracy: 0.9392 - val_loss: 0.1640 - val_accuracy: 0.9393\n",
      "Epoch 97/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1591 - accuracy: 0.9407 - val_loss: 0.1714 - val_accuracy: 0.9364\n",
      "Epoch 98/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1578 - accuracy: 0.9414 - val_loss: 0.1638 - val_accuracy: 0.9422\n",
      "Epoch 99/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1580 - accuracy: 0.9421 - val_loss: 0.2042 - val_accuracy: 0.9335\n",
      "Epoch 100/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1619 - accuracy: 0.9414 - val_loss: 0.1702 - val_accuracy: 0.9393\n",
      "Epoch 101/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1588 - accuracy: 0.9407 - val_loss: 0.1867 - val_accuracy: 0.9335\n",
      "Epoch 102/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1592 - accuracy: 0.9421 - val_loss: 0.1521 - val_accuracy: 0.9422\n",
      "Epoch 103/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1587 - accuracy: 0.9407 - val_loss: 0.1726 - val_accuracy: 0.9393\n",
      "Epoch 104/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1592 - accuracy: 0.9399 - val_loss: 0.1891 - val_accuracy: 0.9364\n",
      "Epoch 105/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1616 - accuracy: 0.9385 - val_loss: 0.2008 - val_accuracy: 0.9335\n",
      "Epoch 106/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1603 - accuracy: 0.9407 - val_loss: 0.1688 - val_accuracy: 0.9335\n",
      "Epoch 107/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1592 - accuracy: 0.9385 - val_loss: 0.1500 - val_accuracy: 0.9422\n",
      "Epoch 108/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1583 - accuracy: 0.9392 - val_loss: 0.1854 - val_accuracy: 0.9335\n",
      "Epoch 109/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1585 - accuracy: 0.9399 - val_loss: 0.1643 - val_accuracy: 0.9364\n",
      "Epoch 110/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1579 - accuracy: 0.9414 - val_loss: 0.1778 - val_accuracy: 0.9364\n",
      "Epoch 111/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1599 - accuracy: 0.9407 - val_loss: 0.1497 - val_accuracy: 0.9422\n",
      "Epoch 112/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1573 - accuracy: 0.9407 - val_loss: 0.1771 - val_accuracy: 0.9220\n",
      "Epoch 113/200\n",
      "44/44 [==============================] - 0s 968us/step - loss: 0.1577 - accuracy: 0.9385 - val_loss: 0.2011 - val_accuracy: 0.9075\n",
      "Epoch 114/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1567 - accuracy: 0.9407 - val_loss: 0.1687 - val_accuracy: 0.9364\n",
      "Epoch 115/200\n",
      "44/44 [==============================] - 0s 990us/step - loss: 0.1570 - accuracy: 0.9421 - val_loss: 0.1662 - val_accuracy: 0.9364\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1578 - accuracy: 0.9407 - val_loss: 0.1530 - val_accuracy: 0.9364\n",
      "Epoch 117/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1582 - accuracy: 0.9407 - val_loss: 0.1730 - val_accuracy: 0.9277\n",
      "Epoch 118/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1574 - accuracy: 0.9399 - val_loss: 0.1702 - val_accuracy: 0.9220\n",
      "Epoch 119/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1603 - accuracy: 0.9399 - val_loss: 0.1874 - val_accuracy: 0.9364\n",
      "Epoch 120/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1562 - accuracy: 0.9414 - val_loss: 0.1657 - val_accuracy: 0.9364\n",
      "Epoch 121/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1560 - accuracy: 0.9392 - val_loss: 0.1559 - val_accuracy: 0.9393\n",
      "Epoch 122/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1574 - accuracy: 0.9407 - val_loss: 0.1870 - val_accuracy: 0.9191\n",
      "Epoch 123/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1570 - accuracy: 0.9407 - val_loss: 0.1613 - val_accuracy: 0.9393\n",
      "Epoch 124/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1582 - accuracy: 0.9399 - val_loss: 0.1945 - val_accuracy: 0.9335\n",
      "Epoch 125/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1553 - accuracy: 0.9428 - val_loss: 0.1643 - val_accuracy: 0.9393\n",
      "Epoch 126/200\n",
      "44/44 [==============================] - 0s 915us/step - loss: 0.1578 - accuracy: 0.9414 - val_loss: 0.1911 - val_accuracy: 0.9277\n",
      "Epoch 127/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1558 - accuracy: 0.9407 - val_loss: 0.1642 - val_accuracy: 0.9277\n",
      "Epoch 128/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 0.9370 - val_loss: 0.2038 - val_accuracy: 0.9306\n",
      "Epoch 129/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1566 - accuracy: 0.9436 - val_loss: 0.1717 - val_accuracy: 0.9364\n",
      "Epoch 130/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1553 - accuracy: 0.9407 - val_loss: 0.1474 - val_accuracy: 0.9393\n",
      "Epoch 131/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1584 - accuracy: 0.9436 - val_loss: 0.1437 - val_accuracy: 0.9393\n",
      "Epoch 132/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1568 - accuracy: 0.9407 - val_loss: 0.1703 - val_accuracy: 0.9364\n",
      "Epoch 133/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1577 - accuracy: 0.9392 - val_loss: 0.1617 - val_accuracy: 0.9364\n",
      "Epoch 134/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 0.9414 - val_loss: 0.1826 - val_accuracy: 0.9191\n",
      "Epoch 135/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1559 - accuracy: 0.9436 - val_loss: 0.1820 - val_accuracy: 0.9335\n",
      "Epoch 136/200\n",
      "44/44 [==============================] - 0s 858us/step - loss: 0.1563 - accuracy: 0.9407 - val_loss: 0.1603 - val_accuracy: 0.9364\n",
      "Epoch 137/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1572 - accuracy: 0.9414 - val_loss: 0.1835 - val_accuracy: 0.9220\n",
      "Epoch 138/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1552 - accuracy: 0.9428 - val_loss: 0.1626 - val_accuracy: 0.9364\n",
      "Epoch 139/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1557 - accuracy: 0.9385 - val_loss: 0.2172 - val_accuracy: 0.9075\n",
      "Epoch 140/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1582 - accuracy: 0.9399 - val_loss: 0.1563 - val_accuracy: 0.9364\n",
      "Epoch 141/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1568 - accuracy: 0.9414 - val_loss: 0.1711 - val_accuracy: 0.9249\n",
      "Epoch 142/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1552 - accuracy: 0.9385 - val_loss: 0.1924 - val_accuracy: 0.9162\n",
      "Epoch 143/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1546 - accuracy: 0.9414 - val_loss: 0.1606 - val_accuracy: 0.9393\n",
      "Epoch 144/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1539 - accuracy: 0.9407 - val_loss: 0.2008 - val_accuracy: 0.9162\n",
      "Epoch 145/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1556 - accuracy: 0.9407 - val_loss: 0.1587 - val_accuracy: 0.9364\n",
      "Epoch 146/200\n",
      "44/44 [==============================] - 0s 977us/step - loss: 0.1548 - accuracy: 0.9407 - val_loss: 0.1665 - val_accuracy: 0.9364\n",
      "Epoch 147/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1550 - accuracy: 0.9414 - val_loss: 0.1608 - val_accuracy: 0.9364\n",
      "Epoch 148/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1555 - accuracy: 0.9407 - val_loss: 0.1547 - val_accuracy: 0.9364\n",
      "Epoch 149/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1537 - accuracy: 0.9421 - val_loss: 0.1755 - val_accuracy: 0.9191\n",
      "Epoch 150/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1543 - accuracy: 0.9407 - val_loss: 0.1897 - val_accuracy: 0.9364\n",
      "Epoch 151/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1556 - accuracy: 0.9428 - val_loss: 0.1551 - val_accuracy: 0.9422\n",
      "Epoch 152/200\n",
      "44/44 [==============================] - 0s 845us/step - loss: 0.1539 - accuracy: 0.9392 - val_loss: 0.1937 - val_accuracy: 0.9335\n",
      "Epoch 153/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1546 - accuracy: 0.9414 - val_loss: 0.1550 - val_accuracy: 0.9393\n",
      "Epoch 154/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1542 - accuracy: 0.9414 - val_loss: 0.1682 - val_accuracy: 0.9364\n",
      "Epoch 155/200\n",
      "44/44 [==============================] - 0s 921us/step - loss: 0.1557 - accuracy: 0.9436 - val_loss: 0.1729 - val_accuracy: 0.9191\n",
      "Epoch 156/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1550 - accuracy: 0.9378 - val_loss: 0.1518 - val_accuracy: 0.9393\n",
      "Epoch 157/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1550 - accuracy: 0.9399 - val_loss: 0.1718 - val_accuracy: 0.9191\n",
      "Epoch 158/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1564 - accuracy: 0.9407 - val_loss: 0.1478 - val_accuracy: 0.9393\n",
      "Epoch 159/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1552 - accuracy: 0.9407 - val_loss: 0.1939 - val_accuracy: 0.9104\n",
      "Epoch 160/200\n",
      "44/44 [==============================] - 0s 983us/step - loss: 0.1546 - accuracy: 0.9399 - val_loss: 0.1511 - val_accuracy: 0.9277\n",
      "Epoch 161/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1545 - accuracy: 0.9370 - val_loss: 0.1650 - val_accuracy: 0.9364\n",
      "Epoch 162/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1558 - accuracy: 0.9378 - val_loss: 0.1512 - val_accuracy: 0.9393\n",
      "Epoch 163/200\n",
      "44/44 [==============================] - 0s 904us/step - loss: 0.1540 - accuracy: 0.9428 - val_loss: 0.1583 - val_accuracy: 0.9364\n",
      "Epoch 164/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1555 - accuracy: 0.9399 - val_loss: 0.1558 - val_accuracy: 0.9364\n",
      "Epoch 165/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1581 - accuracy: 0.9356 - val_loss: 0.1829 - val_accuracy: 0.9075\n",
      "Epoch 166/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1557 - accuracy: 0.9414 - val_loss: 0.1891 - val_accuracy: 0.9162\n",
      "Epoch 167/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1532 - accuracy: 0.9407 - val_loss: 0.1705 - val_accuracy: 0.9249\n",
      "Epoch 168/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1537 - accuracy: 0.9414 - val_loss: 0.1497 - val_accuracy: 0.9393\n",
      "Epoch 169/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1539 - accuracy: 0.9421 - val_loss: 0.1614 - val_accuracy: 0.9393\n",
      "Epoch 170/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1526 - accuracy: 0.9414 - val_loss: 0.1774 - val_accuracy: 0.9191\n",
      "Epoch 171/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1528 - accuracy: 0.9414 - val_loss: 0.1523 - val_accuracy: 0.9364\n",
      "Epoch 172/200\n",
      "44/44 [==============================] - 0s 947us/step - loss: 0.1528 - accuracy: 0.9421 - val_loss: 0.1762 - val_accuracy: 0.9191\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1537 - accuracy: 0.9421 - val_loss: 0.1795 - val_accuracy: 0.9249\n",
      "Epoch 174/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1542 - accuracy: 0.9385 - val_loss: 0.1669 - val_accuracy: 0.9364\n",
      "Epoch 175/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1528 - accuracy: 0.9428 - val_loss: 0.1613 - val_accuracy: 0.9364\n",
      "Epoch 176/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1551 - accuracy: 0.9407 - val_loss: 0.1766 - val_accuracy: 0.9335\n",
      "Epoch 177/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1551 - accuracy: 0.9385 - val_loss: 0.1900 - val_accuracy: 0.9364\n",
      "Epoch 178/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.9407 - val_loss: 0.1491 - val_accuracy: 0.9422\n",
      "Epoch 179/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1538 - accuracy: 0.9421 - val_loss: 0.1655 - val_accuracy: 0.9306\n",
      "Epoch 180/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1541 - accuracy: 0.9407 - val_loss: 0.1850 - val_accuracy: 0.9191\n",
      "Epoch 181/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1540 - accuracy: 0.9407 - val_loss: 0.1698 - val_accuracy: 0.9364\n",
      "Epoch 182/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1534 - accuracy: 0.9436 - val_loss: 0.1664 - val_accuracy: 0.9364\n",
      "Epoch 183/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1556 - accuracy: 0.9392 - val_loss: 0.2041 - val_accuracy: 0.9104\n",
      "Epoch 184/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1518 - accuracy: 0.9421 - val_loss: 0.1586 - val_accuracy: 0.9364\n",
      "Epoch 185/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1539 - accuracy: 0.9414 - val_loss: 0.1500 - val_accuracy: 0.9393\n",
      "Epoch 186/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1539 - accuracy: 0.9407 - val_loss: 0.1717 - val_accuracy: 0.9277\n",
      "Epoch 187/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1526 - accuracy: 0.9421 - val_loss: 0.1686 - val_accuracy: 0.9249\n",
      "Epoch 188/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1544 - accuracy: 0.9428 - val_loss: 0.1614 - val_accuracy: 0.9335\n",
      "Epoch 189/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1531 - accuracy: 0.9407 - val_loss: 0.1817 - val_accuracy: 0.9364\n",
      "Epoch 190/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1535 - accuracy: 0.9421 - val_loss: 0.1457 - val_accuracy: 0.9364\n",
      "Epoch 191/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1522 - accuracy: 0.9436 - val_loss: 0.1678 - val_accuracy: 0.9306\n",
      "Epoch 192/200\n",
      "44/44 [==============================] - 0s 937us/step - loss: 0.1535 - accuracy: 0.9370 - val_loss: 0.1573 - val_accuracy: 0.9364\n",
      "Epoch 193/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1525 - accuracy: 0.9414 - val_loss: 0.1787 - val_accuracy: 0.9191\n",
      "Epoch 194/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1523 - accuracy: 0.9428 - val_loss: 0.1449 - val_accuracy: 0.9364\n",
      "Epoch 195/200\n",
      "44/44 [==============================] - 0s 907us/step - loss: 0.1542 - accuracy: 0.9399 - val_loss: 0.1610 - val_accuracy: 0.9364\n",
      "Epoch 196/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1535 - accuracy: 0.9414 - val_loss: 0.1685 - val_accuracy: 0.9364\n",
      "Epoch 197/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1532 - accuracy: 0.9407 - val_loss: 0.1756 - val_accuracy: 0.9335\n",
      "Epoch 198/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1526 - accuracy: 0.9450 - val_loss: 0.1546 - val_accuracy: 0.9364\n",
      "Epoch 199/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1532 - accuracy: 0.9414 - val_loss: 0.1715 - val_accuracy: 0.9335\n",
      "Epoch 200/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1532 - accuracy: 0.9450 - val_loss: 0.1848 - val_accuracy: 0.9075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x242c3059e50>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_confirmed.fit(x_ctrain,y_ctrain,epochs=200,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_confirmed = (lstm_confirmed.predict(x_test) > 0.50).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['Id'] = df.loc[:,'Id']\n",
    "new_df['Confirmed'] = predicted_confirmed\n",
    "new_df['Deaths'] = predicted_deaths\n",
    "new_df['Recovered'] = predicted_recovered.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"Kagglepred_assgn3.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
